<!DOCTYPE html>
<!-- saved from url=(0053)https://github.com/mrdbourke/tensorflow-deep-learning -->
<html lang="en" data-color-mode="auto" data-light-theme="light" data-dark-theme="dark" data-a11y-animated-images="system" data-a11y-link-underlines="true" data-turbo-loaded=""><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><style type="text/css">.turbo-progress-bar {
  position: fixed;
  display: block;
  top: 0;
  left: 0;
  height: 3px;
  background: #0076ff;
  z-index: 2147483647;
  transition:
    width 300ms ease-out,
    opacity 150ms 150ms ease-in;
  transform: translate3d(0, 0, 0);
}
</style>
    
  <link rel="dns-prefetch" href="https://github.githubassets.com/">
  <link rel="dns-prefetch" href="https://avatars.githubusercontent.com/">
  <link rel="dns-prefetch" href="https://github-cloud.s3.amazonaws.com/">
  <link rel="dns-prefetch" href="https://user-images.githubusercontent.com/">
  <link rel="preconnect" href="https://github.githubassets.com/" crossorigin="">
  <link rel="preconnect" href="https://avatars.githubusercontent.com/">

  

  <link crossorigin="anonymous" media="all" rel="stylesheet" href="./github-tensorflow-deep-learning_files/light-efd2f2257c96.css"><link crossorigin="anonymous" media="all" rel="stylesheet" href="./github-tensorflow-deep-learning_files/dark-6b1e37da2254.css"><link data-color-theme="dark_dimmed" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark_dimmed-aa16bfa90fb8.css"><link data-color-theme="dark_high_contrast" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark_high_contrast-f4daad25d8cf.css"><link data-color-theme="dark_colorblind" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark_colorblind-a4629b2e906b.css"><link data-color-theme="light_colorblind" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/light_colorblind-afcc3a6a38dd.css"><link data-color-theme="light_high_contrast" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/light_high_contrast-79bca7145393.css"><link data-color-theme="light_tritanopia" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/light_tritanopia-fe4137b54b26.css"><link data-color-theme="dark_tritanopia" crossorigin="anonymous" media="all" rel="stylesheet" data-href="https://github.githubassets.com/assets/dark_tritanopia-1911f0cf0db4.css">
    <link crossorigin="anonymous" media="all" rel="stylesheet" href="./github-tensorflow-deep-learning_files/primer-primitives-8500c2c7ce5f.css">
    <link crossorigin="anonymous" media="all" rel="stylesheet" href="./github-tensorflow-deep-learning_files/primer-bbda46ca867f.css">
    <link crossorigin="anonymous" media="all" rel="stylesheet" href="./github-tensorflow-deep-learning_files/global-fe6db6dfddd1.css">
    <link crossorigin="anonymous" media="all" rel="stylesheet" href="./github-tensorflow-deep-learning_files/github-cf4e90581e80.css">
  <link crossorigin="anonymous" media="all" rel="stylesheet" href="./github-tensorflow-deep-learning_files/repository-992e95451f25.css">
<link crossorigin="anonymous" media="all" rel="stylesheet" href="./github-tensorflow-deep-learning_files/code-34406d39e629.css">

  


  <script type="application/json" id="client-env">{"locale":"en","featureFlags":["code_vulnerability_scanning","copilot_beta_features_opt_in","copilot_chat_static_thread_suggestions","copilot_completion_new_domain","copilot_conversational_ux_history_refs","copilot_followup_to_agent","copilot_implicit_context","copilot_smell_icebreaker_ux","custom_inp","experimentation_azure_variant_endpoint","failbot_handle_non_errors","filter_prefetch_suggestions","geojson_azure_maps","ghas_copilot_agents_ga_web_updates","ghost_pilot_confidence_scores","ghost_pilot_screen_reader","ghost_pilot_stream_handling","hovercard_accessibility","hovercard_longer_activate_timeout","marketing_pages_search_explore_provider","remove_child_patch","report_hydro_web_vitals","repository_suggester_elastic_search","sample_network_conn_type","site_metered_billing_update","ignore_hidden_in_quote_reply"]}</script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/wp-runtime-d11f0cd9d403.js.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_dompurify_dist_purify_js-89a69c248502.js.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_oddbird_popover-polyfill_dist_popover_js-567.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_github_mini-throttle_dist_index_js-node_modu.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/environment-cd098098ff2e.js.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_github_selector-observer_dist_index_esm_js-f.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_behaviors_dist_esm_focus-zone_js-c908.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_github_relative-time-element_dist_index_js-f.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_behaviors_dist_esm_anchored-position_.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_github_auto-complete-element_dist_index_js-n.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_github_text-expander-element_dist_index_js-c.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_github_mini-throttle_dist_index_js-nod(1).download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_github_filter-input-element_dist_index_js-no.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_github_catalyst_lib_index_js-node_modules_gi.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_github_file-attachment-element_dist_index_js.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/app_assets_modules_github_onfocus_ts-ui_packages_trusted-types-po.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/github-elements-074e91131d8f.js.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/element-registry-207a3f1b3875.js.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_github_catalyst_lib_index_js-node_modu(1).download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_braintree_browser-detection_dist_browser-det.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_lit-html_lit-html_js-ce7225a304c5.js.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_github_mini-throttle_dist_index_js-nod(2).download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_github_turbo_dist_turbo_es2017-esm_js-858e04.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_github_remote-form_dist_index_js-node_module.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_scroll-anchoring_dist_scroll-anchoring_esm_j.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_color-convert_index_js-0e07cc183eed.js.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_github_session-resume_dist_index_js-node_mod.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_behaviors_dist_esm_dimensions_js-node.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_github_quote-selection_dist_index_js-node_mo.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/ui_packages_updatable-content_updatable-content_ts-e15463ecf7e6.j.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/app_assets_modules_github_behaviors_task-list_ts-app_assets_modul.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/app_assets_modules_github_sticky-scroll-into-view_ts-112600808cf9.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/app_assets_modules_github_behaviors_ajax-error_ts-app_assets_modu.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/app_assets_modules_github_behaviors_commenting_edit_ts-app_assets.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/app_assets_modules_github_blob-anchor_ts-app_assets_modules_githu.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/behaviors-3b4c83250375.js.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_delegated-events_dist_index_js-node_modules_.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/notifications-global-3ddac678adaf.js.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_virtualized-list_es_index_js-node_modules_gi.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_github_remote-form_dist_index_js-node_(1).download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/app_assets_modules_github_ref-selector_ts-00df584d9e79.js.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/codespaces-1f3309c400b4.js.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_github_file-attachment-element_dist_in(1).download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/app_assets_modules_github_repositories_get-repo-element_ts-4fc152.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/repositories-22e89d7b03b0.js.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_github_mini-throttle_dist_index_js-nod(3).download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/code-menu-a8d08997ac4f.js.download"></script>
  
    <script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/react-lib-7b7b5264f6c1.js.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_github_mini-throttle_dist_index_js-nod(4).download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_Box_Box_js-55a9038b54f0.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_Button_Button_js-b0edbf.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_TooltipV2_Tooltip_js-4d.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_clsx_dist_clsx_m_js-node_modules_primer_reac.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_ActionList_index_js-f64.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_ActionMenu_ActionMenu_j.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_Text_Text_js-node_modul.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_FormControl_FormControl.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_FilteredActionList_Filt.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_Dialog_js-node_modules_.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/ui_packages_react-core_create-browser-history_ts-ui_packages_safe.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/notifications-subscriptions-menu-be1efa498152.js.download"></script>
<link crossorigin="anonymous" media="all" rel="stylesheet" href="./github-tensorflow-deep-learning_files/notifications-subscriptions-menu.572fff1cb5c3caef1ac9.module.css">


  <title>mrdbourke/tensorflow-deep-learning: All course materials for the Zero to Mastery Deep Learning with TensorFlow course.</title>



  <meta name="route-pattern" content="/:user_id/:repository" data-turbo-transient="">
  <meta name="route-controller" content="files" data-turbo-transient="">
  <meta name="route-action" content="disambiguate" data-turbo-transient="">

    
  <meta name="current-catalog-service-hash" content="f3abb0cc802f3d7b95fc8762b94bdcb13bf39634c40c357301c4aa1d67a256fb">


  <meta name="request-id" content="FCB3:12FEE2:DF07B9:E29DF1:66BFBABE" data-turbo-transient="true"><meta name="html-safe-nonce" content="d8e4e8e38ccefc4171aceda94f57b4bfd561b1b705ef3dc448c6de591c573bea" data-turbo-transient="true"><meta name="visitor-payload" content="eyJyZWZlcnJlciI6Imh0dHBzOi8vd3d3LnVkZW15LmNvbS8iLCJyZXF1ZXN0X2lkIjoiRkNCMzoxMkZFRTI6REYwN0I5OkUyOURGMTo2NkJGQkFCRSIsInZpc2l0b3JfaWQiOiI4ODEyNzIwMDc5Mjg1MjM2NzI2IiwicmVnaW9uX2VkZ2UiOiJzZWEiLCJyZWdpb25fcmVuZGVyIjoiaWFkIn0=" data-turbo-transient="true"><meta name="visitor-hmac" content="042dddea12f9df58a5c8abfc1a5d581e70b3bc9f1dd2621a57823a7673646b36" data-turbo-transient="true">


    <meta name="hovercard-subject-tag" content="repository:315463340" data-turbo-transient="">


  <meta name="github-keyboard-shortcuts" content="repository,copilot" data-turbo-transient="true">
  

  <meta name="selected-link" value="repo_source" data-turbo-transient="">
  <link rel="assets" href="https://github.githubassets.com/">

    <meta name="google-site-verification" content="Apib7-x98H0j5cPqHWwSMm6dNU4GmODRoqxLiDzdx9I">

<meta name="octolytics-url" content="https://collector.github.com/github/collect"><meta name="octolytics-actor-id" content="63025015"><meta name="octolytics-actor-login" content="xroadtraveler"><meta name="octolytics-actor-hash" content="067a46a1c5fab517bba1085bba20e0971dcd3a9c118ee61eefef6f2c4c02149a">

  <meta name="analytics-location" content="/&lt;user-name&gt;/&lt;repo-name&gt;" data-turbo-transient="true">

  




    <meta name="user-login" content="xroadtraveler">

  <link rel="sudo-modal" href="https://github.com/sessions/sudo_modal">

    <meta name="viewport" content="width=device-width">

    

      <meta name="description" content="All course materials for the Zero to Mastery Deep Learning with TensorFlow course. - mrdbourke/tensorflow-deep-learning">

      <link rel="search" type="application/opensearchdescription+xml" href="https://github.com/opensearch.xml" title="GitHub">

    <link rel="fluid-icon" href="https://github.com/fluidicon.png" title="GitHub">
    <meta property="fb:app_id" content="1401488693436528">
    <meta name="apple-itunes-app" content="app-id=1477376905, app-argument=https://github.com/mrdbourke/tensorflow-deep-learning">

      <meta name="twitter:image:src" content="https://repository-images.githubusercontent.com/315463340/97930280-7699-11eb-83db-150c8cd7f3e6"><meta name="twitter:site" content="@github"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="mrdbourke/tensorflow-deep-learning: All course materials for the Zero to Mastery Deep Learning with TensorFlow course."><meta name="twitter:description" content="All course materials for the Zero to Mastery Deep Learning with TensorFlow course. - mrdbourke/tensorflow-deep-learning">
  <meta property="og:image" content="https://repository-images.githubusercontent.com/315463340/97930280-7699-11eb-83db-150c8cd7f3e6"><meta property="og:image:alt" content="All course materials for the Zero to Mastery Deep Learning with TensorFlow course. - mrdbourke/tensorflow-deep-learning"><meta property="og:site_name" content="GitHub"><meta property="og:type" content="object"><meta property="og:title" content="mrdbourke/tensorflow-deep-learning: All course materials for the Zero to Mastery Deep Learning with TensorFlow course."><meta property="og:url" content="https://github.com/mrdbourke/tensorflow-deep-learning"><meta property="og:description" content="All course materials for the Zero to Mastery Deep Learning with TensorFlow course. - mrdbourke/tensorflow-deep-learning">
  


      <link rel="shared-web-socket" href="wss://alive.github.com/_sockets/u/63025015/ws?session=eyJ2IjoiVjMiLCJ1Ijo2MzAyNTAxNSwicyI6MTQ0NjMzMTAxOSwiYyI6MTI4MTc5NDI3MSwidCI6MTcyMzg0MTIxNH0=--1796f0bb4722d2db728c2abadfe5aef0e089a98a4417f1d633c7f724d80d59cf" data-refresh-url="/_alive" data-session-id="1e11f212c35fba52f5b2009b4ddcf323229069017fe5d8b41f82bd1fa394d5e3">
      <link rel="shared-web-socket-src" href="https://github.com/assets-cdn/worker/socket-worker-1a9b1a7a6108.js">


      <meta name="hostname" content="github.com">


      <meta name="keyboard-shortcuts-preference" content="all">
      <meta name="hovercards-preference" content="true">

        <meta name="expected-hostname" content="github.com">


  <meta http-equiv="x-pjax-version" content="b3ac1ddb39875dae2ded80cd9cef61cfbd6c5a031048367541d6101aa202584b" data-turbo-track="reload">
  <meta http-equiv="x-pjax-csp-version" content="43bc2a0e2750a1219c17b5bf1ec22aae37041bbc018bc5e27bb7708f80e7ab88" data-turbo-track="reload">
  <meta http-equiv="x-pjax-css-version" content="7f3a6fa631adee55b20691ccc8267f762130f641fe9a0d5ba41c45f484f2eb18" data-turbo-track="reload">
  <meta http-equiv="x-pjax-js-version" content="97bb3529754a93478ec83e919e442209258c0a6ef723da7730823348490275fc" data-turbo-track="reload">

  <meta name="turbo-cache-control" content="no-preview" data-turbo-transient="">

      <meta data-hydrostats="publish">
  <meta name="go-import" content="github.com/mrdbourke/tensorflow-deep-learning git https://github.com/mrdbourke/tensorflow-deep-learning.git">

  <meta name="octolytics-dimension-user_id" content="16750345"><meta name="octolytics-dimension-user_login" content="mrdbourke"><meta name="octolytics-dimension-repository_id" content="315463340"><meta name="octolytics-dimension-repository_nwo" content="mrdbourke/tensorflow-deep-learning"><meta name="octolytics-dimension-repository_public" content="true"><meta name="octolytics-dimension-repository_is_fork" content="false"><meta name="octolytics-dimension-repository_network_root_id" content="315463340"><meta name="octolytics-dimension-repository_network_root_nwo" content="mrdbourke/tensorflow-deep-learning">



      <link rel="canonical" href="https://github.com/mrdbourke/tensorflow-deep-learning" data-turbo-transient="">


    <meta name="turbo-body-classes" content="logged-in env-production page-responsive">


  <meta name="browser-stats-url" content="https://api.github.com/_private/browser/stats">

  <meta name="browser-errors-url" content="https://api.github.com/_private/browser/errors">

  <link rel="mask-icon" href="https://github.githubassets.com/assets/pinned-octocat-093da3e6fa40.svg" color="#000000">
  <link rel="alternate icon" class="js-site-favicon" type="image/png" href="https://github.githubassets.com/favicons/favicon.png">
  <link rel="icon" class="js-site-favicon" type="image/svg+xml" href="https://github.githubassets.com/favicons/favicon.svg">

<meta name="theme-color" content="#1e2327">
<meta name="color-scheme" content="light dark">


  <link rel="manifest" href="https://github.com/manifest.json" crossorigin="use-credentials">

  <link rel="stylesheet" type="text/css" href="chrome-extension://fleenceagaplaefnklabikkmocalkcpo/content-script/assets/fonts/webfonts.css"><style data-styled="active" data-styled-version="5.3.6"></style><style>.ssBtnDefault{position:absolute;z-index:100000000;background:none;border:none;outline:none;right:0;cursor:pointer;width:26px;height:26px;margin:0;padding:0;top:8px;right:8px;opacity:.6;pointer-events:all;transition-duration:.25s}.ssBtnDefault:hover{opacity:1 !important;transition-duration:.25s}.ssBtnDefault .fade{transition-duration:5s;opacity:0}.ssBtnYouTube{background:none;border:none;margin-right:20px !important;padding-top:0px !important;width:25px !important}.ytp-embed .ssBtnYouTube{width:20px !important;margin-right:15px !important}.ssBtnVimeo{height:2rem !important;width:2rem !important;margin-top:8px !important}.ssBtnVimeo button{width:100% !important;height:100% !important}.ssBtnVimeo button svg{width:19px}.ssBtnNetflix{background:none;border:none;cursor:pointer;width:4rem;margin:0 .5rem;display:inline-block;flex-shrink:0}.ssBtnNetflix>svg{transform:translateY(-0.3rem)}.ssBtnNetflix:hover{transform:scale(1.2);transition-duration:.25s}.ssBtnHulu{width:27px;margin-top:4px;margin-right:10px;opacity:.7;cursor:pointer}.ssBtnHulu:hover{opacity:1}.ssBtnAmazon{margin-right:1.5vw;outline:none;cursor:pointer;opacity:.8}.ssBtnAmazon:hover{opacity:1}@media(min-width: 1200px){.ssBtnAmazon{width:1.6666666667vw;height:1.6666666667vw}}@media(max-width: 1199px){.ssBtnAmazon{width:20px;height:20px}}.ssBtnHBO{width:48px;height:48px;position:relative;opacity:.7;cursor:pointer;display:flex;justify-content:center;align-items:center}.ssBtnHBO:hover{opacity:1;transform:scale(1.2)}.ssBtnHBO svg{width:24px;height:24px}.ssBtnDisney{opacity:.7}.ssBtnDisney:hover{opacity:1}.ssBtnDisney svg{width:25px !important;height:31px !important;padding-top:4px;margin-right:7px}.ssBtnApple{cursor:pointer;opacity:.7}.ssBtnApple:hover{opacity:1}.ssBtnApple svg{width:22px !important;height:22px !important;margin-right:2px !important}body #ssTempHolder{position:fixed;z-index:1000000000000;width:100%;height:100%;top:0;pointer-events:none}body #ssTempHolder video{width:auto !important;height:auto !important;max-width:100% !important;max-height:100% !important;top:0 !important;left:0 !important;transform:none !important}body.ssTakeScreenshot .ssElement{z-index:100000000000 !important}body.ssTakeScreenshot.ssNetflix [data-uia=video-canvas]{z-index:10000000}body.ssTakeScreenshot.ssNetflix video{background-color:#000}body.ssTakeScreenshot.ssNetflix .player-timedtext{display:none !important}body.ssTakeScreenshot.ssNetflix.showSubs .player-timedtext{display:block !important}body.ssTakeScreenshot.ssAmazon .scalingVideoContainer{z-index:99999999 !important}body.ssTakeScreenshot.ssDisney .btm-media-overlays-container{display:none}body.ssTakeScreenshot.ssDisney .dss-hls-subtitle-overlay{display:none}body.ssTakeScreenshot.ssDisney.showSubs .dss-hls-subtitle-overlay{display:block}body.ssTakeScreenshot.ssHulu .ContentPlayer__contentArea{z-index:10000000000;position:relative}body.ssTakeScreenshot.ssHulu .ClosedCaption{display:none}body.ssTakeScreenshot.ssHulu.showSubs .ClosedCaption{display:block}body.ssTakeScreenshot.ssHulu.showSubs .ClosedCaption .ClosedCaption__outband{bottom:30px !important}body.ssTakeScreenshot.ssHBO video{z-index:99999999}body.ssTakeScreenshot.ssHBO *:has(video){z-index:99999999}body.ssTakeScreenshot.ssYoutube .html5-video-container,body.ssTakeScreenshot.ssYoutube .ytp-caption-window-container{z-index:999999999 !important}body.ssTakeScreenshot.ssApple #apple-music-video-player{z-index:999999999 !important}body.ssTakeScreenshot.ssApple .scrim{display:none}body .ssWrapper{overflow:hidden}body .ssNotification{display:flex;width:100%;height:4rem;justify-content:center;align-items:center;position:fixed;z-index:1000000000;top:-4rem;animation-name:notification;animation-duration:2s;animation-iteration-count:1}@keyframes notification{0%{top:-4rem}25%{top:3rem}85%{top:3rem}}body .ssNotification .ssNContent{position:absolute;z-index:1000000000;padding:.75rem 1.25em;margin-bottom:1em;border:1px solid rgba(0,0,0,0);border-radius:.25em;font-size:12px;height:fit-content;top:0}body .ssNotification .ssNContent.success{background-color:#d4edda;border-color:#c3e6cb;color:#155724}body .ssNotification .ssNContent.fail{background-color:#edd4d4;border-color:#e6c3c3;color:#b62424}body .ssModal{display:none;position:fixed;z-index:100000000;right:20px;opacity:0;background-color:#fffefa;border-radius:3px;padding:25px;color:#525252;font-family:muli,sans-serif;box-shadow:0px 4px 8px 0px rgba(0,0,0,.15);animation-name:animateOn;animation-duration:.2s;animation-fill-mode:forwards}body .ssModal.visible{display:block}body .ssModal *{vertical-align:middle;line-height:normal;font-weight:normal}@keyframes animateOn{from{opacity:0;top:0px}to{opacity:1;top:20px}}body .ssModal .close{position:absolute;right:10px;top:10px;cursor:pointer;opacity:.5;background-image:url(data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4KPCEtLSBHZW5lcmF0b3I6IEFkb2JlIElsbHVzdHJhdG9yIDI3LjAuMCwgU1ZHIEV4cG9ydCBQbHVnLUluIC4gU1ZHIFZlcnNpb246IDYuMDAgQnVpbGQgMCkgIC0tPgo8c3ZnIHZlcnNpb249IjEuMSIgaWQ9IkxheWVyXzEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiIHg9IjBweCIgeT0iMHB4IgoJIHZpZXdCb3g9IjAgMCA0NDMuNCA0NDMuNCIgc3R5bGU9ImVuYWJsZS1iYWNrZ3JvdW5kOm5ldyAwIDAgNDQzLjQgNDQzLjQ7IiB4bWw6c3BhY2U9InByZXNlcnZlIj4KPHBhdGggZD0iTTYuOCw0MDMuNWwxODEuOC0xODEuOEw2LjgsMzkuOWMtNS45LTUuOS04LjItMTQuNS02LTIyLjZDMyw5LjIsOS4yLDMsMTcuMywwLjhjOC4xLTIuMiwxNi43LDAuMSwyMi42LDZsMTgxLjgsMTgxLjgKCUw0MDMuNSw2LjhjNS45LTUuOSwxNC41LTguMiwyMi42LTZjOC4xLDIuMiwxNC40LDguNCwxNi41LDE2LjVjMi4yLDguMS0wLjEsMTYuNy02LDIyLjZMMjU0LjcsMjIxLjdsMTgxLjgsMTgxLjgKCWM1LjksNS45LDguMiwxNC41LDYsMjIuNmMtMi4yLDguMS04LjQsMTQuNC0xNi41LDE2LjVjLTguMSwyLjItMTYuNy0wLjEtMjIuNi02TDIyMS43LDI1NC43TDM5LjksNDM2LjVjLTUuOSw1LjktMTQuNSw4LjItMjIuNiw2CglDOS4yLDQ0MC40LDMsNDM0LjEsMC44LDQyNkMtMS40LDQxOCwwLjksNDA5LjQsNi44LDQwMy41TDYuOCw0MDMuNXoiLz4KPC9zdmc+Cg==);width:10px;height:10px}body .ssModal .ssButtons{margin-top:25px;text-align:right}body .ssModal .ssButtons .ssButton,body .ssModal .ssButtons a .ssButton{display:inline-block;height:20px;padding:3px 12px 3px;margin-left:14px;border-radius:4px;box-shadow:0px 4px 8px 0px rgba(0,0,0,.15);background-color:#fff;font-size:12px;color:#525252;line-height:20px;font-weight:normal;cursor:pointer;text-decoration:none}body .ssModal .ssButtons .ssButton .emoji,body .ssModal .ssButtons a .ssButton .emoji{font-size:15px;vertical-align:bottom}body .ssModal .ssButtons .ssButton.blue,body .ssModal .ssButtons a .ssButton.blue{background-color:#19acef;color:#fff}body .ssModal .icon{background-image:url(data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4KPCEtLSBHZW5lcmF0b3I6IEFkb2JlIElsbHVzdHJhdG9yIDI1LjIuMywgU1ZHIEV4cG9ydCBQbHVnLUluIC4gU1ZHIFZlcnNpb246IDYuMDAgQnVpbGQgMCkgIC0tPgo8c3ZnIHZlcnNpb249IjEuMSIKCSBpZD0iTGF5ZXJfMSIgeG1sbnM6Y2M9Imh0dHA6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL25zIyIgeG1sbnM6ZGM9Imh0dHA6Ly9wdXJsLm9yZy9kYy9lbGVtZW50cy8xLjEvIiB4bWxuczppbmtzY2FwZT0iaHR0cDovL3d3dy5pbmtzY2FwZS5vcmcvbmFtZXNwYWNlcy9pbmtzY2FwZSIgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIiB4bWxuczpzb2RpcG9kaT0iaHR0cDovL3NvZGlwb2RpLnNvdXJjZWZvcmdlLm5ldC9EVEQvc29kaXBvZGktMC5kdGQiIHhtbG5zOnN2Zz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciCgkgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayIgeD0iMHB4IiB5PSIwcHgiIHZpZXdCb3g9IjAgMCAxMDAgODMuOSIKCSBzdHlsZT0iZW5hYmxlLWJhY2tncm91bmQ6bmV3IDAgMCAxMDAgODMuOTsiIHhtbDpzcGFjZT0icHJlc2VydmUiPgo8c3R5bGUgdHlwZT0idGV4dC9jc3MiPgoJLnN0MHtmaWxsOiMwMEFERUY7fQo8L3N0eWxlPgo8ZyB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLC05NTIuMzYyMTgpIj4KCTxwYXRoIGNsYXNzPSJzdDAiIGQ9Ik0zNS42LDk1Mi40Yy0xLjMsMC0yLjQsMS0yLjksMS44bC01LjYsMTEuMUgxMWMtNiwwLTExLDUtMTEsMTF2NDljMCw2LDUsMTEsMTEsMTFoNzhjNiwwLDExLTUsMTEtMTF2LTQ5CgkJYzAtNi01LTExLTExLTExSDcyLjlsLTUuNi0xMS4xYy0wLjUtMS4xLTEuNi0xLjgtMi45LTEuOEwzNS42LDk1Mi40TDM1LjYsOTUyLjR6IE0zNy42LDk1OC44aDI1LjJsNS41LDExLjEKCQljMC41LDEuMSwxLjYsMS44LDIuOSwxLjhoMTguMWMyLjYsMCw0LjUsMS45LDQuNSw0LjV2NDljMCwyLjYtMS45LDQuNS00LjUsNC41SDExLjFjLTIuNiwwLTQuNS0xLjktNC41LTQuNXYtNDkKCQljMC0yLjYsMS45LTQuNSw0LjUtNC41aDE4LjFjMS4xLDAsMi40LTAuOCwyLjktMS44TDM3LjYsOTU4Ljh6IE01MC4yLDk3OS44Yy0xMS42LDAtMjEsOS40LTIxLDIxczkuNCwyMSwyMSwyMXMyMS05LjQsMjEtMjEKCQlTNjEuOCw5NzkuOCw1MC4yLDk3OS44eiBNNTAuMiw5ODYuMmM4LjEsMCwxNC41LDYuNSwxNC41LDE0LjVzLTYuNSwxNC41LTE0LjUsMTQuNXMtMTQuNS02LjUtMTQuNS0xNC41UzQyLjEsOTg2LjIsNTAuMiw5ODYuMnoiLz4KPC9nPgo8L3N2Zz4K);background-repeat:no-repeat;width:30px;height:30px;vertical-align:top;margin-right:22px;margin-top:2px;display:inline-block}body .ssModal .body{display:inline-block;width:315px}body .ssModal .body .title{font-size:15px;font-weight:600;margin-bottom:7px}body .ssModal .body .description{font-size:13px;font-weight:lighter}
/*# sourceMappingURL=data:application/json;base64,{"version":3,"sources":["webpack://./scss/ScreenshotControl/_buttons.scss","webpack://./scss/ScreenshotControl.scss","webpack://./scss/ScreenshotControl/_notifications.scss","webpack://./scss/ScreenshotControl/_modal.scss"],"names":[],"mappings":"AAAA,cAEC,iBAAA,CACA,iBAAA,CACA,eAAA,CACA,WAAA,CACA,YAAA,CACA,OAAA,CACA,cAAA,CAEA,UAAA,CACA,WAAA,CACA,QAAA,CACA,SAAA,CACA,OAAA,CACA,SAAA,CAEA,UAAA,CACA,kBAAA,CAEG,wBAAA,CAEA,oBACI,oBAAA,CACA,wBAAA,CAGJ,oBACI,sBAAA,CACA,SAAA,CAQR,cAEC,eAAA,CACA,WAAA,CAEA,4BAAA,CACG,0BAAA,CACA,qBAAA,CAEH,yBACC,qBAAA,CACA,4BAAA,CAIF,YAEC,sBAAA,CACG,qBAAA,CAEA,yBAAA,CAEH,mBAEC,qBAAA,CACA,sBAAA,CAEA,uBACC,UAAA,CAMH,cACC,eAAA,CACA,WAAA,CACA,cAAA,CAEA,UAAA,CAEA,cAAA,CAGA,oBAAA,CACA,aAAA,CAUA,kBAEC,6BAAA,CAIE,oBACI,oBAAA,CACH,wBAAA,CAIL,WAEC,UAAA,CACA,cAAA,CACA,iBAAA,CACA,UAAA,CACA,cAAA,CAEA,iBACC,SAAA,CAIF,aACC,kBAAA,CAEA,YAAA,CAEE,cAAA,CACA,UAAA,CAIC,mBACI,SAAA,CAIR,0BAAA,aAAA,oBAAA,CAAA,qBAAA,CAAA,CACA,0BAAA,aAAA,UAAA,CAAA,WAAA,CAAA,CAGA,UAEI,UAAA,CACA,WAAA,CACA,iBAAA,CACA,UAAA,CACA,cAAA,CACA,YAAA,CACA,sBAAA,CACA,kBAAA,CAEH,gBACC,SAAA,CACA,oBAAA,CAGD,cACC,UAAA,CACA,WAAA,CAIF,aAGI,UAAA,CAEH,mBACC,SAAA,CAGD,iBACC,qBAAA,CACA,sBAAA,CACA,eAAA,CACA,gBAAA,CAIF,YAIC,cAAA,CAGG,UAAA,CAEH,kBACC,SAAA,CAGD,gBACC,qBAAA,CACA,sBAAA,CACA,2BAAA,CC3LD,mBACC,cAAA,CACA,qBAAA,CACA,UAAA,CACA,WAAA,CACA,KAAA,CACA,mBAAA,CAEA,yBACC,qBAAA,CACA,sBAAA,CACA,yBAAA,CACA,0BAAA,CACA,gBAAA,CACA,iBAAA,CACA,yBAAA,CAMD,iCACC,+BAAA,CAKA,wDACC,gBAAA,CAGD,sCACC,qBAAA,CAID,kDAEC,uBAAA,CAKA,2DAEC,wBAAA,CAQF,sDACC,2BAAA,CAMD,6DACC,YAAA,CAGD,yDACC,YAAA,CAKA,kEACC,aAAA,CAMF,yDACC,mBAAA,CACG,iBAAA,CAGJ,4CACC,YAAA,CAIA,qDACC,aAAA,CAEA,6EACC,sBAAA,CAQH,kCACC,gBAAA,CAGD,yCACC,gBAAA,CAOD,qHACC,4BAAA,CAKD,wDACC,4BAAA,CAGD,qCACC,YAAA,CAKH,gBACC,eAAA,CCpIF,qBAEI,YAAA,CACA,UAAA,CACA,WAAA,CACA,sBAAA,CACA,kBAAA,CACA,cAAA,CACA,kBAAA,CACA,SAAA,CAEA,2BAAA,CACA,qBAAA,CACA,2BAAA,CAEA,wBACI,GAAA,SAAA,CACA,IAAA,QAAA,CACA,IAAA,QAAA,CAAA,CAGJ,iCAEI,iBAAA,CACA,kBAAA,CACA,qBAAA,CACA,iBAAA,CACA,8BAAA,CACA,mBAAA,CACA,cAAA,CACA,kBAAA,CACA,KAAA,CAEA,yCACI,wBAAA,CACA,oBAAA,CACA,aAAA,CAGJ,sCACI,wBAAA,CACA,oBAAA,CACA,aAAA,CC1CZ,cAEI,YAAA,CAMA,cAAA,CACA,iBAAA,CAEA,UAAA,CAEA,SAAA,CAEA,wBAAA,CACA,iBAAA,CAEA,YAAA,CAEA,aAAA,CACA,2BAAA,CAQA,0CAAA,CAEA,wBAAA,CACA,sBAAA,CACA,4BAAA,CA7BA,sBACI,aAAA,CAkBJ,gBACI,qBAAA,CACA,kBAAA,CACA,kBAAA,CASJ,qBACI,KACI,SAAA,CACA,OAAA,CAEJ,GACI,SAAA,CACA,QAAA,CAAA,CAIR,qBACI,iBAAA,CACA,UAAA,CACA,QAAA,CACA,cAAA,CACA,UAAA,CAEA,wDAAA,CAEA,UAAA,CACA,WAAA,CAIJ,yBAEI,eAAA,CACA,gBAAA,CAEA,wEACI,oBAAA,CAEA,WAAA,CAEA,oBAAA,CACA,gBAAA,CAEA,iBAAA,CACA,0CAAA,CACA,qBAAA,CAEA,cAAA,CACA,aAAA,CACA,gBAAA,CACA,kBAAA,CAEA,cAAA,CAEA,oBAAA,CAEA,sFACI,cAAA,CACA,qBAAA,CAGJ,kFACI,wBAAA,CACA,UAAA,CAKZ,oBACI,wDAAA,CACA,2BAAA,CAEA,UAAA,CACA,WAAA,CAEA,kBAAA,CACA,iBAAA,CACA,cAAA,CAEA,oBAAA,CAGJ,oBAEI,oBAAA,CACA,WAAA,CAEA,2BACI,cAAA,CACA,eAAA,CACA,iBAAA,CAEJ,iCACI,cAAA,CACA,mBAAA","sourcesContent":[".ssBtnDefault {\n\t\n\tposition: absolute;\n\tz-index: 100000000;\n\tbackground:none;\n\tborder: none;\n\toutline: none;\n\tright:0;\n\tcursor: pointer;\n\t\n\twidth: 26px;\n\theight: 26px;\n\tmargin: 0;//5% 8px 0;\n\tpadding:0;\n\ttop:8px;\n\tright:8px;\n\t\n\topacity: .6;\n\tpointer-events: all;\n\t/*transition-fill-mode: forwards;*/\n    transition-duration: .25s;\n\n    &:hover {\n        opacity: 1 !important; \n        transition-duration: .25s;\n    }\n\n    .fade {\n        transition-duration: 5s;\n        opacity: 0;\n    }\n    \n    /*svg {\n        background-color:red;\n    }*/\n}\n\n.ssBtnYouTube {\n\n\tbackground:none;\n\tborder: none;\n\t\n\tmargin-right: 20px !important;\n    padding-top: 0px !important;\n    width: 25px !important;\n\n\t.ytp-embed & {\n\t\twidth: 20px !important;\n\t\tmargin-right: 15px !important;\n\t}\n}\n\n.ssBtnVimeo {\n\n\theight: 2rem !important;\n    width: 2rem !important;\n    //padding: 6px !important;\n    margin-top: 8px !important;\n\n\tbutton {\n\n\t\twidth: 100% !important;\n\t\theight: 100% !important;\n\t\t\n\t\tsvg {\n\t\t\twidth: 19px;\n\t\t}\n\t}\n\n}\n\n.ssBtnNetflix {\n\tbackground:none;\n\tborder: none;\n\tcursor: pointer;\n\n\twidth:4rem;\n\t\n\tmargin: 0 0.5rem;\n\t//margin: 0 2rem 0 4rem;\n\n\tdisplay:inline-block;\n\tflex-shrink: 0;\n\t\n\t//margin-top:-1rem;\n\t//height:2.4rem;\n\t//width: 50px;\n\t//height: 35px !important;\n\t//width: 100%;//3.6em !important;\n    //height: 100%;//1.6em !important;\n\t//padding:0 0 .6em 0;\n\n\t& > svg {\n\t\t//margin-top:-.3rem;\n\t\ttransform:translateY(-.3rem);\n\t\t//transform: scale(.5);\n\t}\n    \n    &:hover {\n        transform:scale(1.2);\n\t    transition-duration: .25s;\n    }\n}\n\n.ssBtnHulu {\n\t\n\twidth: 27px;\n\tmargin-top: 4px;\n\tmargin-right:10px;\n\topacity: .7;\n\tcursor: pointer;\n\t\n\t&:hover {\n\t\topacity: 1;\n\t}\n}\n\n.ssBtnAmazon {\n\tmargin-right: 1.5vw;\n    \n\toutline: none;\n\t\n   cursor: pointer;\n   opacity: .8;\n\n   //z-index: 9999999999;\n\n    &:hover {\n        opacity: 1;\n    }\n}\n\n@media (min-width: 1200px) { .ssBtnAmazon { width: 1.6666666666666665vw; height: 1.6666666666666665vw; } }\n@media (max-width: 1199px) { .ssBtnAmazon { width: 20px; height: 20px; } }\n\n\n.ssBtnHBO {\n\n    width: 48px;\n    height: 48px;\n    position: relative;\n    opacity: 0.7;\n    cursor: pointer;\n    display: flex;\n    justify-content: center;\n    align-items: center;\n\n\t&:hover {\n\t\topacity: 1;\n\t\ttransform: scale(1.2);\n\t}\n\n\tsvg {\n\t\twidth: 24px;\n\t\theight: 24px;\n\t}\n}\n\n.ssBtnDisney {\n\t//width: 26px;\n    //margin-right: 13px;\n    opacity: .7;\n\n\t&:hover {\n\t\topacity: 1;\n\t}\n\n\tsvg {\n\t\twidth: 25px !important;\n\t\theight: 31px !important;\n\t\tpadding-top: 4px;\n\t\tmargin-right: 7px;\n\t}\n}\n\n.ssBtnApple {\n\t//width: 26px;\n    //margin-right: 13px;\n\n\tcursor: pointer;\n\n\n    opacity: .7;\n\n\t&:hover {\n\t\topacity: 1;\n\t}\n\n\tsvg {\n\t\twidth: 22px !important;\n\t\theight: 22px !important;\n\t\tmargin-right: 2px !important;\n\t}\n}","@import \"ScreenshotControl/buttons\";\n\nbody {\n\n\t#ssTempHolder {\n\t\tposition:fixed;\n\t\tz-index:1000000000000;\n\t\twidth:100%;\n\t\theight:100%;\n\t\ttop:0;\n\t\tpointer-events: none;\n\n\t\tvideo {\n\t\t\twidth:auto !important;\n\t\t\theight:auto !important;\n\t\t\tmax-width:100% !important;\n\t\t\tmax-height: 100% !important;\n\t\t\ttop: 0 !important;\n\t\t\tleft: 0 !important;\n\t\t\ttransform: none !important;\n\t\t}\n\t}\n\n\t&.ssTakeScreenshot {\n\t\t\n\t\t.ssElement {\n\t\t\tz-index: 100000000000 !important;\n\t\t}\n\t\t\n\t\t&.ssNetflix {\n\t\n\t\t\t[data-uia=video-canvas] {\n\t\t\t\tz-index: 10000000;\n\t\t\t}\n\t\t\t\n\t\t\tvideo {\n\t\t\t\tbackground-color: #000000;\n\t\t\t\t//height: auto !important;\n\t\t\t}\n\n\t\t\t.player-timedtext {\n\n\t\t\t\tdisplay:none !important;\n\t\t\t}\t\t\t\n\n\t\t\t&.showSubs {\n\t\t\t\t\n\t\t\t\t.player-timedtext {\n\n\t\t\t\t\tdisplay: block !important;\n\t\t\t\t\t//bottom: 10% !important;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t&.ssAmazon {\n\n\t\t\t.scalingVideoContainer {\n\t\t\t\tz-index: 99999999 !important;\n\t\t\t}\n\t\t}\n\n\t\t&.ssDisney {\n\n\t\t\t.btm-media-overlays-container {\n\t\t\t\tdisplay:none;\n\t\t\t}\n\n\t\t\t.dss-hls-subtitle-overlay {\n\t\t\t\tdisplay: none;\n\t\t\t}\n\n\t\t\t&.showSubs {\n\t\t\t\t\n\t\t\t\t.dss-hls-subtitle-overlay {\n\t\t\t\t\tdisplay: block;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t&.ssHulu {\n\t\t\t.ContentPlayer__contentArea {\n\t\t\t\tz-index: 10000000000;\n    \t\t\tposition: relative;\n\t\t\t}\n\n\t\t\t.ClosedCaption {\n\t\t\t\tdisplay:none;\n\t\t\t}\n\n\t\t\t&.showSubs {\n\t\t\t\t.ClosedCaption {\n\t\t\t\t\tdisplay:block;\n\n\t\t\t\t\t.ClosedCaption__outband {\n\t\t\t\t\t\tbottom: 30px !important;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t&.ssHBO {\n\n\t\t\tvideo {\n\t\t\t\tz-index: 99999999;\n\t\t\t}\n\n\t\t\t*:has(video) {\n\t\t\t\tz-index: 99999999;\n\t\t\t}\n\n\t\t}\n\n\t\t&.ssYoutube {\n\n\t\t\t.html5-video-container, .ytp-caption-window-container {\n\t\t\t\tz-index: 999999999 !important;\n\t\t\t}\n\t\t}\n\n\t\t&.ssApple {\n\t\t\t#apple-music-video-player {\n\t\t\t\tz-index: 999999999 !important;\n\t\t\t}\n\n\t\t\t.scrim {\n\t\t\t\tdisplay:none;\n\t\t\t}\n\t\t}\n\t}\n\n\t.ssWrapper {\n\t\toverflow: hidden;\n\t}\n\n\t@import \"ScreenshotControl/notifications\";\n\t@import \"ScreenshotControl/modal\";\n}",".ssNotification {\n\n    display: flex;\n    width: 100%;\n    height: 4rem;\n    justify-content: center;\n    align-items: center;\n    position: fixed;\n    z-index: 1000000000;\n    top:-4rem;\n\n    animation-name: notification;\n    animation-duration: 2s;\n    animation-iteration-count: 1;\n\n    @keyframes notification {\n        0% {top: -4rem;}\n        25% {top: 3rem;}\n        85% {top: 3rem;}\n    }\n\n    .ssNContent {\n        //content: 'Screenshot copied to clipboard!';\n        position: absolute;\n        z-index: 1000000000;\n        padding: .75rem 1.25em;\n        margin-bottom: 1em;\n        border: 1px solid transparent;\n        border-radius: .25em;\n        font-size: 12px;\n        height: fit-content;\n        top:0;\n\n        &.success {\n            background-color: #d4edda;\n            border-color: #c3e6cb;\n            color: #155724;\n        }\n    \n        &.fail {\n            background-color: #edd4d4;\n            border-color: #e6c3c3;\n            color: #b62424;\n        }\n    }\n\n}",".ssModal {\n\n    display: none;\n\n    &.visible {\n        display:block;\n    }\n\n    position: fixed;\n    z-index: 100000000;\n\n    right:20px;\n    \n    opacity: 0;\n\n    background-color:#fffefa;\n    border-radius: 3px;\n\n    padding: 25px;\n\n    color: #525252;\n    font-family: muli, sans-serif;\n    \n    * {\n        vertical-align: middle;\n        line-height: normal;\n        font-weight: normal;\n    }\n\n    box-shadow: 0px 4px 8px 0px rgba(0, 0, 0, 0.15);\n\n    animation-name: animateOn;\n    animation-duration: .2s;\n    animation-fill-mode: forwards;\n\n    @keyframes animateOn {\n        from {\n            opacity: 0;\n            top: 0px;\n        }\n        to {\n            opacity: 1;\n            top: 20px;\n        }\n    }\n\n    .close {\n        position: absolute;\n        right: 10px;\n        top: 10px;\n        cursor: pointer;\n        opacity: .5;\n\n        background-image: url('../images/close.svg');\n\n        width:10px;\n        height:10px;\n\n    }\n\n    .ssButtons {\n\n        margin-top: 25px;\n        text-align: right;\n\n        .ssButton, a .ssButton {\n            display:inline-block;\n\n            height:20px;\n            \n            padding:3px 12px 3px;\n            margin-left: 14px;\n            \n            border-radius: 4px;\n            box-shadow: 0px 4px 8px 0px rgba(0, 0, 0, 0.15);\n            background-color: #FFFFFF;\n            \n            font-size: 12px;\n            color: #525252;\n            line-height: 20px;\n            font-weight: normal;\n    \n            cursor: pointer;\n\n            text-decoration: none;\n\n            .emoji {\n                font-size: 15px;\n                vertical-align: bottom;\n            }\n    \n            &.blue {\n                background-color: #19acef;\n                color: #FFFFFF;\n            }\n        }\n    }\n\n    .icon {\n        background-image: url('../images/iconBlue.svg');\n        background-repeat: no-repeat;\n\n        width:30px;\n        height:30px;\n\n        vertical-align: top;\n        margin-right: 22px;\n        margin-top:2px;\n\n        display:inline-block;\n    }\n\n    .body {\n\n        display:inline-block;\n        width:315px;\n\n        .title {\n            font-size: 15px;\n            font-weight: 600;\n            margin-bottom: 7px;\n        }\n        .description {\n            font-size: 13px;\n            font-weight: lighter;\n        }\n    }\n\n}"],"sourceRoot":""} */</style><style id="ms-consent-banner-main-styles">.w8hcgFksdo30C8w-bygqu{color:#000}.ydkKdaztSS0AeHWIeIHsQ a{color:#0067B8}.erL690_8JwUW-R4bJRcfl{background-color:#EBEBEB;border:none;color:#000}.erL690_8JwUW-R4bJRcfl:enabled:hover{color:#000;background-color:#DBDBDB;box-shadow:0px 4px 10px rgba(0,0,0,0.25);border:none}.erL690_8JwUW-R4bJRcfl:enabled:focus{background-color:#DBDBDB;box-shadow:0px 4px 10px rgba(0,0,0,0.25);border:2px solid #000}.erL690_8JwUW-R4bJRcfl:disabled{opacity:1;color:rgba(0,0,0,0.2);background-color:rgba(0,0,0,0.2);border:none}._1zNQOqxpBFSokeCLGi_hGr{border:none;background-color:#0067B8;color:#fff}._1zNQOqxpBFSokeCLGi_hGr:enabled:hover{color:#fff;background-color:#0067B8;box-shadow:0px 4px 10px rgba(0,0,0,0.25);border:none}._1zNQOqxpBFSokeCLGi_hGr:enabled:focus{background-color:#0067B8;box-shadow:0px 4px 10px rgba(0,0,0,0.25);border:2px solid #000}._1zNQOqxpBFSokeCLGi_hGr:disabled{opacity:1;color:rgba(0,0,0,0.2);background-color:rgba(0,120,215,0.2);border:none}._23tra1HsiiP6cT-Cka-ycB{position:relative;display:flex;z-index:9999;width:100%;background-color:#F2F2F2;justify-content:space-between;text-align:left}div[dir="rtl"]._23tra1HsiiP6cT-Cka-ycB{text-align:right}._1Upc2NjY8AlDn177YoVj0y{margin:0;padding-left:5%;padding-top:8px;padding-bottom:8px}div[dir="rtl"] ._1Upc2NjY8AlDn177YoVj0y{margin:0;padding:8px 5% 8px 0;float:none}._23tra1HsiiP6cT-Cka-ycB svg{fill:none;max-width:none;max-height:none}._1V_hlU-7jdtPiooHMu89BB{display:table-cell;padding:12px;width:24px;height:24px;font-family:Segoe UI, SegoeUI, Arial, sans-serif;font-style:normal;font-weight:normal;font-size:24px;line-height:0}.f6QKJD7fhSbnJLarTL-W-{display:table-cell;vertical-align:middle;padding:0;font-family:Segoe UI, SegoeUI, Arial, sans-serif;font-style:normal;font-weight:normal;font-size:13px;line-height:16px}.f6QKJD7fhSbnJLarTL-W- a{text-decoration:underline}._2j0fmugLb1FgYz6KPuB91w{display:inline-block;margin-left:5%;margin-right:5%;min-width:40%;min-width:calc((150px + 3 * 4px) * 2 + 150px);min-width:-webkit-fit-content;min-width:-moz-fit-content;min-width:fit-content;align-self:center;position:relative}._1XuCi2WhiqeWRUVp3pnFG3{margin:4px;padding:5px;min-width:150px;min-height:36px;vertical-align:top;cursor:pointer;font-family:Segoe UI, SegoeUI, Arial, sans-serif;font-style:normal;font-weight:normal;font-size:15px;line-height:20px;text-align:center}._1XuCi2WhiqeWRUVp3pnFG3:focus{box-sizing:border-box}._1XuCi2WhiqeWRUVp3pnFG3:disabled{cursor:not-allowed}._2bvsb3ubApyZ0UGoQA9O9T{display:block;position:fixed;z-index:10000;top:0;left:0;width:100%;height:100%;background-color:rgba(255,255,255,0.6);overflow:auto;text-align:left}div[dir="rtl"]._2bvsb3ubApyZ0UGoQA9O9T{text-align:right}div[dir="rtl"] ._2bvsb3ubApyZ0UGoQA9O9T{left:auto;right:0}.AFsJE948muYyzCMktdzuk{position:relative;top:8%;margin-bottom:40px;margin-left:auto;margin-right:auto;box-sizing:border-box;width:640px;background-color:#fff;border:1px solid #0067B8}._3kWyBRbW_dgnMiEyx06Fu4{float:right;z-index:1;margin:2px;padding:12px;border:none;cursor:pointer;font-family:Segoe UI, SegoeUI, Arial, sans-serif;font-style:normal;font-weight:normal;font-size:13px;line-height:13px;display:flex;align-items:center;text-align:center;color:#666;background-color:#fff}div[dir="rtl"] ._3kWyBRbW_dgnMiEyx06Fu4{margin:2px;padding:12px;float:left}.uCYvKvHXrhjNgflv1VqdD{position:static;margin-top:36px;margin-left:36px;margin-right:36px}._17pX1m9O_W--iZbDt3Ta5r{margin-top:0;margin-bottom:12px;font-family:Segoe UI, SegoeUI, Arial, sans-serif;font-style:normal;font-weight:600;font-size:20px;line-height:24px;text-transform:none}._1kBkHQ1V1wu3kl-YcLgUr6{height:446px;overflow:auto}._20_nXDf6uFs9Q6wxRXG-I-{margin-top:0;font-family:Segoe UI, SegoeUI, Arial, sans-serif;font-style:normal;font-weight:normal;font-size:15px;line-height:20px}._20_nXDf6uFs9Q6wxRXG-I- a{text-decoration:underline}dl._2a0NH_GDQEQe5Ynfo7suVH{margin-top:36px;margin-bottom:0;padding:0;list-style:none;text-transform:none}dt._3j_LCPv7fyXv3A8FIXVwZ4{margin-top:20px;float:none;font-family:Segoe UI, SegoeUI, Arial, sans-serif;font-style:normal;font-weight:600;font-size:18px;line-height:24px;list-style:none}.k-vxTGFbdq1aOZB2HHpjh{margin:0;padding:0;border:none}._2Bucyy75c_ogoU1g-liB5R{margin:0;padding:0;border-bottom:none;font-family:Segoe UI, SegoeUI, Arial, sans-serif;font-style:normal;font-weight:600;font-size:18px;line-height:24px;text-transform:none}._63gwfzV8dclrsl2cfd90r{display:inline-block;margin-top:0;margin-bottom:13px;font-family:Segoe UI, SegoeUI, Arial, sans-serif;font-style:normal;font-weight:normal;font-size:15px;line-height:20px}._1l8wM_4mRYGz3Iu7l3BZR7{display:block}._2UE03QS02aZGkslegN_F-i{display:inline-block;position:relative;left:5px;margin-bottom:13px;margin-right:34px;padding:3px}div[dir="rtl"] ._2UE03QS02aZGkslegN_F-i{margin:0 0 13px 34px;padding:3px;float:none}div[dir="rtl"] ._2UE03QS02aZGkslegN_F-i{left:auto;right:5px}._23tra1HsiiP6cT-Cka-ycB *::before,._2bvsb3ubApyZ0UGoQA9O9T *::before,._23tra1HsiiP6cT-Cka-ycB *::after,._2bvsb3ubApyZ0UGoQA9O9T *::after{box-sizing:inherit}._1HSFn0HzGo6w4ADApV8-c4{outline:2px solid rgba(0,0,0,0.8)}input[type="radio"]._1dp8Vp5m3HwAqGx8qBmFV2{display:inline-block;position:relative;margin-top:0;margin-left:0;margin-right:0;height:0;width:0;border-radius:0;cursor:pointer;outline:none;box-sizing:border-box;-webkit-appearance:none;-moz-appearance:none;appearance:none}input[type="radio"]._1dp8Vp5m3HwAqGx8qBmFV2+label::before{display:block;position:absolute;top:5px;left:3px;height:19px;width:19px;content:"";border-radius:50%;border:1px solid #000;background-color:#fff}div[dir="rtl"] input[type="radio"]._1dp8Vp5m3HwAqGx8qBmFV2+label::before{left:auto;right:3px}input[type="radio"]._1dp8Vp5m3HwAqGx8qBmFV2:not(:disabled)+label:hover::before{border:1px solid #0067B8}input[type="radio"]._1dp8Vp5m3HwAqGx8qBmFV2:not(:disabled)+label:hover::after{display:block;position:absolute;top:10px;left:8px;height:9px;width:9px;content:"";border-radius:50%;background-color:rgba(0,0,0,0.8)}div[dir="rtl"] input[type="radio"]._1dp8Vp5m3HwAqGx8qBmFV2:not(:disabled)+label:hover::after{left:auto;right:8px}input[type="radio"]._1dp8Vp5m3HwAqGx8qBmFV2:not(:disabled)+label:focus::before{border:1px solid #0067B8}input[type="radio"]._1dp8Vp5m3HwAqGx8qBmFV2:not(:disabled)+label:focus::after{display:block;position:absolute;top:10px;left:8px;height:9px;width:9px;content:"";border-radius:50%;background-color:#000}div[dir="rtl"] input[type="radio"]._1dp8Vp5m3HwAqGx8qBmFV2:not(:disabled)+label:focus::after{left:auto;right:8px}input[type="radio"]._1dp8Vp5m3HwAqGx8qBmFV2:checked+label::after{display:block;position:absolute;top:10px;left:8px;height:9px;width:9px;content:"";border-radius:50%;background-color:#000}div[dir="rtl"] input[type="radio"]._1dp8Vp5m3HwAqGx8qBmFV2:checked+label::after{left:auto;right:8px}input[type="radio"]._1dp8Vp5m3HwAqGx8qBmFV2:disabled+label{cursor:not-allowed}input[type="radio"]._1dp8Vp5m3HwAqGx8qBmFV2:disabled+label::before{border:1px solid rgba(0,0,0,0.2);background-color:rgba(0,0,0,0.2)}._3RJzeL3l9Rl_lAQEm6VwdX{display:block;position:static;float:right;margin-top:0;margin-bottom:0;margin-left:19px;margin-right:0;padding-top:0;padding-bottom:0;padding-left:8px;padding-right:0;width:80%;width:calc(100% - 19px);font-family:Segoe UI, SegoeUI, Arial, sans-serif;font-style:normal;font-weight:normal;font-size:15px;line-height:20px;text-transform:none;cursor:pointer;box-sizing:border-box}div[dir="rtl"] ._3RJzeL3l9Rl_lAQEm6VwdX{margin:0 19px 0 0;padding:0 8px 0 0;float:left}.nohp3sIG12ZBhzcMnPala{margin-top:20px;margin-bottom:48px}._2uhaEsmeotZ3P-M0AXo2kF{padding:0;width:278px;height:36px;cursor:pointer;font-family:Segoe UI, SegoeUI, Arial, sans-serif;font-style:normal;font-weight:normal;font-size:15px;line-height:20px;text-align:center}._2uhaEsmeotZ3P-M0AXo2kF:focus{box-sizing:border-box}._2uhaEsmeotZ3P-M0AXo2kF:disabled{cursor:not-allowed}._3tOu1FJ59c_xz_PmI1lKV5{float:right;padding:0;width:278px;height:36px;cursor:pointer;font-family:Segoe UI, SegoeUI, Arial, sans-serif;font-style:normal;font-weight:normal;font-size:15px;line-height:20px;text-align:center}._3tOu1FJ59c_xz_PmI1lKV5:focus{box-sizing:border-box}._3tOu1FJ59c_xz_PmI1lKV5:disabled{cursor:not-allowed}div[dir="rtl"] ._3tOu1FJ59c_xz_PmI1lKV5{margin:0;padding:0;float:left}@media only screen and (max-width: 768px){._2j0fmugLb1FgYz6KPuB91w,._1Upc2NjY8AlDn177YoVj0y{padding-top:8px;padding-bottom:12px;padding-left:3.75%;padding-right:3.75%;margin:0;width:92.5%}._23tra1HsiiP6cT-Cka-ycB{display:block}._1XuCi2WhiqeWRUVp3pnFG3{margin-bottom:8px;margin-left:0;margin-right:0;width:100%}._2bvsb3ubApyZ0UGoQA9O9T{overflow:hidden}.AFsJE948muYyzCMktdzuk{top:1.8%;width:93.33%;height:96.4%;overflow:hidden}.uCYvKvHXrhjNgflv1VqdD{margin-top:24px;margin-left:24px;margin-right:24px;height:100%}._1kBkHQ1V1wu3kl-YcLgUr6{height:62%;height:calc(100% - 188px);min-height:50%}._2uhaEsmeotZ3P-M0AXo2kF{width:100%}._3tOu1FJ59c_xz_PmI1lKV5{margin-bottom:12px;margin-left:0;width:100%}div[dir="rtl"] ._3tOu1FJ59c_xz_PmI1lKV5{margin:0 0 12px 0;padding:0;float:none}}@media only screen and (max-width: 768px) and (orientation: landscape), only screen and (max-height: 260px), only screen and (max-width: 340px){.AFsJE948muYyzCMktdzuk{overflow:auto}}@media only screen and (max-height: 260px), only screen and (max-width: 340px){._1XuCi2WhiqeWRUVp3pnFG3{min-width:0}._3kWyBRbW_dgnMiEyx06Fu4{padding:3%}.uCYvKvHXrhjNgflv1VqdD{margin-top:3%;margin-left:3%;margin-right:3%}._17pX1m9O_W--iZbDt3Ta5r{margin-bottom:3%}._1kBkHQ1V1wu3kl-YcLgUr6{height:calc(79% - 64px)}.nohp3sIG12ZBhzcMnPala{margin-top:5%;margin-bottom:10%}._3tOu1FJ59c_xz_PmI1lKV5{margin-bottom:3%}div[dir="rtl"] ._3tOu1FJ59c_xz_PmI1lKV5{margin:0 0 3% 0;padding:0;float:none}}
</style><style type="text/css" id="ms-consent-banner-theme-styles">._23tra1HsiiP6cT-Cka-ycB {
            background-color: #24292f !important;
        }.w8hcgFksdo30C8w-bygqu {
            color: #ffffff !important;
        }.ydkKdaztSS0AeHWIeIHsQ a {
            color: #d8b9ff !important;
        }._2bvsb3ubApyZ0UGoQA9O9T {
            background-color: rgba(23, 23, 23, 0.8) !important;
        }.AFsJE948muYyzCMktdzuk {
            background-color: #24292f !important;
            border: 1px solid #d8b9ff !important;
        }._3kWyBRbW_dgnMiEyx06Fu4 {
            color: #d8b9ff !important;
            background-color: #24292f !important;
        }._1zNQOqxpBFSokeCLGi_hGr {
            border: 1px solid #ffffff !important;
            background-color: #ffffff !important;
            color: #1f2328 !important;
        }._1zNQOqxpBFSokeCLGi_hGr:enabled:hover {
            color: #1f2328 !important;
            background-color: #d8b9ff !important;
            box-shadow: none !important;
            border: 1px solid transparent !important;
        }._1zNQOqxpBFSokeCLGi_hGr:enabled:focus {
            background-color: #d8b9ff !important;
            box-shadow: none !important;
            border: 2px solid #ffffff !important;
        }._1zNQOqxpBFSokeCLGi_hGr:disabled {
            opacity: 0.5 !important;
            color: #1f2328 !important;
            background-color: #ffffff !important;
            border: 1px solid transparent !important;
        }.erL690_8JwUW-R4bJRcfl {
            border: 1px solid #eaeef2 !important;
            background-color: #32383f !important;
            color: #ffffff !important;
        }.erL690_8JwUW-R4bJRcfl:enabled:hover {
            color: #ffffff !important;
            background-color: #24292f !important;
            box-shadow: none !important;
            border: 1px solid #ffffff !important;
        }.erL690_8JwUW-R4bJRcfl:enabled:focus {
            background-color: #24292f !important;
            box-shadow: none !important;
            border: 2px solid #6e7781 !important;
        }.erL690_8JwUW-R4bJRcfl:disabled {
            opacity: 0.5 !important;
            color: #ffffff !important;
            background-color: #424a53 !important;
            border: 1px solid #6e7781 !important;
        }input[type="radio"]._1dp8Vp5m3HwAqGx8qBmFV2 + label::before {
            border: 1px solid #d8b9ff !important;
            background-color: #24292f !important;
        }._1HSFn0HzGo6w4ADApV8-c4 {
            outline: 2px solid #ffffff !important;
        }input[type="radio"]._1dp8Vp5m3HwAqGx8qBmFV2:checked + label::after {
            background-color: #d8b9ff !important;
        }input[type="radio"]._1dp8Vp5m3HwAqGx8qBmFV2 + label:hover::before {
            border: 1px solid #ffffff !important;
        }input[type="radio"]._1dp8Vp5m3HwAqGx8qBmFV2 + label:hover::after {
            background-color: #ffffff !important;
        }input[type="radio"]._1dp8Vp5m3HwAqGx8qBmFV2 + label:focus::before {
            border: 1px solid #ffffff !important;
        }input[type="radio"]._1dp8Vp5m3HwAqGx8qBmFV2 + label:focus::after {
            background-color: #d8b9ff !important;
        }input[type="radio"]._1dp8Vp5m3HwAqGx8qBmFV2:disabled + label::before {
            border: 1px solid rgba(227, 227, 227, 0.2) !important;
            background-color: rgba(227, 227, 227, 0.2) !important;
        }</style></head>

  <body class="logged-in env-production page-responsive" style="overflow-wrap: break-word; --dialog-scrollgutter: 17px;">
    <div data-turbo-body="" class="logged-in env-production page-responsive" style="word-wrap: break-word;">
      


    <div class="position-relative js-header-wrapper ">
      <a href="https://github.com/mrdbourke/tensorflow-deep-learning#start-of-content" data-skip-target-assigned="false" class="p-3 color-bg-accent-emphasis color-fg-on-emphasis show-on-focus js-skip-to-content">Skip to content</a>

      <span data-view-component="true" class="progress-pjax-loader Progress position-fixed width-full">
    <span style="width: 0%;" data-view-component="true" class="Progress-item progress-pjax-loader-bar left-0 top-0 color-bg-accent-emphasis"></span>
</span>      
      
      <script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_Dialog_Dialog_js-node_m.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/keyboard-shortcuts-dialog-15a4cf222dbb.js.download"></script>

<react-partial partial-name="keyboard-shortcuts-dialog" data-ssr="false" data-catalyst="" class="loaded">
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{"docsUrl":"https://docs.github.com/get-started/accessibility/keyboard-shortcuts"}}</script>
  <div data-target="react-partial.reactRoot"><script type="application/json" id="__PRIMER_DATA_:r7:__">{"resolvedServerColorMode":"day"}</script></div>
</react-partial>




      

          

                <header class="AppHeader" role="banner">
  <h2 class="sr-only">Navigation Menu</h2>

    

    <div class="AppHeader-globalBar pb-2 js-global-bar">
      <div class="AppHeader-globalBar-start">
          <deferred-side-panel data-url="/_side-panels/global" data-catalyst="">
  <include-fragment data-target="deferred-side-panel.fragment"><template shadowrootmode="open"><style>:host {display: block;}</style><slot></slot></template>
      <button aria-label="Open global navigation menu" data-action="click:deferred-side-panel#loadPanel click:deferred-side-panel#panelOpened" data-show-dialog-id="dialog-ab083822-3ecb-47fd-b950-fd4177344ef1" id="dialog-show-dialog-ab083822-3ecb-47fd-b950-fd4177344ef1" type="button" data-view-component="true" class="Button Button--iconOnly Button--secondary Button--medium AppHeader-button color-bg-transparent p-0 color-fg-muted">  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-three-bars Button-visual">
    <path d="M1 2.75A.75.75 0 0 1 1.75 2h12.5a.75.75 0 0 1 0 1.5H1.75A.75.75 0 0 1 1 2.75Zm0 5A.75.75 0 0 1 1.75 7h12.5a.75.75 0 0 1 0 1.5H1.75A.75.75 0 0 1 1 7.75ZM1.75 12h12.5a.75.75 0 0 1 0 1.5H1.75a.75.75 0 0 1 0-1.5Z"></path>
</svg>
</button>

<dialog-helper>
  <dialog data-target="deferred-side-panel.panel" id="dialog-ab083822-3ecb-47fd-b950-fd4177344ef1" aria-modal="true" aria-labelledby="dialog-ab083822-3ecb-47fd-b950-fd4177344ef1-title" aria-describedby="dialog-ab083822-3ecb-47fd-b950-fd4177344ef1-description" data-view-component="true" class="Overlay Overlay-whenNarrow Overlay--size-small-portrait Overlay--motion-scaleFade Overlay--placement-left SidePanel">
    <div styles="flex-direction: row;" data-view-component="true" class="Overlay-header">
  <div class="Overlay-headerContentWrap">
    <div class="Overlay-titleWrap">
      <h1 class="Overlay-title sr-only" id="dialog-ab083822-3ecb-47fd-b950-fd4177344ef1-title">
        Global navigation
      </h1>
            <div data-view-component="true" class="d-flex">
      <div data-view-component="true" class="AppHeader-logo position-relative">
        <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-mark-github">
    <path d="M12.5.75C6.146.75 1 5.896 1 12.25c0 5.089 3.292 9.387 7.863 10.91.575.101.79-.244.79-.546 0-.273-.014-1.178-.014-2.142-2.889.532-3.636-.704-3.866-1.35-.13-.331-.69-1.352-1.18-1.625-.402-.216-.977-.748-.014-.762.906-.014 1.553.834 1.769 1.179 1.035 1.74 2.688 1.25 3.349.948.1-.747.402-1.25.733-1.538-2.559-.287-5.232-1.279-5.232-5.678 0-1.25.445-2.285 1.178-3.09-.115-.288-.517-1.467.115-3.048 0 0 .963-.302 3.163 1.179.92-.259 1.897-.388 2.875-.388.977 0 1.955.13 2.875.388 2.2-1.495 3.162-1.179 3.162-1.179.633 1.581.23 2.76.115 3.048.733.805 1.179 1.825 1.179 3.09 0 4.413-2.688 5.39-5.247 5.678.417.36.776 1.05.776 2.128 0 1.538-.014 2.774-.014 3.162 0 .302.216.662.79.547C20.709 21.637 24 17.324 24 12.25 24 5.896 18.854.75 12.5.75Z"></path>
</svg>
</div></div>
    </div>
    <div class="Overlay-actionWrap">
      <button data-close-dialog-id="dialog-ab083822-3ecb-47fd-b950-fd4177344ef1" aria-label="Close" type="button" data-view-component="true" class="close-button Overlay-closeButton"><svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg></button>
    </div>
  </div>
  
</div>
      <scrollable-region data-labelled-by="dialog-ab083822-3ecb-47fd-b950-fd4177344ef1-title" data-catalyst="" style="overflow: auto;">
        <div data-view-component="true" class="Overlay-body d-flex flex-column px-2">    <div data-view-component="true" class="d-flex flex-column mb-3">
        <nav aria-label="Site navigation" data-view-component="true" class="ActionList">
  
  <nav-list data-catalyst="">
    <ul data-target="nav-list.topLevelList" data-view-component="true" class="ActionListWrap">
        
          
<li data-item-id="" data-targets="nav-list.items" data-view-component="true" class="ActionListItem">
    
    
    <a data-hotkey="g d" data-analytics-event="{&quot;category&quot;:&quot;Global navigation&quot;,&quot;action&quot;:&quot;HOME&quot;,&quot;label&quot;:null}" id="item-234cd776-df94-44f5-9663-a048dd1610ec" href="https://github.com/dashboard" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-home">
    <path d="M6.906.664a1.749 1.749 0 0 1 2.187 0l5.25 4.2c.415.332.657.835.657 1.367v7.019A1.75 1.75 0 0 1 13.25 15h-3.5a.75.75 0 0 1-.75-.75V9H7v5.25a.75.75 0 0 1-.75.75h-3.5A1.75 1.75 0 0 1 1 13.25V6.23c0-.531.242-1.034.657-1.366l5.25-4.2Zm1.25 1.171a.25.25 0 0 0-.312 0l-5.25 4.2a.25.25 0 0 0-.094.196v7.019c0 .138.112.25.25.25H5.5V8.25a.75.75 0 0 1 .75-.75h3.5a.75.75 0 0 1 .75.75v5.25h2.75a.25.25 0 0 0 .25-.25V6.23a.25.25 0 0 0-.094-.195Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Home
</span>      
</a>
  
</li>

        
          
<li data-item-id="" data-targets="nav-list.items" data-view-component="true" class="ActionListItem">
    
    
    <a data-hotkey="g i" data-analytics-event="{&quot;category&quot;:&quot;Global navigation&quot;,&quot;action&quot;:&quot;ISSUES&quot;,&quot;label&quot;:null}" id="item-3247bbd4-4939-4bf8-a05e-1e0223c41cc2" href="https://github.com/issues" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-issue-opened">
    <path d="M8 9.5a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z"></path><path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Issues
</span>      
</a>
  
</li>

        
          
<li data-item-id="" data-targets="nav-list.items" data-view-component="true" class="ActionListItem">
    
    
    <a data-hotkey="g p" data-analytics-event="{&quot;category&quot;:&quot;Global navigation&quot;,&quot;action&quot;:&quot;PULL_REQUESTS&quot;,&quot;label&quot;:null}" id="item-08854c65-0b57-4267-b287-7b41b464ded5" href="https://github.com/pulls" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-git-pull-request">
    <path d="M1.5 3.25a2.25 2.25 0 1 1 3 2.122v5.256a2.251 2.251 0 1 1-1.5 0V5.372A2.25 2.25 0 0 1 1.5 3.25Zm5.677-.177L9.573.677A.25.25 0 0 1 10 .854V2.5h1A2.5 2.5 0 0 1 13.5 5v5.628a2.251 2.251 0 1 1-1.5 0V5a1 1 0 0 0-1-1h-1v1.646a.25.25 0 0 1-.427.177L7.177 3.427a.25.25 0 0 1 0-.354ZM3.75 2.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm0 9.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm8.25.75a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Pull requests
</span>      
</a>
  
</li>

        
          
<li data-item-id="" data-targets="nav-list.items" data-view-component="true" class="ActionListItem">
    
    
    <a data-analytics-event="{&quot;category&quot;:&quot;Global navigation&quot;,&quot;action&quot;:&quot;PROJECTS&quot;,&quot;label&quot;:null}" id="item-6dd871a2-56f8-4f75-9611-9179cba4ac42" href="https://github.com/projects" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-table">
    <path d="M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25ZM6.5 6.5v8h7.75a.25.25 0 0 0 .25-.25V6.5Zm8-1.5V1.75a.25.25 0 0 0-.25-.25H6.5V5Zm-13 1.5v7.75c0 .138.112.25.25.25H5v-8ZM5 5V1.5H1.75a.25.25 0 0 0-.25.25V5Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Projects
</span>      
</a>
  
</li>

        
          
<li data-item-id="" data-targets="nav-list.items" data-view-component="true" class="ActionListItem">
    
    
    <a data-analytics-event="{&quot;category&quot;:&quot;Global navigation&quot;,&quot;action&quot;:&quot;DISCUSSIONS&quot;,&quot;label&quot;:null}" id="item-06b3f886-6749-4846-975d-d4fd7672c6af" href="https://github.com/discussions" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-comment-discussion">
    <path d="M1.75 1h8.5c.966 0 1.75.784 1.75 1.75v5.5A1.75 1.75 0 0 1 10.25 10H7.061l-2.574 2.573A1.458 1.458 0 0 1 2 11.543V10h-.25A1.75 1.75 0 0 1 0 8.25v-5.5C0 1.784.784 1 1.75 1ZM1.5 2.75v5.5c0 .138.112.25.25.25h1a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h3.5a.25.25 0 0 0 .25-.25v-5.5a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25Zm13 2a.25.25 0 0 0-.25-.25h-.5a.75.75 0 0 1 0-1.5h.5c.966 0 1.75.784 1.75 1.75v5.5A1.75 1.75 0 0 1 14.25 12H14v1.543a1.458 1.458 0 0 1-2.487 1.03L9.22 12.28a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215l2.22 2.22v-2.19a.75.75 0 0 1 .75-.75h1a.25.25 0 0 0 .25-.25Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Discussions
</span>      
</a>
  
</li>

        
          
<li data-item-id="" data-targets="nav-list.items" data-view-component="true" class="ActionListItem">
    
    
    <a data-analytics-event="{&quot;category&quot;:&quot;Global navigation&quot;,&quot;action&quot;:&quot;CODESPACES&quot;,&quot;label&quot;:null}" id="item-e3a6db61-6a47-4a80-9ca7-4ba603b15563" href="https://github.com/codespaces" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-codespaces">
    <path d="M0 11.25c0-.966.784-1.75 1.75-1.75h12.5c.966 0 1.75.784 1.75 1.75v3A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25Zm2-9.5C2 .784 2.784 0 3.75 0h8.5C13.216 0 14 .784 14 1.75v5a1.75 1.75 0 0 1-1.75 1.75h-8.5A1.75 1.75 0 0 1 2 6.75Zm1.75-.25a.25.25 0 0 0-.25.25v5c0 .138.112.25.25.25h8.5a.25.25 0 0 0 .25-.25v-5a.25.25 0 0 0-.25-.25Zm-2 9.5a.25.25 0 0 0-.25.25v3c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-3a.25.25 0 0 0-.25-.25Z"></path><path d="M7 12.75a.75.75 0 0 1 .75-.75h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1-.75-.75Zm-4 0a.75.75 0 0 1 .75-.75h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1-.75-.75Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Codespaces
</span>      
</a>
  
</li>

        
          <li role="presentation" aria-hidden="true" data-view-component="true" class="ActionList-sectionDivider"></li>
        
          
<li data-item-id="" data-targets="nav-list.items" data-view-component="true" class="ActionListItem">
    
    
    <a data-analytics-event="{&quot;category&quot;:&quot;Global navigation&quot;,&quot;action&quot;:&quot;EXPLORE&quot;,&quot;label&quot;:null}" id="item-a0fb8e4f-3b95-4309-8921-25285ebba3fe" href="https://github.com/explore" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-telescope">
    <path d="M14.184 1.143v-.001l1.422 2.464a1.75 1.75 0 0 1-.757 2.451L3.104 11.713a1.75 1.75 0 0 1-2.275-.702l-.447-.775a1.75 1.75 0 0 1 .53-2.32L11.682.573a1.748 1.748 0 0 1 2.502.57Zm-4.709 9.32h-.001l2.644 3.863a.75.75 0 1 1-1.238.848l-1.881-2.75v2.826a.75.75 0 0 1-1.5 0v-2.826l-1.881 2.75a.75.75 0 1 1-1.238-.848l2.049-2.992a.746.746 0 0 1 .293-.253l1.809-.87a.749.749 0 0 1 .944.252ZM9.436 3.92h-.001l-4.97 3.39.942 1.63 5.42-2.61Zm3.091-2.108h.001l-1.85 1.26 1.505 2.605 2.016-.97a.247.247 0 0 0 .13-.151.247.247 0 0 0-.022-.199l-1.422-2.464a.253.253 0 0 0-.161-.119.254.254 0 0 0-.197.038ZM1.756 9.157a.25.25 0 0 0-.075.33l.447.775a.25.25 0 0 0 .325.1l1.598-.769-.83-1.436-1.465 1Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Explore
</span>      
</a>
  
</li>

        
          
<li data-item-id="" data-targets="nav-list.items" data-view-component="true" class="ActionListItem">
    
    
    <a data-analytics-event="{&quot;category&quot;:&quot;Global navigation&quot;,&quot;action&quot;:&quot;MARKETPLACE&quot;,&quot;label&quot;:null}" id="item-4aa7866a-52bb-4227-815a-94100453b407" href="https://github.com/marketplace" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-gift">
    <path d="M2 2.75A2.75 2.75 0 0 1 4.75 0c.983 0 1.873.42 2.57 1.232.268.318.497.668.68 1.042.183-.375.411-.725.68-1.044C9.376.42 10.266 0 11.25 0a2.75 2.75 0 0 1 2.45 4h.55c.966 0 1.75.784 1.75 1.75v2c0 .698-.409 1.301-1 1.582v4.918A1.75 1.75 0 0 1 13.25 16H2.75A1.75 1.75 0 0 1 1 14.25V9.332C.409 9.05 0 8.448 0 7.75v-2C0 4.784.784 4 1.75 4h.55c-.192-.375-.3-.8-.3-1.25ZM7.25 9.5H2.5v4.75c0 .138.112.25.25.25h4.5Zm1.5 0v5h4.5a.25.25 0 0 0 .25-.25V9.5Zm0-4V8h5.5a.25.25 0 0 0 .25-.25v-2a.25.25 0 0 0-.25-.25Zm-7 0a.25.25 0 0 0-.25.25v2c0 .138.112.25.25.25h5.5V5.5h-5.5Zm3-4a1.25 1.25 0 0 0 0 2.5h2.309c-.233-.818-.542-1.401-.878-1.793-.43-.502-.915-.707-1.431-.707ZM8.941 4h2.309a1.25 1.25 0 0 0 0-2.5c-.516 0-1 .205-1.43.707-.337.392-.646.975-.879 1.793Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Marketplace
</span>      
</a>
  
</li>

</ul>  </nav-list>
</nav>

        <div data-view-component="true" class="my-3 d-flex flex-justify-center height-full">
          <svg style="box-sizing: content-box; color: var(--color-icon-primary);" width="16" height="16" viewBox="0 0 16 16" fill="none" aria-hidden="true" data-view-component="true" class="anim-rotate">
  <circle cx="8" cy="8" r="7" stroke="currentColor" stroke-opacity="0.25" stroke-width="2" vector-effect="non-scaling-stroke" fill="none"></circle>
  <path d="M15 8a7.002 7.002 0 00-7-7" stroke="currentColor" stroke-width="2" stroke-linecap="round" vector-effect="non-scaling-stroke"></path>
</svg>  <span class="sr-only">Loading</span>

</div>
</div>
      <div data-view-component="true" class="flex-1"></div>


      <div data-view-component="true" class="px-2">      <p class="color-fg-subtle text-small text-light"> 2024 GitHub, Inc.</p>

      <div data-view-component="true" class="d-flex flex-wrap text-small text-light">
          <a target="_blank" href="https://github.com/about" data-view-component="true" class="Link mr-2">About</a>
          <a target="_blank" href="https://github.blog/" data-view-component="true" class="Link mr-2">Blog</a>
          <a target="_blank" href="https://docs.github.com/site-policy/github-terms/github-terms-of-service" data-view-component="true" class="Link mr-2">Terms</a>
          <a target="_blank" href="https://docs.github.com/site-policy/privacy-policies/github-privacy-statement" data-view-component="true" class="Link mr-2">Privacy</a>
          <a target="_blank" href="https://github.com/security" data-view-component="true" class="Link mr-2">Security</a>
          <a target="_blank" href="https://www.githubstatus.com/" data-view-component="true" class="Link mr-3">Status</a>

</div></div>
</div>
      </scrollable-region>
      
</dialog></dialog-helper>

  </include-fragment>
</deferred-side-panel>

        <a class="AppHeader-logo ml-2" href="https://github.com/" data-hotkey="g d" aria-label="Homepage " data-turbo="false" data-analytics-event="{&quot;category&quot;:&quot;Header&quot;,&quot;action&quot;:&quot;go to dashboard&quot;,&quot;label&quot;:&quot;icon:logo&quot;}">
          <svg height="32" aria-hidden="true" viewBox="0 0 24 24" version="1.1" width="32" data-view-component="true" class="octicon octicon-mark-github v-align-middle color-fg-default">
    <path d="M12.5.75C6.146.75 1 5.896 1 12.25c0 5.089 3.292 9.387 7.863 10.91.575.101.79-.244.79-.546 0-.273-.014-1.178-.014-2.142-2.889.532-3.636-.704-3.866-1.35-.13-.331-.69-1.352-1.18-1.625-.402-.216-.977-.748-.014-.762.906-.014 1.553.834 1.769 1.179 1.035 1.74 2.688 1.25 3.349.948.1-.747.402-1.25.733-1.538-2.559-.287-5.232-1.279-5.232-5.678 0-1.25.445-2.285 1.178-3.09-.115-.288-.517-1.467.115-3.048 0 0 .963-.302 3.163 1.179.92-.259 1.897-.388 2.875-.388.977 0 1.955.13 2.875.388 2.2-1.495 3.162-1.179 3.162-1.179.633 1.581.23 2.76.115 3.048.733.805 1.179 1.825 1.179 3.09 0 4.413-2.688 5.39-5.247 5.678.417.36.776 1.05.776 2.128 0 1.538-.014 2.774-.014 3.162 0 .302.216.662.79.547C20.709 21.637 24 17.324 24 12.25 24 5.896 18.854.75 12.5.75Z"></path>
</svg>
        </a>

          <div class="AppHeader-context">
  <div class="AppHeader-context-compact">
      <button aria-expanded="false" aria-haspopup="dialog" aria-label="Page context: mrdbourke / tensorflow-deep-learning" id="dialog-show-context-region-dialog" data-show-dialog-id="context-region-dialog" type="button" data-view-component="true" class="AppHeader-context-compact-trigger Truncate Button--secondary Button--medium Button box-shadow-none">  <span class="Button-content">
    <span class="Button-label"><span class="AppHeader-context-compact-lead">
                <span class="AppHeader-context-compact-parentItem">mrdbourke</span>
                <span class="no-wrap">&nbsp;/</span>

            </span>

            <strong class="AppHeader-context-compact-mainItem d-flex flex-items-center Truncate">
  <span class="Truncate-text ">tensorflow-deep-learning</span>

</strong></span>
  </span>
</button>

<dialog-helper>
  <dialog id="context-region-dialog" aria-modal="true" aria-labelledby="context-region-dialog-title" aria-describedby="context-region-dialog-description" data-view-component="true" class="Overlay Overlay-whenNarrow Overlay--size-medium Overlay--motion-scaleFade">
    <div data-view-component="true" class="Overlay-header">
  <div class="Overlay-headerContentWrap">
    <div class="Overlay-titleWrap">
      <h1 class="Overlay-title " id="context-region-dialog-title">
        Navigate back to
      </h1>
        
    </div>
    <div class="Overlay-actionWrap">
      <button data-close-dialog-id="context-region-dialog" aria-label="Close" type="button" data-view-component="true" class="close-button Overlay-closeButton"><svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg></button>
    </div>
  </div>
  
</div>
      <scrollable-region data-labelled-by="context-region-dialog-title" data-catalyst="" style="overflow: auto;">
        <div data-view-component="true" class="Overlay-body">          <ul role="list" class="list-style-none">
    <li>
      <a data-analytics-event="{&quot;category&quot;:&quot;SiteHeaderComponent&quot;,&quot;action&quot;:&quot;context_region_crumb&quot;,&quot;label&quot;:&quot;mrdbourke&quot;,&quot;screen_size&quot;:&quot;compact&quot;}" href="https://github.com/mrdbourke" data-view-component="true" class="Link--primary Truncate d-flex flex-items-center py-1">
        <span class="AppHeader-context-item-label Truncate-text ">
            <svg aria-hidden="true" height="12" viewBox="0 0 16 16" version="1.1" width="12" data-view-component="true" class="octicon octicon-person mr-1">
    <path d="M10.561 8.073a6.005 6.005 0 0 1 3.432 5.142.75.75 0 1 1-1.498.07 4.5 4.5 0 0 0-8.99 0 .75.75 0 0 1-1.498-.07 6.004 6.004 0 0 1 3.431-5.142 3.999 3.999 0 1 1 5.123 0ZM10.5 5a2.5 2.5 0 1 0-5 0 2.5 2.5 0 0 0 5 0Z"></path>
</svg>

          mrdbourke
        </span>

</a>
    </li>
    <li>
      <a data-analytics-event="{&quot;category&quot;:&quot;SiteHeaderComponent&quot;,&quot;action&quot;:&quot;context_region_crumb&quot;,&quot;label&quot;:&quot;tensorflow-deep-learning&quot;,&quot;screen_size&quot;:&quot;compact&quot;}" href="https://github.com/mrdbourke/tensorflow-deep-learning" aria-current="page" data-view-component="true" class="Link--primary Truncate d-flex flex-items-center py-1">
        <span class="AppHeader-context-item-label Truncate-text ">
            <svg aria-hidden="true" height="12" viewBox="0 0 16 16" version="1.1" width="12" data-view-component="true" class="octicon octicon-repo mr-1">
    <path d="M2 2.5A2.5 2.5 0 0 1 4.5 0h8.75a.75.75 0 0 1 .75.75v12.5a.75.75 0 0 1-.75.75h-2.5a.75.75 0 0 1 0-1.5h1.75v-2h-8a1 1 0 0 0-.714 1.7.75.75 0 1 1-1.072 1.05A2.495 2.495 0 0 1 2 11.5Zm10.5-1h-8a1 1 0 0 0-1 1v6.708A2.486 2.486 0 0 1 4.5 9h8ZM5 12.25a.25.25 0 0 1 .25-.25h3.5a.25.25 0 0 1 .25.25v3.25a.25.25 0 0 1-.4.2l-1.45-1.087a.249.249 0 0 0-.3 0L5.4 15.7a.25.25 0 0 1-.4-.2Z"></path>
</svg>

          tensorflow-deep-learning
        </span>

</a>
    </li>
</ul>

</div>
      </scrollable-region>
      
</dialog></dialog-helper>
  </div>

  <div class="AppHeader-context-full">
    <nav role="navigation" aria-label="Page context">
      <ul role="list" class="list-style-none">
    <li>
      <a data-analytics-event="{&quot;category&quot;:&quot;SiteHeaderComponent&quot;,&quot;action&quot;:&quot;context_region_crumb&quot;,&quot;label&quot;:&quot;mrdbourke&quot;,&quot;screen_size&quot;:&quot;full&quot;}" data-hovercard-type="user" data-hovercard-url="/users/mrdbourke/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/mrdbourke" data-view-component="true" class="AppHeader-context-item">
        <span class="AppHeader-context-item-label  ">

          mrdbourke
        </span>

</a>
        <span class="AppHeader-context-item-separator">/</span>
    </li>
    <li>
      <a data-analytics-event="{&quot;category&quot;:&quot;SiteHeaderComponent&quot;,&quot;action&quot;:&quot;context_region_crumb&quot;,&quot;label&quot;:&quot;tensorflow-deep-learning&quot;,&quot;screen_size&quot;:&quot;full&quot;}" href="https://github.com/mrdbourke/tensorflow-deep-learning" aria-current="page" data-view-component="true" class="AppHeader-context-item">
        <span class="AppHeader-context-item-label  ">

          tensorflow-deep-learning
        </span>

</a>
    </li>
</ul>

    </nav>
  </div>
</div>

      </div>
      <div class="AppHeader-globalBar-end">
          <div class="AppHeader-search">
              


<qbsearch-input class="search-input" data-scope="repo:mrdbourke/tensorflow-deep-learning" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="rBTl3Kwr1a8KuACAO6QjHh4pgBHWyb8C6hAEltITWE98iw01tE1krDtxMPKiSdg13mNic6oE05cv40FS2FFSAw" data-max-custom-scopes="10" data-header-redesign-enabled="true" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="mrdbourke/tensorflow-deep-learning" data-current-org="" data-current-owner="mrdbourke" data-logged-in="true" data-copilot-chat-enabled="false" data-nl-search-enabled="false" data-catalyst="">
  <div class="search-input-container search-with-dialog position-relative d-flex flex-row flex-items-center height-auto color-bg-transparent border-0 color-fg-subtle mx-0" data-action="click:qbsearch-input#searchInputContainerClicked">
      
            <button type="button" data-action="click:qbsearch-input#handleExpand" class="AppHeader-button AppHeader-search-whenNarrow" aria-label="Search or jump to" aria-expanded="false" aria-haspopup="dialog">
            <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-search">
    <path d="M10.68 11.74a6 6 0 0 1-7.922-8.982 6 6 0 0 1 8.982 7.922l3.04 3.04a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215ZM11.5 7a4.499 4.499 0 1 0-8.997 0A4.499 4.499 0 0 0 11.5 7Z"></path>
</svg>
          </button>


<div class="AppHeader-search-whenRegular">
  <div class="AppHeader-search-wrap AppHeader-search-wrap--hasTrailing">
    <div class="AppHeader-search-control">
      <label for="AppHeader-searchInput" aria-label="Search or jump to" class="AppHeader-search-visual--leading">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-search">
    <path d="M10.68 11.74a6 6 0 0 1-7.922-8.982 6 6 0 0 1 8.982 7.922l3.04 3.04a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215ZM11.5 7a4.499 4.499 0 1 0-8.997 0A4.499 4.499 0 0 0 11.5 7Z"></path>
</svg>
      </label>

                <button type="button" data-target="qbsearch-input.inputButton" data-action="click:qbsearch-input#handleExpand" class="AppHeader-searchButton form-control input-contrast text-left color-fg-subtle no-wrap placeholder" data-hotkey="s,/" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;searchbar&quot;,&quot;context&quot;:&quot;global&quot;,&quot;tag&quot;:&quot;input&quot;,&quot;label&quot;:&quot;searchbar_input_global_navbar&quot;}" aria-describedby="search-error-message-flash">
            <div class="overflow-hidden">
              <span id="qb-input-query" data-target="qbsearch-input.inputButtonText">
                  Type <kbd class="AppHeader-search-kbd">/</kbd> to search
              </span>
            </div>
          </button>

    </div>


  </div>
</div>

    <input type="hidden" name="type" class="js-site-search-type-field">

    
<div class="Overlay--hidden " data-modal-dialog-overlay="">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true" class="Overlay Overlay--width-medium Overlay--height-auto">
      <h1 id="search-suggestions-dialog-header" class="sr-only">Search code, repositories, users, issues, pull requests...</h1>
    <div class="Overlay-body Overlay-body--paddingNone">
      
          <div data-view-component="true">        <div class="search-suggestions position-absolute width-full color-shadow-large border color-fg-default color-bg-default overflow-hidden d-flex flex-column query-builder-container" style="border-radius: 12px;" data-target="qbsearch-input.queryBuilderContainer" hidden="">
          <!-- '"` --><!-- </textarea></xmp> --><form id="query-builder-test-form" action="https://github.com/mrdbourke/tensorflow-deep-learning" accept-charset="UTF-8" method="get">
  <query-builder data-target="qbsearch-input.queryBuilder" id="query-builder-query-builder-test" data-filter-key=":" data-view-component="true" class="QueryBuilder search-query-builder" data-min-width="300" data-catalyst="">
    <div class="FormControl FormControl--fullWidth">
      <label id="query-builder-test-label" for="query-builder-test" class="FormControl-label sr-only">
        Search
      </label>
      <div class="QueryBuilder-StyledInput width-fit " data-target="query-builder.styledInput">
          <span id="query-builder-test-leadingvisual-wrap" class="FormControl-input-leadingVisualWrap QueryBuilder-leadingVisualWrap">
            <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-search FormControl-input-leadingVisual">
    <path d="M10.68 11.74a6 6 0 0 1-7.922-8.982 6 6 0 0 1 8.982 7.922l3.04 3.04a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215ZM11.5 7a4.499 4.499 0 1 0-8.997 0A4.499 4.499 0 0 0 11.5 7Z"></path>
</svg>
          </span>
        <div data-target="query-builder.styledInputContainer" class="QueryBuilder-StyledInputContainer">
          <div aria-hidden="true" class="QueryBuilder-StyledInputContent" data-target="query-builder.styledInputContent"></div>
          <div class="QueryBuilder-InputWrapper">
            <div aria-hidden="true" class="QueryBuilder-Sizer" data-target="query-builder.sizer"><span></span></div>
            <input id="query-builder-test" name="query-builder-test" value="" autocomplete="off" type="text" role="combobox" spellcheck="false" aria-expanded="false" aria-describedby="validation-cf1e2c5a-f202-486f-b75e-67913c7ee531" data-target="query-builder.input" data-action="
          input:query-builder#inputChange
          blur:query-builder#inputBlur
          keydown:query-builder#inputKeydown
          focus:query-builder#inputFocus
        " data-view-component="true" class="FormControl-input QueryBuilder-Input FormControl-medium" aria-controls="query-builder-test-results" aria-autocomplete="list" aria-haspopup="listbox" style="width: 300px;">
          </div>
        </div>
          <span class="sr-only" id="query-builder-test-clear">Clear</span>
          <button role="button" id="query-builder-test-clear-button" aria-labelledby="query-builder-test-clear query-builder-test-label" data-target="query-builder.clearButton" data-action="
                click:query-builder#clear
                focus:query-builder#clearButtonFocus
                blur:query-builder#clearButtonBlur
              " variant="small" hidden="" type="button" data-view-component="true" class="Button Button--iconOnly Button--invisible Button--medium mr-1 px-2 py-0 d-flex flex-items-center rounded-1 color-fg-muted">  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x-circle-fill Button-visual">
    <path d="M2.343 13.657A8 8 0 1 1 13.658 2.343 8 8 0 0 1 2.343 13.657ZM6.03 4.97a.751.751 0 0 0-1.042.018.751.751 0 0 0-.018 1.042L6.94 8 4.97 9.97a.749.749 0 0 0 .326 1.275.749.749 0 0 0 .734-.215L8 9.06l1.97 1.97a.749.749 0 0 0 1.275-.326.749.749 0 0 0-.215-.734L9.06 8l1.97-1.97a.749.749 0 0 0-.326-1.275.749.749 0 0 0-.734.215L8 6.94Z"></path>
</svg>
</button>

      </div>
      <template id="search-icon"></template>

<template id="code-icon"></template>

<template id="file-code-icon"></template>

<template id="history-icon"></template>

<template id="repo-icon"></template>

<template id="bookmark-icon"></template>

<template id="plus-circle-icon"></template>

<template id="circle-icon"></template>

<template id="trash-icon"></template>

<template id="team-icon"></template>

<template id="project-icon"></template>

<template id="pencil-icon"></template>

<template id="copilot-icon"></template>

<template id="copilot-error-icon"></template>

<template id="workflow-icon"></template>

<template id="book-icon"></template>

<template id="code-review-icon"></template>

<template id="codespaces-icon"></template>

<template id="comment-icon"></template>

<template id="comment-discussion-icon"></template>

<template id="organization-icon"></template>

<template id="rocket-icon"></template>

<template id="shield-check-icon"></template>

<template id="heart-icon"></template>

<template id="server-icon"></template>

<template id="globe-icon"></template>

<template id="issue-opened-icon"></template>

<template id="device-mobile-icon"></template>

<template id="package-icon"></template>

<template id="credit-card-icon"></template>

<template id="play-icon"></template>

<template id="gift-icon"></template>

<template id="code-square-icon"></template>

<template id="device-desktop-icon"></template>

        <div class="position-relative">
                <ul role="listbox" class="ActionListWrap QueryBuilder-ListWrap" aria-label="Suggestions" data-action="
                    combobox-commit:query-builder#comboboxCommit
                    mousedown:query-builder#resultsMousedown
                  " data-target="query-builder.resultsList" data-persist-list="false" id="query-builder-test-results"></ul>
        </div>
      <div class="FormControl-inlineValidation" id="validation-cf1e2c5a-f202-486f-b75e-67913c7ee531" hidden="hidden">
        <span class="FormControl-inlineValidation--visual">
          <svg aria-hidden="true" height="12" viewBox="0 0 12 12" version="1.1" width="12" data-view-component="true" class="octicon octicon-alert-fill">
    <path d="M4.855.708c.5-.896 1.79-.896 2.29 0l4.675 8.351a1.312 1.312 0 0 1-1.146 1.954H1.33A1.313 1.313 0 0 1 .183 9.058ZM7 7V3H5v4Zm-1 3a1 1 0 1 0 0-2 1 1 0 0 0 0 2Z"></path>
</svg>
        </span>
        <span></span>
</div>    </div>
    <div data-target="query-builder.screenReaderFeedback" aria-live="polite" aria-atomic="true" class="sr-only">0 suggestions.</div>
</query-builder></form>
          <div class="d-flex flex-row color-fg-muted px-3 text-small color-bg-default search-feedback-prompt">
            <a target="_blank" href="https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax" data-view-component="true" class="Link color-fg-accent text-normal ml-2">
              Search syntax tips
</a>            <div class="d-flex flex-1"></div>
              <button data-action="click:qbsearch-input#showFeedbackDialog" type="button" data-view-component="true" class="Button--link Button--medium Button color-fg-accent text-normal ml-2">  <span class="Button-content">
    <span class="Button-label">Give feedback</span>
  </span>
</button>
          </div>
        </div>
</div>

    </div>
</modal-dialog></div>
  </div>
  <div data-action="click:qbsearch-input#retract" class="dark-backdrop position-fixed" hidden="" data-target="qbsearch-input.darkBackdrop"></div>
  <div class="color-fg-default">
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true" class="Overlay Overlay-whenNarrow Overlay--size-medium Overlay--motion-scaleFade">
    <div data-view-component="true" class="Overlay-header">
  <div class="Overlay-headerContentWrap">
    <div class="Overlay-titleWrap">
      <h1 class="Overlay-title " id="feedback-dialog-title">
        Provide feedback
      </h1>
        
    </div>
    <div class="Overlay-actionWrap">
      <button data-close-dialog-id="feedback-dialog" aria-label="Close" type="button" data-view-component="true" class="close-button Overlay-closeButton"><svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg></button>
    </div>
  </div>
  
</div>
      <scrollable-region data-labelled-by="feedback-dialog-title" data-catalyst="" style="overflow: auto;">
        <div data-view-component="true" class="Overlay-body">        <!-- '"` --><!-- </textarea></xmp> --><form id="code-search-feedback-form" data-turbo="false" action="https://github.com/search/feedback" accept-charset="UTF-8" method="post"><input type="hidden" name="authenticity_token" value="vaXx3KefUMATm6CElscSD0q5yemTyAYscHLyNBK_PCLqGmu-fcfn9Z61-3h9eIBy-WB1diCZYiFjGp56yMo50Q">
          <p>We read every piece of feedback, and take your input very seriously.</p>
          <textarea name="feedback" class="form-control width-full mb-2" style="height: 120px" id="feedback"></textarea>
          <input name="include_email" id="include_email" aria-label="Include my email address so I can be contacted" class="form-control mr-2" type="checkbox">
          <label for="include_email" style="font-weight: normal">Include my email address so I can be contacted</label>
</form></div>
      </scrollable-region>
      <div data-view-component="true" class="Overlay-footer Overlay-footer--alignEnd">          <button data-close-dialog-id="feedback-dialog" type="button" data-view-component="true" class="btn">    Cancel
</button>
          <button form="code-search-feedback-form" data-action="click:qbsearch-input#submitFeedback" type="submit" data-view-component="true" class="btn-primary btn">    Submit feedback
</button>
</div>
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager" data-catalyst="">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true" class="Overlay Overlay-whenNarrow Overlay--size-medium Overlay--motion-scaleFade">
    <div data-view-component="true" class="Overlay-header Overlay-header--divided">
  <div class="Overlay-headerContentWrap">
    <div class="Overlay-titleWrap">
      <h1 class="Overlay-title " id="custom-scopes-dialog-title">
        Saved searches
      </h1>
        <h2 id="custom-scopes-dialog-description" class="Overlay-description">Use saved searches to filter your results more quickly</h2>
    </div>
    <div class="Overlay-actionWrap">
      <button data-close-dialog-id="custom-scopes-dialog" aria-label="Close" type="button" data-view-component="true" class="close-button Overlay-closeButton"><svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg></button>
    </div>
  </div>
  
</div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title" data-catalyst="" style="overflow: auto;">
        <div data-view-component="true" class="Overlay-body">        <div data-target="custom-scopes.customScopesModalDialogFlash"></div>

        <div hidden="" class="create-custom-scope-form" data-target="custom-scopes.createCustomScopeForm">
        <!-- '"` --><!-- </textarea></xmp> --><form id="custom-scopes-dialog-form" data-turbo="false" action="https://github.com/search/custom_scopes" accept-charset="UTF-8" method="post"><input type="hidden" name="authenticity_token" value="4g1maj_6XBzye7t6ezA_8rzo-UOfwdL31dPRc8_LDLyOxOEhkJXYnT64pb2hYUxnNpwbfSotIX6YB1jUCEOY7w">
          <div data-target="custom-scopes.customScopesModalDialogFlash"></div>

          <input type="hidden" id="custom_scope_id" name="custom_scope_id" data-target="custom-scopes.customScopesIdField">

          <div class="form-group">
            <label for="custom_scope_name">Name</label>
            <auto-check src="/search/custom_scopes/check_name" required="">
              <input type="text" name="custom_scope_name" id="custom_scope_name" data-target="custom-scopes.customScopesNameField" class="form-control" autocomplete="off" placeholder="github-ruby" required="" maxlength="50" spellcheck="false">
              <input type="hidden" value="XzQFWkNTFE_30_Z9reGiir9D43B0Q7F43ZWKA3mjl-mzIGiMIzTeblLK4EoiEmLhkqgTlTz9_Qrlg3D-Vc1CCw" data-csrf="true">
            </auto-check>
          </div>

          <div class="form-group">
            <label for="custom_scope_query">Query</label>
            <input type="text" name="custom_scope_query" id="custom_scope_query" data-target="custom-scopes.customScopesQueryField" class="form-control" autocomplete="off" placeholder="(repo:mona/a OR repo:mona/b) AND lang:python" required="" maxlength="500">
          </div>

          <p class="text-small color-fg-muted">
            To see all available qualifiers, see our <a class="Link--inTextBlock" href="https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax">documentation</a>.
          </p>
</form>        </div>

        <div data-target="custom-scopes.manageCustomScopesForm">
          <div data-target="custom-scopes.list"></div>
        </div>

</div>
      </scrollable-region>
      <div data-view-component="true" class="Overlay-footer Overlay-footer--alignEnd Overlay-footer--divided">          <button data-action="click:custom-scopes#customScopesCancel" type="button" data-view-component="true" class="btn">    Cancel
</button>
          <button form="custom-scopes-dialog-form" data-action="click:custom-scopes#customScopesSubmit" data-target="custom-scopes.customScopesSubmitButton" type="submit" data-view-component="true" class="btn-primary btn">    Create saved search
</button>
</div>
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>    <input type="hidden" value="vacoiGHQb9Rga2vxO9ujHFUdvYJcnVIvKP6X9JGVLbNwpV6m6qM6ZAG9Uy6t8hBy6HQc-7OnO4e9lorL-i7O1g" data-csrf="true" class="js-data-jump-to-suggestions-path-csrf">

          </div>

        <div class="AppHeader-actions position-relative">
             <react-partial-anchor data-catalyst="">
      <button id="global-create-menu-anchor" aria-label="Create something new" data-target="react-partial-anchor.anchor" type="button" data-view-component="true" class="AppHeader-button global-create-button Button--secondary Button--medium Button width-auto color-fg-muted" aria-describedby="tooltip-86a6b0a7-9689-459f-9bd7-54a2d403795c" aria-expanded="false" aria-haspopup="true">  <span class="Button-content">
      <span class="Button-visual Button-leadingVisual">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-plus">
    <path d="M7.75 2a.75.75 0 0 1 .75.75V7h4.25a.75.75 0 0 1 0 1.5H8.5v4.25a.75.75 0 0 1-1.5 0V8.5H2.75a.75.75 0 0 1 0-1.5H7V2.75A.75.75 0 0 1 7.75 2Z"></path>
</svg>
      </span>
    <span class="Button-label"><svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-triangle-down">
    <path d="m4.427 7.427 3.396 3.396a.25.25 0 0 0 .354 0l3.396-3.396A.25.25 0 0 0 11.396 7H4.604a.25.25 0 0 0-.177.427Z"></path>
</svg></span>
  </span>
</button><tool-tip id="tooltip-86a6b0a7-9689-459f-9bd7-54a2d403795c" for="global-create-menu-anchor" popover="manual" data-direction="s" data-type="description" data-view-component="true" class="sr-only position-absolute" role="tooltip"><template shadowrootmode="open"><style>
      :host {
        --tooltip-top: var(--tool-tip-position-top, 0);
        --tooltip-left: var(--tool-tip-position-left, 0);
        padding: var(--overlay-paddingBlock-condensed) var(--overlay-padding-condensed) !important;
        font: var(--text-body-shorthand-small);
        color: var(--tooltip-fgColor, var(--fgColor-onEmphasis)) !important;
        text-align: center;
        text-decoration: none;
        text-shadow: none;
        text-transform: none;
        letter-spacing: normal;
        word-wrap: break-word;
        white-space: pre;
        background: var(--tooltip-bgColor, var(--bgColor-emphasis)) !important;
        border-radius: var(--borderRadius-medium);
        border: 0 !important;
        opacity: 0;
        max-width: var(--overlay-width-small);
        word-wrap: break-word;
        white-space: normal;
        width: max-content !important;
        inset: var(--tooltip-top) auto auto var(--tooltip-left) !important;
        overflow: visible !important;
        text-wrap: balance;
      }

      :host(:is(.tooltip-n, .tooltip-nw, .tooltip-ne)) {
        --tooltip-top: calc(var(--tool-tip-position-top, 0) - var(--overlay-offset, 0.25rem));
        --tooltip-left: var(--tool-tip-position-left);
      }

      :host(:is(.tooltip-s, .tooltip-sw, .tooltip-se)) {
        --tooltip-top: calc(var(--tool-tip-position-top, 0) + var(--overlay-offset, 0.25rem));
        --tooltip-left: var(--tool-tip-position-left);
      }

      :host(.tooltip-w) {
        --tooltip-top: var(--tool-tip-position-top);
        --tooltip-left: calc(var(--tool-tip-position-left, 0) - var(--overlay-offset, 0.25rem));
      }

      :host(.tooltip-e) {
        --tooltip-top: var(--tool-tip-position-top);
        --tooltip-left: calc(var(--tool-tip-position-left, 0) + var(--overlay-offset, 0.25rem));
      }

      :host:after{
        position: absolute;
        display: block;
        right: 0;
        left: 0;
        height: var(--overlay-offset, 0.25rem);
        content: "";
      }

      :host(.tooltip-s):after,
      :host(.tooltip-se):after,
      :host(.tooltip-sw):after {
        bottom: 100%
      }

      :host(.tooltip-n):after,
      :host(.tooltip-ne):after,
      :host(.tooltip-nw):after {
        top: 100%;
      }

      @keyframes tooltip-appear {
        from {
          opacity: 0;
        }
        to {
          opacity: 1;
        }
      }

      :host(:popover-open),
      :host(:popover-open):before {
        animation-name: tooltip-appear;
        animation-duration: .1s;
        animation-fill-mode: forwards;
        animation-timing-function: ease-in;
      }

      :host(.\:popover-open) {
        animation-name: tooltip-appear;
        animation-duration: .1s;
        animation-fill-mode: forwards;
        animation-timing-function: ease-in;
      }

      @media (forced-colors: active) {
        :host {
          outline: solid 1px transparent;
        }

        :host:before {
          display: none;
        }
      }
    </style><slot></slot></template>Create new...</tool-tip>

      
    
        <script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_FeatureFlags_FeatureFla.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/ui_packages_react-core_register-partial_ts-ui_packages_global-cre.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/global-create-menu-ea4992326398.js.download"></script>

<react-partial partial-name="global-create-menu" data-ssr="false" data-catalyst="" class="loaded">
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{"createRepo":true,"importRepo":true,"codespaces":true,"gist":true,"createOrg":true,"createProject":false,"createProjectUrl":"/xroadtraveler?tab=projects","createLegacyProject":false,"createIssue":false,"org":null,"owner":"mrdbourke","repo":"tensorflow-deep-learning"}}</script>
  <div data-target="react-partial.reactRoot"><script type="application/json" id="__PRIMER_DATA_:rg:__">{"resolvedServerColorMode":"day"}</script></div>
</react-partial>

      </react-partial-anchor>


          <a href="https://github.com/issues" data-analytics-event="{&quot;category&quot;:&quot;Global navigation&quot;,&quot;action&quot;:&quot;ISSUES_HEADER&quot;,&quot;label&quot;:null}" id="icon-button-392436e4-42e5-4ae5-be8b-2276dd33c46b" aria-labelledby="tooltip-c4189e7b-50e1-4d7d-a09c-fc4ffd12ca15" data-view-component="true" class="Button Button--iconOnly Button--secondary Button--medium AppHeader-button color-fg-muted">  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-issue-opened Button-visual">
    <path d="M8 9.5a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z"></path><path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Z"></path>
</svg>
</a><tool-tip id="tooltip-c4189e7b-50e1-4d7d-a09c-fc4ffd12ca15" for="icon-button-392436e4-42e5-4ae5-be8b-2276dd33c46b" popover="manual" data-direction="s" data-type="label" data-view-component="true" class="sr-only position-absolute" aria-hidden="true" role="tooltip"><template shadowrootmode="open"><style>
      :host {
        --tooltip-top: var(--tool-tip-position-top, 0);
        --tooltip-left: var(--tool-tip-position-left, 0);
        padding: var(--overlay-paddingBlock-condensed) var(--overlay-padding-condensed) !important;
        font: var(--text-body-shorthand-small);
        color: var(--tooltip-fgColor, var(--fgColor-onEmphasis)) !important;
        text-align: center;
        text-decoration: none;
        text-shadow: none;
        text-transform: none;
        letter-spacing: normal;
        word-wrap: break-word;
        white-space: pre;
        background: var(--tooltip-bgColor, var(--bgColor-emphasis)) !important;
        border-radius: var(--borderRadius-medium);
        border: 0 !important;
        opacity: 0;
        max-width: var(--overlay-width-small);
        word-wrap: break-word;
        white-space: normal;
        width: max-content !important;
        inset: var(--tooltip-top) auto auto var(--tooltip-left) !important;
        overflow: visible !important;
        text-wrap: balance;
      }

      :host(:is(.tooltip-n, .tooltip-nw, .tooltip-ne)) {
        --tooltip-top: calc(var(--tool-tip-position-top, 0) - var(--overlay-offset, 0.25rem));
        --tooltip-left: var(--tool-tip-position-left);
      }

      :host(:is(.tooltip-s, .tooltip-sw, .tooltip-se)) {
        --tooltip-top: calc(var(--tool-tip-position-top, 0) + var(--overlay-offset, 0.25rem));
        --tooltip-left: var(--tool-tip-position-left);
      }

      :host(.tooltip-w) {
        --tooltip-top: var(--tool-tip-position-top);
        --tooltip-left: calc(var(--tool-tip-position-left, 0) - var(--overlay-offset, 0.25rem));
      }

      :host(.tooltip-e) {
        --tooltip-top: var(--tool-tip-position-top);
        --tooltip-left: calc(var(--tool-tip-position-left, 0) + var(--overlay-offset, 0.25rem));
      }

      :host:after{
        position: absolute;
        display: block;
        right: 0;
        left: 0;
        height: var(--overlay-offset, 0.25rem);
        content: "";
      }

      :host(.tooltip-s):after,
      :host(.tooltip-se):after,
      :host(.tooltip-sw):after {
        bottom: 100%
      }

      :host(.tooltip-n):after,
      :host(.tooltip-ne):after,
      :host(.tooltip-nw):after {
        top: 100%;
      }

      @keyframes tooltip-appear {
        from {
          opacity: 0;
        }
        to {
          opacity: 1;
        }
      }

      :host(:popover-open),
      :host(:popover-open):before {
        animation-name: tooltip-appear;
        animation-duration: .1s;
        animation-fill-mode: forwards;
        animation-timing-function: ease-in;
      }

      :host(.\:popover-open) {
        animation-name: tooltip-appear;
        animation-duration: .1s;
        animation-fill-mode: forwards;
        animation-timing-function: ease-in;
      }

      @media (forced-colors: active) {
        :host {
          outline: solid 1px transparent;
        }

        :host:before {
          display: none;
        }
      }
    </style><slot></slot></template>Issues</tool-tip>

          <a href="https://github.com/pulls" data-analytics-event="{&quot;category&quot;:&quot;Global navigation&quot;,&quot;action&quot;:&quot;PULL_REQUESTS_HEADER&quot;,&quot;label&quot;:null}" id="icon-button-294ff72e-3689-41b2-9399-4086ec8fc5d4" aria-labelledby="tooltip-3c8bd9da-9924-400d-b26c-fe6b5c5880a8" data-view-component="true" class="Button Button--iconOnly Button--secondary Button--medium AppHeader-button color-fg-muted">  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-git-pull-request Button-visual">
    <path d="M1.5 3.25a2.25 2.25 0 1 1 3 2.122v5.256a2.251 2.251 0 1 1-1.5 0V5.372A2.25 2.25 0 0 1 1.5 3.25Zm5.677-.177L9.573.677A.25.25 0 0 1 10 .854V2.5h1A2.5 2.5 0 0 1 13.5 5v5.628a2.251 2.251 0 1 1-1.5 0V5a1 1 0 0 0-1-1h-1v1.646a.25.25 0 0 1-.427.177L7.177 3.427a.25.25 0 0 1 0-.354ZM3.75 2.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm0 9.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm8.25.75a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Z"></path>
</svg>
</a><tool-tip id="tooltip-3c8bd9da-9924-400d-b26c-fe6b5c5880a8" for="icon-button-294ff72e-3689-41b2-9399-4086ec8fc5d4" popover="manual" data-direction="s" data-type="label" data-view-component="true" class="sr-only position-absolute" aria-hidden="true" role="tooltip"><template shadowrootmode="open"><style>
      :host {
        --tooltip-top: var(--tool-tip-position-top, 0);
        --tooltip-left: var(--tool-tip-position-left, 0);
        padding: var(--overlay-paddingBlock-condensed) var(--overlay-padding-condensed) !important;
        font: var(--text-body-shorthand-small);
        color: var(--tooltip-fgColor, var(--fgColor-onEmphasis)) !important;
        text-align: center;
        text-decoration: none;
        text-shadow: none;
        text-transform: none;
        letter-spacing: normal;
        word-wrap: break-word;
        white-space: pre;
        background: var(--tooltip-bgColor, var(--bgColor-emphasis)) !important;
        border-radius: var(--borderRadius-medium);
        border: 0 !important;
        opacity: 0;
        max-width: var(--overlay-width-small);
        word-wrap: break-word;
        white-space: normal;
        width: max-content !important;
        inset: var(--tooltip-top) auto auto var(--tooltip-left) !important;
        overflow: visible !important;
        text-wrap: balance;
      }

      :host(:is(.tooltip-n, .tooltip-nw, .tooltip-ne)) {
        --tooltip-top: calc(var(--tool-tip-position-top, 0) - var(--overlay-offset, 0.25rem));
        --tooltip-left: var(--tool-tip-position-left);
      }

      :host(:is(.tooltip-s, .tooltip-sw, .tooltip-se)) {
        --tooltip-top: calc(var(--tool-tip-position-top, 0) + var(--overlay-offset, 0.25rem));
        --tooltip-left: var(--tool-tip-position-left);
      }

      :host(.tooltip-w) {
        --tooltip-top: var(--tool-tip-position-top);
        --tooltip-left: calc(var(--tool-tip-position-left, 0) - var(--overlay-offset, 0.25rem));
      }

      :host(.tooltip-e) {
        --tooltip-top: var(--tool-tip-position-top);
        --tooltip-left: calc(var(--tool-tip-position-left, 0) + var(--overlay-offset, 0.25rem));
      }

      :host:after{
        position: absolute;
        display: block;
        right: 0;
        left: 0;
        height: var(--overlay-offset, 0.25rem);
        content: "";
      }

      :host(.tooltip-s):after,
      :host(.tooltip-se):after,
      :host(.tooltip-sw):after {
        bottom: 100%
      }

      :host(.tooltip-n):after,
      :host(.tooltip-ne):after,
      :host(.tooltip-nw):after {
        top: 100%;
      }

      @keyframes tooltip-appear {
        from {
          opacity: 0;
        }
        to {
          opacity: 1;
        }
      }

      :host(:popover-open),
      :host(:popover-open):before {
        animation-name: tooltip-appear;
        animation-duration: .1s;
        animation-fill-mode: forwards;
        animation-timing-function: ease-in;
      }

      :host(.\:popover-open) {
        animation-name: tooltip-appear;
        animation-duration: .1s;
        animation-fill-mode: forwards;
        animation-timing-function: ease-in;
      }

      @media (forced-colors: active) {
        :host {
          outline: solid 1px transparent;
        }

        :host:before {
          display: none;
        }
      }
    </style><slot></slot></template>Pull requests</tool-tip>

        </div>

        <notification-indicator data-channel="eyJjIjoibm90aWZpY2F0aW9uLWNoYW5nZWQ6NjMwMjUwMTUiLCJ0IjoxNzIzODQxMjE0fQ==--359e68a0e3e2eda19c6292677ccf8f49f63d2d8ff8cb156ef7315065691b758c" data-indicator-mode="none" data-tooltip-global="You have unread notifications" data-tooltip-unavailable="Notifications are unavailable at the moment." data-tooltip-none="You have no unread notifications" data-header-redesign-enabled="true" data-fetch-indicator-src="/notifications/indicator" data-fetch-indicator-enabled="true" data-view-component="true" class="js-socket-channel" data-fetch-retry-delay-time="500" data-catalyst="">
    <a id="AppHeader-notifications-button" href="https://github.com/notifications" aria-labelledby="notification-indicator-tooltip" data-hotkey="g n" data-target="notification-indicator.link" data-analytics-event="{&quot;category&quot;:&quot;Global navigation&quot;,&quot;action&quot;:&quot;NOTIFICATIONS_HEADER&quot;,&quot;label&quot;:&quot;icon:read&quot;}" data-view-component="true" class="Button Button--iconOnly Button--secondary Button--medium AppHeader-button color-fg-muted">  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-inbox Button-visual">
    <path d="M2.8 2.06A1.75 1.75 0 0 1 4.41 1h7.18c.7 0 1.333.417 1.61 1.06l2.74 6.395c.04.093.06.194.06.295v4.5A1.75 1.75 0 0 1 14.25 15H1.75A1.75 1.75 0 0 1 0 13.25v-4.5c0-.101.02-.202.06-.295Zm1.61.44a.25.25 0 0 0-.23.152L1.887 8H4.75a.75.75 0 0 1 .6.3L6.625 10h2.75l1.275-1.7a.75.75 0 0 1 .6-.3h2.863L11.82 2.652a.25.25 0 0 0-.23-.152Zm10.09 7h-2.875l-1.275 1.7a.75.75 0 0 1-.6.3h-3.5a.75.75 0 0 1-.6-.3L4.375 9.5H1.5v3.75c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25Z"></path>
</svg>
</a>

    <tool-tip id="notification-indicator-tooltip" data-target="notification-indicator.tooltip" for="AppHeader-notifications-button" popover="manual" data-direction="s" data-type="label" data-view-component="true" class="position-absolute sr-only" aria-hidden="true" role="tooltip" style="--tool-tip-position-top: 48px; --tool-tip-position-left: 1272.1124725341797px;"><template shadowrootmode="open"><style>
      :host {
        --tooltip-top: var(--tool-tip-position-top, 0);
        --tooltip-left: var(--tool-tip-position-left, 0);
        padding: var(--overlay-paddingBlock-condensed) var(--overlay-padding-condensed) !important;
        font: var(--text-body-shorthand-small);
        color: var(--tooltip-fgColor, var(--fgColor-onEmphasis)) !important;
        text-align: center;
        text-decoration: none;
        text-shadow: none;
        text-transform: none;
        letter-spacing: normal;
        word-wrap: break-word;
        white-space: pre;
        background: var(--tooltip-bgColor, var(--bgColor-emphasis)) !important;
        border-radius: var(--borderRadius-medium);
        border: 0 !important;
        opacity: 0;
        max-width: var(--overlay-width-small);
        word-wrap: break-word;
        white-space: normal;
        width: max-content !important;
        inset: var(--tooltip-top) auto auto var(--tooltip-left) !important;
        overflow: visible !important;
        text-wrap: balance;
      }

      :host(:is(.tooltip-n, .tooltip-nw, .tooltip-ne)) {
        --tooltip-top: calc(var(--tool-tip-position-top, 0) - var(--overlay-offset, 0.25rem));
        --tooltip-left: var(--tool-tip-position-left);
      }

      :host(:is(.tooltip-s, .tooltip-sw, .tooltip-se)) {
        --tooltip-top: calc(var(--tool-tip-position-top, 0) + var(--overlay-offset, 0.25rem));
        --tooltip-left: var(--tool-tip-position-left);
      }

      :host(.tooltip-w) {
        --tooltip-top: var(--tool-tip-position-top);
        --tooltip-left: calc(var(--tool-tip-position-left, 0) - var(--overlay-offset, 0.25rem));
      }

      :host(.tooltip-e) {
        --tooltip-top: var(--tool-tip-position-top);
        --tooltip-left: calc(var(--tool-tip-position-left, 0) + var(--overlay-offset, 0.25rem));
      }

      :host:after{
        position: absolute;
        display: block;
        right: 0;
        left: 0;
        height: var(--overlay-offset, 0.25rem);
        content: "";
      }

      :host(.tooltip-s):after,
      :host(.tooltip-se):after,
      :host(.tooltip-sw):after {
        bottom: 100%
      }

      :host(.tooltip-n):after,
      :host(.tooltip-ne):after,
      :host(.tooltip-nw):after {
        top: 100%;
      }

      @keyframes tooltip-appear {
        from {
          opacity: 0;
        }
        to {
          opacity: 1;
        }
      }

      :host(:popover-open),
      :host(:popover-open):before {
        animation-name: tooltip-appear;
        animation-duration: .1s;
        animation-fill-mode: forwards;
        animation-timing-function: ease-in;
      }

      :host(.\:popover-open) {
        animation-name: tooltip-appear;
        animation-duration: .1s;
        animation-fill-mode: forwards;
        animation-timing-function: ease-in;
      }

      @media (forced-colors: active) {
        :host {
          outline: solid 1px transparent;
        }

        :host:before {
          display: none;
        }
      }
    </style><slot></slot></template>You have no unread notifications</tool-tip>
</notification-indicator>

        

        <div class="AppHeader-user">
          <deferred-side-panel data-url="/_side-panels/user?repository_id=315463340" data-catalyst="">
  <include-fragment data-target="deferred-side-panel.fragment"><template shadowrootmode="open"><style>:host {display: block;}</style><slot></slot></template>
    <react-partial-anchor data-catalyst="">
  <button data-target="react-partial-anchor.anchor" data-login="xroadtraveler" aria-label="Open user navigation menu" type="button" data-view-component="true" class="Button--invisible Button--medium Button Button--invisible-noVisuals color-bg-transparent p-0" aria-expanded="false" aria-haspopup="true">  <span class="Button-content">
    <span class="Button-label"><img src="./github-tensorflow-deep-learning_files/63025015" alt="" size="32" height="32" width="32" data-view-component="true" class="avatar circle"></span>
  </span>
</button>
  

    <script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/global-user-nav-drawer-13d6c248f2c5.js.download"></script>
<link crossorigin="anonymous" media="all" rel="stylesheet" href="./github-tensorflow-deep-learning_files/primer-react-css.c618884f5114d8c53ed1.module.css">
<link crossorigin="anonymous" media="all" rel="stylesheet" href="./github-tensorflow-deep-learning_files/global-user-nav-drawer.dd5b95699efad9266028.module.css">

<react-partial partial-name="global-user-nav-drawer" data-ssr="false" data-catalyst="" class="loaded">
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{"owner":{"login":"xroadtraveler","name":"Travis Rillos","avatarUrl":"https://avatars.githubusercontent.com/u/63025015?v=4"},"drawerId":"global-user-nav-drawer","lazyLoadItemDataFetchUrl":"/_side-panels/user.json","canAddAccount":true,"addAccountPath":"/login?add_account=1\u0026return_to=https%3A%2F%2Fgithub.com%2Fmrdbourke%2Ftensorflow-deep-learning","switchAccountPath":"/switch_account","loginAccountPath":"/login?add_account=1","projectsPath":"/xroadtraveler?tab=projects","gistsUrl":"https://gist.github.com/mine","docsUrl":"https://docs.github.com","yourEnterpriseUrl":null,"enterpriseSettingsUrl":null,"supportUrl":"https://support.github.com","showAccountSwitcher":true,"showEnterprises":true,"showEnterprise":false,"showGists":true,"showSponsors":true,"showFeaturesPreviews":true,"showEnterpriseSettings":false,"createMenuProps":{"createRepo":true,"importRepo":true,"codespaces":true,"gist":true,"createOrg":true,"createProject":false,"createProjectUrl":"/xroadtraveler?tab=projects","createLegacyProject":false,"createIssue":false,"org":null,"owner":"mrdbourke","repo":"tensorflow-deep-learning"}}}</script>
  <div data-target="react-partial.reactRoot"><script type="application/json" id="__PRIMER_DATA_:rj:__">{"resolvedServerColorMode":"day"}</script></div>
</react-partial>

  </react-partial-anchor>

  </include-fragment>
</deferred-side-panel>
        </div>

        <div class="position-absolute mt-2">
            
<site-header-logged-in-user-menu data-catalyst="">

</site-header-logged-in-user-menu>

        </div>
      </div>
    </div>


      <div class="AppHeader-localBar">
        <nav data-pjax="#js-repo-pjax-container" aria-label="Repository" data-view-component="true" class="js-repo-nav js-sidenav-container-pjax js-responsive-underlinenav overflow-hidden UnderlineNav">

  <ul data-view-component="true" class="UnderlineNav-body list-style-none">
      <li data-view-component="true" class="d-inline-flex">
  <a id="code-tab" href="https://github.com/mrdbourke/tensorflow-deep-learning" data-tab-item="i0code-tab" data-selected-links="repo_source repo_downloads repo_commits repo_releases repo_tags repo_branches repo_packages repo_deployments repo_attestations /mrdbourke/tensorflow-deep-learning" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g c" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Code&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" aria-current="page" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item selected">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-code UnderlineNav-octicon d-none d-sm-inline">
    <path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path>
</svg>
        <span data-content="Code">Code</span>
          <span id="code-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="Not available" data-view-component="true" class="Counter"></span>


    
</a></li>
      <li data-view-component="true" class="d-inline-flex">
  <a id="issues-tab" href="https://github.com/mrdbourke/tensorflow-deep-learning/issues" data-tab-item="i1issues-tab" data-selected-links="repo_issues repo_labels repo_milestones /mrdbourke/tensorflow-deep-learning/issues /_view_fragments/issues/index/mrdbourke/tensorflow-deep-learning/layout" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g i" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Issues&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-issue-opened UnderlineNav-octicon d-none d-sm-inline">
    <path d="M8 9.5a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z"></path><path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Z"></path>
</svg>
        <span data-content="Issues">Issues</span>
          <span id="issues-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="54" data-view-component="true" class="Counter">54</span>


    
</a></li>
      <li data-view-component="true" class="d-inline-flex">
  <a id="pull-requests-tab" href="https://github.com/mrdbourke/tensorflow-deep-learning/pulls" data-tab-item="i2pull-requests-tab" data-selected-links="repo_pulls checks /mrdbourke/tensorflow-deep-learning/pulls" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g p" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Pull requests&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-git-pull-request UnderlineNav-octicon d-none d-sm-inline">
    <path d="M1.5 3.25a2.25 2.25 0 1 1 3 2.122v5.256a2.251 2.251 0 1 1-1.5 0V5.372A2.25 2.25 0 0 1 1.5 3.25Zm5.677-.177L9.573.677A.25.25 0 0 1 10 .854V2.5h1A2.5 2.5 0 0 1 13.5 5v5.628a2.251 2.251 0 1 1-1.5 0V5a1 1 0 0 0-1-1h-1v1.646a.25.25 0 0 1-.427.177L7.177 3.427a.25.25 0 0 1 0-.354ZM3.75 2.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm0 9.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm8.25.75a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Z"></path>
</svg>
        <span data-content="Pull requests">Pull requests</span>
          <span id="pull-requests-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="4" data-view-component="true" class="Counter">4</span>


    
</a></li>
      <li data-view-component="true" class="d-inline-flex">
  <a id="discussions-tab" href="https://github.com/mrdbourke/tensorflow-deep-learning/discussions" data-tab-item="i3discussions-tab" data-selected-links="repo_discussions /mrdbourke/tensorflow-deep-learning/discussions" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g g" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Discussions&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-comment-discussion UnderlineNav-octicon d-none d-sm-inline">
    <path d="M1.75 1h8.5c.966 0 1.75.784 1.75 1.75v5.5A1.75 1.75 0 0 1 10.25 10H7.061l-2.574 2.573A1.458 1.458 0 0 1 2 11.543V10h-.25A1.75 1.75 0 0 1 0 8.25v-5.5C0 1.784.784 1 1.75 1ZM1.5 2.75v5.5c0 .138.112.25.25.25h1a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h3.5a.25.25 0 0 0 .25-.25v-5.5a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25Zm13 2a.25.25 0 0 0-.25-.25h-.5a.75.75 0 0 1 0-1.5h.5c.966 0 1.75.784 1.75 1.75v5.5A1.75 1.75 0 0 1 14.25 12H14v1.543a1.458 1.458 0 0 1-2.487 1.03L9.22 12.28a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215l2.22 2.22v-2.19a.75.75 0 0 1 .75-.75h1a.25.25 0 0 0 .25-.25Z"></path>
</svg>
        <span data-content="Discussions">Discussions</span>
          <span id="discussions-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="Not available" data-view-component="true" class="Counter"></span>


    
</a></li>
      <li data-view-component="true" class="d-inline-flex">
  <a id="actions-tab" href="https://github.com/mrdbourke/tensorflow-deep-learning/actions" data-tab-item="i4actions-tab" data-selected-links="repo_actions /mrdbourke/tensorflow-deep-learning/actions" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g a" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Actions&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-play UnderlineNav-octicon d-none d-sm-inline">
    <path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Zm4.879-2.773 4.264 2.559a.25.25 0 0 1 0 .428l-4.264 2.559A.25.25 0 0 1 6 10.559V5.442a.25.25 0 0 1 .379-.215Z"></path>
</svg>
        <span data-content="Actions">Actions</span>
          <span id="actions-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="Not available" data-view-component="true" class="Counter"></span>


    
</a></li>
      <li data-view-component="true" class="d-inline-flex">
  <a id="projects-tab" href="https://github.com/mrdbourke/tensorflow-deep-learning/projects" data-tab-item="i5projects-tab" data-selected-links="repo_projects new_repo_project repo_project /mrdbourke/tensorflow-deep-learning/projects" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g b" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Projects&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-table UnderlineNav-octicon d-none d-sm-inline">
    <path d="M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25ZM6.5 6.5v8h7.75a.25.25 0 0 0 .25-.25V6.5Zm8-1.5V1.75a.25.25 0 0 0-.25-.25H6.5V5Zm-13 1.5v7.75c0 .138.112.25.25.25H5v-8ZM5 5V1.5H1.75a.25.25 0 0 0-.25.25V5Z"></path>
</svg>
        <span data-content="Projects">Projects</span>
          <span id="projects-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="1" data-view-component="true" class="Counter">1</span>


    
</a></li>
      <li data-view-component="true" class="d-inline-flex">
  <a id="security-tab" href="https://github.com/mrdbourke/tensorflow-deep-learning/security" data-tab-item="i6security-tab" data-selected-links="security overview alerts policy token_scanning code_scanning /mrdbourke/tensorflow-deep-learning/security" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g s" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Security&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-shield UnderlineNav-octicon d-none d-sm-inline">
    <path d="M7.467.133a1.748 1.748 0 0 1 1.066 0l5.25 1.68A1.75 1.75 0 0 1 15 3.48V7c0 1.566-.32 3.182-1.303 4.682-.983 1.498-2.585 2.813-5.032 3.855a1.697 1.697 0 0 1-1.33 0c-2.447-1.042-4.049-2.357-5.032-3.855C1.32 10.182 1 8.566 1 7V3.48a1.75 1.75 0 0 1 1.217-1.667Zm.61 1.429a.25.25 0 0 0-.153 0l-5.25 1.68a.25.25 0 0 0-.174.238V7c0 1.358.275 2.666 1.057 3.86.784 1.194 2.121 2.34 4.366 3.297a.196.196 0 0 0 .154 0c2.245-.956 3.582-2.104 4.366-3.298C13.225 9.666 13.5 8.36 13.5 7V3.48a.251.251 0 0 0-.174-.237l-5.25-1.68ZM8.75 4.75v3a.75.75 0 0 1-1.5 0v-3a.75.75 0 0 1 1.5 0ZM9 10.5a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path>
</svg>
        <span data-content="Security">Security</span>
          

    
</a></li>
      <li data-view-component="true" class="d-inline-flex">
  <a id="insights-tab" href="https://github.com/mrdbourke/tensorflow-deep-learning/pulse" data-tab-item="i7insights-tab" data-selected-links="repo_graphs repo_contributors dependency_graph dependabot_updates pulse people community /mrdbourke/tensorflow-deep-learning/pulse" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Insights&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true" class="UnderlineNav-item no-wrap js-responsive-underlinenav-item js-selected-navigation-item">
    
              <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-graph UnderlineNav-octicon d-none d-sm-inline">
    <path d="M1.5 1.75V13.5h13.75a.75.75 0 0 1 0 1.5H.75a.75.75 0 0 1-.75-.75V1.75a.75.75 0 0 1 1.5 0Zm14.28 2.53-5.25 5.25a.75.75 0 0 1-1.06 0L7 7.06 4.28 9.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.25-3.25a.75.75 0 0 1 1.06 0L10 7.94l4.72-4.72a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Z"></path>
</svg>
        <span data-content="Insights">Insights</span>
          <span id="insights-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="Not available" data-view-component="true" class="Counter"></span>


    
</a></li>
</ul>
    <div style="visibility:hidden;" data-view-component="true" class="UnderlineNav-actions js-responsive-underlinenav-overflow position-absolute pr-3 pr-md-4 pr-lg-5 right-0">      <action-menu data-select-variant="none" data-view-component="true" data-catalyst="">
  <focus-group direction="vertical" mnemonics="" retain="">
    <button id="action-menu-7cba1beb-2a79-4de9-9251-ee408fd8197f-button" popovertarget="action-menu-7cba1beb-2a79-4de9-9251-ee408fd8197f-overlay" aria-controls="action-menu-7cba1beb-2a79-4de9-9251-ee408fd8197f-list" aria-haspopup="true" aria-labelledby="tooltip-f54204ee-02ba-42a9-9eff-40e5d46b3e50" type="button" data-view-component="true" class="Button Button--iconOnly Button--secondary Button--medium UnderlineNav-item">  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-kebab-horizontal Button-visual">
    <path d="M8 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3ZM1.5 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Zm13 0a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z"></path>
</svg>
</button><tool-tip id="tooltip-f54204ee-02ba-42a9-9eff-40e5d46b3e50" for="action-menu-7cba1beb-2a79-4de9-9251-ee408fd8197f-button" popover="manual" data-direction="s" data-type="label" data-view-component="true" class="sr-only position-absolute" aria-hidden="true" role="tooltip"><template shadowrootmode="open"><style>
      :host {
        --tooltip-top: var(--tool-tip-position-top, 0);
        --tooltip-left: var(--tool-tip-position-left, 0);
        padding: var(--overlay-paddingBlock-condensed) var(--overlay-padding-condensed) !important;
        font: var(--text-body-shorthand-small);
        color: var(--tooltip-fgColor, var(--fgColor-onEmphasis)) !important;
        text-align: center;
        text-decoration: none;
        text-shadow: none;
        text-transform: none;
        letter-spacing: normal;
        word-wrap: break-word;
        white-space: pre;
        background: var(--tooltip-bgColor, var(--bgColor-emphasis)) !important;
        border-radius: var(--borderRadius-medium);
        border: 0 !important;
        opacity: 0;
        max-width: var(--overlay-width-small);
        word-wrap: break-word;
        white-space: normal;
        width: max-content !important;
        inset: var(--tooltip-top) auto auto var(--tooltip-left) !important;
        overflow: visible !important;
        text-wrap: balance;
      }

      :host(:is(.tooltip-n, .tooltip-nw, .tooltip-ne)) {
        --tooltip-top: calc(var(--tool-tip-position-top, 0) - var(--overlay-offset, 0.25rem));
        --tooltip-left: var(--tool-tip-position-left);
      }

      :host(:is(.tooltip-s, .tooltip-sw, .tooltip-se)) {
        --tooltip-top: calc(var(--tool-tip-position-top, 0) + var(--overlay-offset, 0.25rem));
        --tooltip-left: var(--tool-tip-position-left);
      }

      :host(.tooltip-w) {
        --tooltip-top: var(--tool-tip-position-top);
        --tooltip-left: calc(var(--tool-tip-position-left, 0) - var(--overlay-offset, 0.25rem));
      }

      :host(.tooltip-e) {
        --tooltip-top: var(--tool-tip-position-top);
        --tooltip-left: calc(var(--tool-tip-position-left, 0) + var(--overlay-offset, 0.25rem));
      }

      :host:after{
        position: absolute;
        display: block;
        right: 0;
        left: 0;
        height: var(--overlay-offset, 0.25rem);
        content: "";
      }

      :host(.tooltip-s):after,
      :host(.tooltip-se):after,
      :host(.tooltip-sw):after {
        bottom: 100%
      }

      :host(.tooltip-n):after,
      :host(.tooltip-ne):after,
      :host(.tooltip-nw):after {
        top: 100%;
      }

      @keyframes tooltip-appear {
        from {
          opacity: 0;
        }
        to {
          opacity: 1;
        }
      }

      :host(:popover-open),
      :host(:popover-open):before {
        animation-name: tooltip-appear;
        animation-duration: .1s;
        animation-fill-mode: forwards;
        animation-timing-function: ease-in;
      }

      :host(.\:popover-open) {
        animation-name: tooltip-appear;
        animation-duration: .1s;
        animation-fill-mode: forwards;
        animation-timing-function: ease-in;
      }

      @media (forced-colors: active) {
        :host {
          outline: solid 1px transparent;
        }

        :host:before {
          display: none;
        }
      }
    </style><slot></slot></template>Additional navigation options</tool-tip>


<anchored-position id="action-menu-7cba1beb-2a79-4de9-9251-ee408fd8197f-overlay" anchor="action-menu-7cba1beb-2a79-4de9-9251-ee408fd8197f-button" align="start" side="outside-bottom" anchor-offset="normal" popover="auto" data-view-component="true" style="inset: 36px auto auto 0px;">
  <div data-view-component="true" class="Overlay Overlay--size-auto">
    
      <div data-view-component="true" class="Overlay-body Overlay-body--paddingNone">          <action-list data-catalyst="">
  <div data-view-component="true">
    <ul aria-labelledby="action-menu-7cba1beb-2a79-4de9-9251-ee408fd8197f-button" id="action-menu-7cba1beb-2a79-4de9-9251-ee408fd8197f-list" role="menu" data-view-component="true" class="ActionListWrap--inset ActionListWrap">
        <li hidden="" data-menu-item="i0code-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-b5376b44-b1b6-4c6e-88ca-1bfd7cc8d083" href="https://github.com/mrdbourke/tensorflow-deep-learning" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-code">
    <path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Code
</span>      
</a>
  
</li>
        <li hidden="" data-menu-item="i1issues-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-c4e2cf2d-5ec4-4c3b-a1a9-dc8ce41c2672" href="https://github.com/mrdbourke/tensorflow-deep-learning/issues" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-issue-opened">
    <path d="M8 9.5a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z"></path><path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Issues
</span>      
</a>
  
</li>
        <li hidden="" data-menu-item="i2pull-requests-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-16d5cdd3-71c5-426e-9380-168c88b60412" href="https://github.com/mrdbourke/tensorflow-deep-learning/pulls" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-git-pull-request">
    <path d="M1.5 3.25a2.25 2.25 0 1 1 3 2.122v5.256a2.251 2.251 0 1 1-1.5 0V5.372A2.25 2.25 0 0 1 1.5 3.25Zm5.677-.177L9.573.677A.25.25 0 0 1 10 .854V2.5h1A2.5 2.5 0 0 1 13.5 5v5.628a2.251 2.251 0 1 1-1.5 0V5a1 1 0 0 0-1-1h-1v1.646a.25.25 0 0 1-.427.177L7.177 3.427a.25.25 0 0 1 0-.354ZM3.75 2.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm0 9.5a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Zm8.25.75a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Pull requests
</span>      
</a>
  
</li>
        <li hidden="" data-menu-item="i3discussions-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-a35ec100-c4cd-49bc-bd14-28815b84ced9" href="https://github.com/mrdbourke/tensorflow-deep-learning/discussions" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-comment-discussion">
    <path d="M1.75 1h8.5c.966 0 1.75.784 1.75 1.75v5.5A1.75 1.75 0 0 1 10.25 10H7.061l-2.574 2.573A1.458 1.458 0 0 1 2 11.543V10h-.25A1.75 1.75 0 0 1 0 8.25v-5.5C0 1.784.784 1 1.75 1ZM1.5 2.75v5.5c0 .138.112.25.25.25h1a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.749.749 0 0 1 .53-.22h3.5a.25.25 0 0 0 .25-.25v-5.5a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25Zm13 2a.25.25 0 0 0-.25-.25h-.5a.75.75 0 0 1 0-1.5h.5c.966 0 1.75.784 1.75 1.75v5.5A1.75 1.75 0 0 1 14.25 12H14v1.543a1.458 1.458 0 0 1-2.487 1.03L9.22 12.28a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215l2.22 2.22v-2.19a.75.75 0 0 1 .75-.75h1a.25.25 0 0 0 .25-.25Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Discussions
</span>      
</a>
  
</li>
        <li hidden="" data-menu-item="i4actions-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-27bff1d4-2958-4943-9d73-b0ae294a14f9" href="https://github.com/mrdbourke/tensorflow-deep-learning/actions" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-play">
    <path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM1.5 8a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0Zm4.879-2.773 4.264 2.559a.25.25 0 0 1 0 .428l-4.264 2.559A.25.25 0 0 1 6 10.559V5.442a.25.25 0 0 1 .379-.215Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Actions
</span>      
</a>
  
</li>
        <li hidden="" data-menu-item="i5projects-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-b74e9eb5-07bb-48c7-afc1-b5e5eb273ecf" href="https://github.com/mrdbourke/tensorflow-deep-learning/projects" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-table">
    <path d="M0 1.75C0 .784.784 0 1.75 0h12.5C15.216 0 16 .784 16 1.75v12.5A1.75 1.75 0 0 1 14.25 16H1.75A1.75 1.75 0 0 1 0 14.25ZM6.5 6.5v8h7.75a.25.25 0 0 0 .25-.25V6.5Zm8-1.5V1.75a.25.25 0 0 0-.25-.25H6.5V5Zm-13 1.5v7.75c0 .138.112.25.25.25H5v-8ZM5 5V1.5H1.75a.25.25 0 0 0-.25.25V5Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Projects
</span>      
</a>
  
</li>
        <li hidden="" data-menu-item="i6security-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-764b0ebd-7797-4fcc-b8b0-8ea395f91769" href="https://github.com/mrdbourke/tensorflow-deep-learning/security" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-shield">
    <path d="M7.467.133a1.748 1.748 0 0 1 1.066 0l5.25 1.68A1.75 1.75 0 0 1 15 3.48V7c0 1.566-.32 3.182-1.303 4.682-.983 1.498-2.585 2.813-5.032 3.855a1.697 1.697 0 0 1-1.33 0c-2.447-1.042-4.049-2.357-5.032-3.855C1.32 10.182 1 8.566 1 7V3.48a1.75 1.75 0 0 1 1.217-1.667Zm.61 1.429a.25.25 0 0 0-.153 0l-5.25 1.68a.25.25 0 0 0-.174.238V7c0 1.358.275 2.666 1.057 3.86.784 1.194 2.121 2.34 4.366 3.297a.196.196 0 0 0 .154 0c2.245-.956 3.582-2.104 4.366-3.298C13.225 9.666 13.5 8.36 13.5 7V3.48a.251.251 0 0 0-.174-.237l-5.25-1.68ZM8.75 4.75v3a.75.75 0 0 1-1.5 0v-3a.75.75 0 0 1 1.5 0ZM9 10.5a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Security
</span>      
</a>
  
</li>
        <li hidden="" data-menu-item="i7insights-tab" data-targets="action-list.items" role="none" data-view-component="true" class="ActionListItem">
    
    
    <a tabindex="-1" id="item-3740efc3-a973-45ef-911a-f0547d782b93" href="https://github.com/mrdbourke/tensorflow-deep-learning/pulse" role="menuitem" data-view-component="true" class="ActionListContent ActionListContent--visual16">
        <span class="ActionListItem-visual ActionListItem-visual--leading">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-graph">
    <path d="M1.5 1.75V13.5h13.75a.75.75 0 0 1 0 1.5H.75a.75.75 0 0 1-.75-.75V1.75a.75.75 0 0 1 1.5 0Zm14.28 2.53-5.25 5.25a.75.75 0 0 1-1.06 0L7 7.06 4.28 9.78a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042l3.25-3.25a.75.75 0 0 1 1.06 0L10 7.94l4.72-4.72a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042Z"></path>
</svg>
        </span>
      
        <span data-view-component="true" class="ActionListItem-label">
          Insights
</span>      
</a>
  
</li>
</ul>    
</div></action-list>


</div>
      
</div></anchored-position>  </focus-group>
</action-menu></div>
</nav>
      </div>
</header>


      <div hidden="hidden" data-view-component="true" class="js-stale-session-flash stale-session-flash flash flash-warn flash-full">
  
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
    <path d="M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path>
</svg>
        <span class="js-stale-session-flash-signed-in" hidden="">You signed in with another tab or window. <a class="Link--inTextBlock" href="https://github.com/mrdbourke/tensorflow-deep-learning">Reload</a> to refresh your session.</span>
        <span class="js-stale-session-flash-signed-out" hidden="">You signed out in another tab or window. <a class="Link--inTextBlock" href="https://github.com/mrdbourke/tensorflow-deep-learning">Reload</a> to refresh your session.</span>
        <span class="js-stale-session-flash-switched" hidden="">You switched accounts on another tab or window. <a class="Link--inTextBlock" href="https://github.com/mrdbourke/tensorflow-deep-learning">Reload</a> to refresh your session.</span>

    <button id="icon-button-c02e350c-6c35-4c0d-98ab-99b98741dfcb" aria-labelledby="tooltip-763635c2-a3ee-45b0-a7d3-baa2aa8e209c" type="button" data-view-component="true" class="Button Button--iconOnly Button--invisible Button--medium flash-close js-flash-close">  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x Button-visual">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
</button><tool-tip id="tooltip-763635c2-a3ee-45b0-a7d3-baa2aa8e209c" for="icon-button-c02e350c-6c35-4c0d-98ab-99b98741dfcb" popover="manual" data-direction="s" data-type="label" data-view-component="true" class="sr-only position-absolute" aria-hidden="true" role="tooltip"><template shadowrootmode="open"><style>
      :host {
        --tooltip-top: var(--tool-tip-position-top, 0);
        --tooltip-left: var(--tool-tip-position-left, 0);
        padding: var(--overlay-paddingBlock-condensed) var(--overlay-padding-condensed) !important;
        font: var(--text-body-shorthand-small);
        color: var(--tooltip-fgColor, var(--fgColor-onEmphasis)) !important;
        text-align: center;
        text-decoration: none;
        text-shadow: none;
        text-transform: none;
        letter-spacing: normal;
        word-wrap: break-word;
        white-space: pre;
        background: var(--tooltip-bgColor, var(--bgColor-emphasis)) !important;
        border-radius: var(--borderRadius-medium);
        border: 0 !important;
        opacity: 0;
        max-width: var(--overlay-width-small);
        word-wrap: break-word;
        white-space: normal;
        width: max-content !important;
        inset: var(--tooltip-top) auto auto var(--tooltip-left) !important;
        overflow: visible !important;
        text-wrap: balance;
      }

      :host(:is(.tooltip-n, .tooltip-nw, .tooltip-ne)) {
        --tooltip-top: calc(var(--tool-tip-position-top, 0) - var(--overlay-offset, 0.25rem));
        --tooltip-left: var(--tool-tip-position-left);
      }

      :host(:is(.tooltip-s, .tooltip-sw, .tooltip-se)) {
        --tooltip-top: calc(var(--tool-tip-position-top, 0) + var(--overlay-offset, 0.25rem));
        --tooltip-left: var(--tool-tip-position-left);
      }

      :host(.tooltip-w) {
        --tooltip-top: var(--tool-tip-position-top);
        --tooltip-left: calc(var(--tool-tip-position-left, 0) - var(--overlay-offset, 0.25rem));
      }

      :host(.tooltip-e) {
        --tooltip-top: var(--tool-tip-position-top);
        --tooltip-left: calc(var(--tool-tip-position-left, 0) + var(--overlay-offset, 0.25rem));
      }

      :host:after{
        position: absolute;
        display: block;
        right: 0;
        left: 0;
        height: var(--overlay-offset, 0.25rem);
        content: "";
      }

      :host(.tooltip-s):after,
      :host(.tooltip-se):after,
      :host(.tooltip-sw):after {
        bottom: 100%
      }

      :host(.tooltip-n):after,
      :host(.tooltip-ne):after,
      :host(.tooltip-nw):after {
        top: 100%;
      }

      @keyframes tooltip-appear {
        from {
          opacity: 0;
        }
        to {
          opacity: 1;
        }
      }

      :host(:popover-open),
      :host(:popover-open):before {
        animation-name: tooltip-appear;
        animation-duration: .1s;
        animation-fill-mode: forwards;
        animation-timing-function: ease-in;
      }

      :host(.\:popover-open) {
        animation-name: tooltip-appear;
        animation-duration: .1s;
        animation-fill-mode: forwards;
        animation-timing-function: ease-in;
      }

      @media (forced-colors: active) {
        :host {
          outline: solid 1px transparent;
        }

        :host:before {
          display: none;
        }
      }
    </style><slot></slot></template>Dismiss alert</tool-tip>


  
</div>
          
    </div>

  <div id="start-of-content" class="show-on-focus"></div>








    <div id="js-flash-container" class="flash-container" data-turbo-replace="">




  <template class="js-flash-template"></template>
</div>


    
    <notification-shelf-watcher data-base-url="https://github.com/notifications/beta/shelf" data-channel="eyJjIjoibm90aWZpY2F0aW9uLWNoYW5nZWQ6NjMwMjUwMTUiLCJ0IjoxNzIzODQxMjE0fQ==--359e68a0e3e2eda19c6292677ccf8f49f63d2d8ff8cb156ef7315065691b758c" data-view-component="true" class="js-socket-channel" data-refresh-delay="500" data-catalyst=""></notification-shelf-watcher>
  <div hidden="" data-initial="" data-target="notification-shelf-watcher.placeholder"></div>






  <div class="application-main " data-commit-hovercards-enabled="" data-discussion-hovercards-enabled="" data-issue-and-pr-hovercards-enabled="">
        <div itemscope="" itemtype="http://schema.org/SoftwareSourceCode" class="">
    <main id="js-repo-pjax-container">
      
  


<template class="js-user-list-create-dialog-template" data-label="Create list"></template>



    






      

  <div id="repository-container-header" class="pt-3 hide-full-screen" data-turbo-replace="">

      <div class="d-flex flex-nowrap flex-justify-end mb-3  container-xl  px-3 px-lg-5" style="gap: 1rem;">

        <div class="flex-auto min-width-0 width-fit">
              <div id="repo-title-component" class=" d-flex flex-nowrap flex-items-center wb-break-word f3 text-normal">
    <img class="avatar mr-2 d-none d-md-block avatar-user" alt="Owner avatar" src="./github-tensorflow-deep-learning_files/16750345" width="24" height="24">
  

  <strong itemprop="name" class="mr-2 flex-self-stretch d-none d-md-block no-wrap overflow-x-hidden">
    <a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" class="d-block overflow-x-hidden color-fg-default" style="text-overflow: ellipsis;" href="https://github.com/mrdbourke/tensorflow-deep-learning">tensorflow-deep-learning</a>
  </strong>

  <span></span><span class="Label Label--secondary v-align-middle mr-1 d-none d-md-block">Public</span>
</div>

<div class="d-none d-md-block">
</div>


        </div>

        <div id="repository-details-container" class="flex-shrink-0" data-turbo-replace="" style="max-width: 70%;">
            <ul class="pagehead-actions flex-shrink-0 d-none d-md-inline" style="padding: 2px 0;">
    
      

  <li>
                <script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/react-lib-7b7b5264f6c1.js.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_github_mini-throttle_dist_index_js-nod(4).download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_Box_Box_js-55a9038b54f0.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_Button_Button_js-b0edbf.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_TooltipV2_Tooltip_js-4d.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_clsx_dist_clsx_m_js-node_modules_primer_reac.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_ActionList_index_js-f64.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_ActionMenu_ActionMenu_j.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_Text_Text_js-node_modul.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_FormControl_FormControl.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_FilteredActionList_Filt.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_Dialog_js-node_modules_.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/ui_packages_react-core_create-browser-history_ts-ui_packages_safe.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/notifications-subscriptions-menu-be1efa498152.js.download"></script>
<link crossorigin="anonymous" media="all" rel="stylesheet" href="./github-tensorflow-deep-learning_files/notifications-subscriptions-menu.572fff1cb5c3caef1ac9.module.css">

<react-partial partial-name="notifications-subscriptions-menu" data-ssr="false" data-catalyst="" class="loaded">
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{"subscriptionType":"none","repositoryId":315463340,"repositoryName":"mrdbourke/tensorflow-deep-learning","watchersCount":158,"subscribableThreadTypes":[{"name":"Issue","enabled":true,"subscribed":false},{"name":"PullRequest","enabled":true,"subscribed":false},{"name":"Release","enabled":true,"subscribed":false},{"name":"Discussion","enabled":true,"subscribed":false},{"name":"SecurityAlert","enabled":true,"subscribed":false}],"repositoryLabels":[],"showLabelSubscriptions":false}}</script>
  <div data-target="react-partial.reactRoot"><div class="d-md-none"><button type="button" data-testid="notifications-subscriptions-menu-button-desktop" class="types__StyledButton-sc-ws60qy-0 feqCqy NotificationsSubscriptionsMenu-module__watchButton--ifxlS" aria-label="Watch: Participating in mrdbourke/tensorflow-deep-learning" aria-haspopup="true" aria-expanded="false" tabindex="0" data-loading="false" aria-describedby=":r9:-loading-announcement" id=":r9:"><span data-component="buttonContent" class="Box-sc-g0xbh4-0 kkrdEu"><span data-component="leadingVisual" class="Box-sc-g0xbh4-0 trpoQ"><svg aria-hidden="true" focusable="false" role="img" class="octicon octicon-eye" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M8 2c1.981 0 3.671.992 4.933 2.078 1.27 1.091 2.187 2.345 2.637 3.023a1.62 1.62 0 0 1 0 1.798c-.45.678-1.367 1.932-2.637 3.023C11.67 13.008 9.981 14 8 14c-1.981 0-3.671-.992-4.933-2.078C1.797 10.83.88 9.576.43 8.898a1.62 1.62 0 0 1 0-1.798c.45-.677 1.367-1.931 2.637-3.022C4.33 2.992 6.019 2 8 2ZM1.679 7.932a.12.12 0 0 0 0 .136c.411.622 1.241 1.75 2.366 2.717C5.176 11.758 6.527 12.5 8 12.5c1.473 0 2.825-.742 3.955-1.715 1.124-.967 1.954-2.096 2.366-2.717a.12.12 0 0 0 0-.136c-.412-.621-1.242-1.75-2.366-2.717C10.824 4.242 9.473 3.5 8 3.5c-1.473 0-2.825.742-3.955 1.715-1.124.967-1.954 2.096-2.366 2.717ZM8 10a2 2 0 1 1-.001-3.999A2 2 0 0 1 8 10Z"></path></svg></span><span data-component="text"></span></span></button></div><div class="d-none d-md-block"><button type="button" data-testid="notifications-subscriptions-menu-button-mobile" aria-label="Watch: Participating in mrdbourke/tensorflow-deep-learning" aria-haspopup="true" aria-expanded="false" tabindex="0" data-loading="false" data-size="small" aria-describedby=":rc:-loading-announcement" id=":rc:" class="types__StyledButton-sc-ws60qy-0 PZiaY"><span data-component="buttonContent" class="Box-sc-g0xbh4-0 kkrdEu"><span data-component="leadingVisual" class="Box-sc-g0xbh4-0 trpoQ"><svg aria-hidden="true" focusable="false" role="img" class="octicon octicon-eye" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M8 2c1.981 0 3.671.992 4.933 2.078 1.27 1.091 2.187 2.345 2.637 3.023a1.62 1.62 0 0 1 0 1.798c-.45.678-1.367 1.932-2.637 3.023C11.67 13.008 9.981 14 8 14c-1.981 0-3.671-.992-4.933-2.078C1.797 10.83.88 9.576.43 8.898a1.62 1.62 0 0 1 0-1.798c.45-.677 1.367-1.931 2.637-3.022C4.33 2.992 6.019 2 8 2ZM1.679 7.932a.12.12 0 0 0 0 .136c.411.622 1.241 1.75 2.366 2.717C5.176 11.758 6.527 12.5 8 12.5c1.473 0 2.825-.742 3.955-1.715 1.124-.967 1.954-2.096 2.366-2.717a.12.12 0 0 0 0-.136c-.412-.621-1.242-1.75-2.366-2.717C10.824 4.242 9.473 3.5 8 3.5c-1.473 0-2.825.742-3.955 1.715-1.124.967-1.954 2.096-2.366 2.717ZM8 10a2 2 0 1 1-.001-3.999A2 2 0 0 1 8 10Z"></path></svg></span><span data-component="text">Watch<span class="ml-2 Counter rounded-3 NotificationsSubscriptionsMenu-module__watchCounter--nAbhU">158</span></span></span><span data-component="trailingAction" class="Box-sc-g0xbh4-0 trpoQ"><svg aria-hidden="true" focusable="false" class="octicon octicon-triangle-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="m4.427 7.427 3.396 3.396a.25.25 0 0 0 .354 0l3.396-3.396A.25.25 0 0 0 11.396 7H4.604a.25.25 0 0 0-.177.427Z"></path></svg></span></button></div><script type="application/json" id="__PRIMER_DATA_:r8:__">{"resolvedServerColorMode":"day"}</script></div>
</react-partial>


  

    </li>

  <li>
        <div data-view-component="true" class="BtnGroup d-flex">
        <a icon="repo-forked" id="fork-button" href="https://github.com/mrdbourke/tensorflow-deep-learning/fork" data-hydro-click="{&quot;event_type&quot;:&quot;repository.click&quot;,&quot;payload&quot;:{&quot;target&quot;:&quot;FORK_BUTTON&quot;,&quot;repository_id&quot;:315463340,&quot;originating_url&quot;:&quot;https://github.com/mrdbourke/tensorflow-deep-learning&quot;,&quot;user_id&quot;:63025015}}" data-hydro-click-hmac="c4c18ea81209c3c56f4ef925836273650d368289a232e56531d0a7333d46f7c2" data-ga-click="Repository, show fork modal, action:files#disambiguate; text:Fork" data-view-component="true" class="btn-sm btn BtnGroup-item" aria-describedby="tooltip-b7d6f8c3-9233-436a-84fa-436752c1f1e5">    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-repo-forked mr-2">
    <path d="M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z"></path>
</svg>Fork
          <span id="repo-network-counter" data-pjax-replace="true" data-turbo-replace="true" title="2,505" data-view-component="true" class="Counter">2.5k</span>
          <tool-tip id="tooltip-b7d6f8c3-9233-436a-84fa-436752c1f1e5" for="fork-button" popover="manual" data-direction="s" data-type="description" data-view-component="true" class="sr-only position-absolute" role="tooltip"><template shadowrootmode="open"><style>
      :host {
        --tooltip-top: var(--tool-tip-position-top, 0);
        --tooltip-left: var(--tool-tip-position-left, 0);
        padding: var(--overlay-paddingBlock-condensed) var(--overlay-padding-condensed) !important;
        font: var(--text-body-shorthand-small);
        color: var(--tooltip-fgColor, var(--fgColor-onEmphasis)) !important;
        text-align: center;
        text-decoration: none;
        text-shadow: none;
        text-transform: none;
        letter-spacing: normal;
        word-wrap: break-word;
        white-space: pre;
        background: var(--tooltip-bgColor, var(--bgColor-emphasis)) !important;
        border-radius: var(--borderRadius-medium);
        border: 0 !important;
        opacity: 0;
        max-width: var(--overlay-width-small);
        word-wrap: break-word;
        white-space: normal;
        width: max-content !important;
        inset: var(--tooltip-top) auto auto var(--tooltip-left) !important;
        overflow: visible !important;
        text-wrap: balance;
      }

      :host(:is(.tooltip-n, .tooltip-nw, .tooltip-ne)) {
        --tooltip-top: calc(var(--tool-tip-position-top, 0) - var(--overlay-offset, 0.25rem));
        --tooltip-left: var(--tool-tip-position-left);
      }

      :host(:is(.tooltip-s, .tooltip-sw, .tooltip-se)) {
        --tooltip-top: calc(var(--tool-tip-position-top, 0) + var(--overlay-offset, 0.25rem));
        --tooltip-left: var(--tool-tip-position-left);
      }

      :host(.tooltip-w) {
        --tooltip-top: var(--tool-tip-position-top);
        --tooltip-left: calc(var(--tool-tip-position-left, 0) - var(--overlay-offset, 0.25rem));
      }

      :host(.tooltip-e) {
        --tooltip-top: var(--tool-tip-position-top);
        --tooltip-left: calc(var(--tool-tip-position-left, 0) + var(--overlay-offset, 0.25rem));
      }

      :host:after{
        position: absolute;
        display: block;
        right: 0;
        left: 0;
        height: var(--overlay-offset, 0.25rem);
        content: "";
      }

      :host(.tooltip-s):after,
      :host(.tooltip-se):after,
      :host(.tooltip-sw):after {
        bottom: 100%
      }

      :host(.tooltip-n):after,
      :host(.tooltip-ne):after,
      :host(.tooltip-nw):after {
        top: 100%;
      }

      @keyframes tooltip-appear {
        from {
          opacity: 0;
        }
        to {
          opacity: 1;
        }
      }

      :host(:popover-open),
      :host(:popover-open):before {
        animation-name: tooltip-appear;
        animation-duration: .1s;
        animation-fill-mode: forwards;
        animation-timing-function: ease-in;
      }

      :host(.\:popover-open) {
        animation-name: tooltip-appear;
        animation-duration: .1s;
        animation-fill-mode: forwards;
        animation-timing-function: ease-in;
      }

      @media (forced-colors: active) {
        :host {
          outline: solid 1px transparent;
        }

        :host:before {
          display: none;
        }
      }
    </style><slot></slot></template>Fork your own copy of mrdbourke/tensorflow-deep-learning</tool-tip>
</a>
      <details group_item="true" id="my-forks-menu-315463340" data-view-component="true" class="details-reset details-overlay BtnGroup-parent d-inline-block position-relative">
              <summary aria-label="See your forks of this repository" data-view-component="true" class="btn-sm btn BtnGroup-item px-2 float-none" aria-haspopup="menu" role="button">    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-triangle-down">
    <path d="m4.427 7.427 3.396 3.396a.25.25 0 0 0 .354 0l3.396-3.396A.25.25 0 0 0 11.396 7H4.604a.25.25 0 0 0-.177.427Z"></path>
</svg>
</summary>
  <details-menu class="SelectMenu right-0" src="/mrdbourke/tensorflow-deep-learning/my_forks_menu_content?can_fork=true" role="menu" data-focus-trap="suspended"><span class="sentinel" tabindex="0" aria-hidden="true"></span>
    <div class="SelectMenu-modal">
        <button class="SelectMenu-closeButton position-absolute right-0 m-2" type="button" aria-label="Close menu" data-toggle-for="my-forks-menu-315463340">
          <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
        </button>
      <div id="filter-menu-aff806" class="d-flex flex-column flex-1 overflow-hidden">
        <div class="SelectMenu-list">

            <include-fragment class="SelectMenu-loading" aria-label="Loading"><template shadowrootmode="open"><style>:host {display: block;}</style><slot></slot></template>
                <p data-show-on-error="" hidden="">
                  Forks could not be loaded
                </p>
                <span data-hide-on-error="">
              <svg role="menuitem" style="box-sizing: content-box; color: var(--color-icon-primary);" width="32" height="32" viewBox="0 0 16 16" fill="none" aria-hidden="true" data-view-component="true" class="anim-rotate">
  <circle cx="8" cy="8" r="7" stroke="currentColor" stroke-opacity="0.25" stroke-width="2" vector-effect="non-scaling-stroke" fill="none"></circle>
  <path d="M15 8a7.002 7.002 0 00-7-7" stroke="currentColor" stroke-width="2" stroke-linecap="round" vector-effect="non-scaling-stroke"></path>
</svg>  <span class="sr-only">Loading</span>

                </span>
            </include-fragment>
        </div>
        
      </div>
    </div>
  <span class="sentinel" tabindex="0" aria-hidden="true"></span></details-menu>
</details></div>
  </li>

  <li>
        <template class="js-unstar-confirmation-dialog-template"></template>

  <div data-view-component="true" class="js-toggler-container js-social-container starring-container d-flex">
    <div data-view-component="true" class="starred BtnGroup flex-1 ml-0">
      <!-- '"` --><!-- </textarea></xmp> --><form class="js-social-form BtnGroup-parent flex-auto js-deferred-toggler-target" data-turbo="false" action="https://github.com/mrdbourke/tensorflow-deep-learning/unstar" accept-charset="UTF-8" method="post"><input type="hidden" name="authenticity_token" value="EsWlDxWEreiCX5rEcpDPUwwBlqlcXv4zPxj_7MNX57w3KuOtRJf0O9mTWNw75UX3eX2qrjT8Yzg9U-IDvOmemQ" autocomplete="off">
          <input type="hidden" value="aRaVRhxbbotDZkRIQhsCJoGlgIUpHRQ97WBoxC-xeAdM-dPkTUg3WBiqhlALboiC9Nm8gkG_iTbvK3UrUA8BIg" data-csrf="true" class="js-confirm-csrf-token">
        <input type="hidden" name="context" value="repository">
          <button data-hydro-click="{&quot;event_type&quot;:&quot;repository.click&quot;,&quot;payload&quot;:{&quot;target&quot;:&quot;UNSTAR_BUTTON&quot;,&quot;repository_id&quot;:315463340,&quot;originating_url&quot;:&quot;https://github.com/mrdbourke/tensorflow-deep-learning&quot;,&quot;user_id&quot;:63025015}}" data-hydro-click-hmac="1dd7828d3f0e59cdccf75efb304918750115bc0856325adfcf9e105b6fdf1cb1" data-ga-click="Repository, click unstar button, action:files#disambiguate; text:Unstar" data-aria-prefix="Unstar this repository" aria-label="Unstar this repository (5093)" type="submit" data-view-component="true" class="rounded-left-2 btn-with-aria-count btn-sm btn BtnGroup-item">    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-star-fill starred-button-icon d-inline-block mr-2">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Z"></path>
</svg><span data-view-component="true" class="d-inline">
              Starred
</span>              <span id="repo-stars-counter-unstar" aria-label="5093 users starred this repository" data-singular-suffix="user starred this repository" data-plural-suffix="users starred this repository" data-turbo-replace="true" title="5,093" data-view-component="true" class="Counter js-social-count">5.1k</span>
</button></form>        <details id="details-user-list-315463340-starred" data-view-component="true" class="details-reset details-overlay BtnGroup-parent js-user-list-menu d-inline-block position-relative">
        <summary aria-label="Add this repository to a list" data-view-component="true" class="btn-sm btn BtnGroup-item px-2 float-none" aria-haspopup="menu" role="button">    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-triangle-down">
    <path d="m4.427 7.427 3.396 3.396a.25.25 0 0 0 .354 0l3.396-3.396A.25.25 0 0 0 11.396 7H4.604a.25.25 0 0 0-.177.427Z"></path>
</svg>
</summary>
  <details-menu class="SelectMenu right-0" src="/mrdbourke/tensorflow-deep-learning/lists" role="menu" data-focus-trap="suspended"><span class="sentinel" tabindex="0" aria-hidden="true"></span>
    <div class="SelectMenu-modal">
        <header class="SelectMenu-header">
                <h4 class="SelectMenu-title f5" id="user-lists-menu">Lists</h4>

          <button class="SelectMenu-closeButton" type="button" aria-label="Close menu" data-toggle-for="details-user-list-315463340-starred">
            <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
          </button>
        </header>
      <div id="filter-menu-fd8310" class="d-flex flex-column flex-1 overflow-hidden">
        <div class="SelectMenu-list">

            <include-fragment class="SelectMenu-loading" aria-label="Loading"><template shadowrootmode="open"><style>:host {display: block;}</style><slot></slot></template>
              <svg role="menuitem" style="box-sizing: content-box; color: var(--color-icon-primary);" width="32" height="32" viewBox="0 0 16 16" fill="none" aria-hidden="true" data-view-component="true" class="anim-rotate">
  <circle cx="8" cy="8" r="7" stroke="currentColor" stroke-opacity="0.25" stroke-width="2" vector-effect="non-scaling-stroke" fill="none"></circle>
  <path d="M15 8a7.002 7.002 0 00-7-7" stroke="currentColor" stroke-width="2" stroke-linecap="round" vector-effect="non-scaling-stroke"></path>
</svg>  <span class="sr-only">Loading</span>

            </include-fragment>
        </div>
        
      </div>
    </div>
  <span class="sentinel" tabindex="0" aria-hidden="true"></span></details-menu>
</details>
</div>
    <div data-view-component="true" class="unstarred BtnGroup ml-0 flex-1">
      <!-- '"` --><!-- </textarea></xmp> --><form class="js-social-form BtnGroup-parent flex-auto" data-turbo="false" action="https://github.com/mrdbourke/tensorflow-deep-learning/star" accept-charset="UTF-8" method="post"><input type="hidden" name="authenticity_token" value="mUzzbPqk9SsCN-ziTX3lMmKxUSeHPwnCtJ10htDkwRJQ4uVpPwDj_KHMidGoxf3ww7TonWbEnFU4sLZu8PYB2g" autocomplete="off">
        <input type="hidden" name="context" value="repository">
          <button data-hydro-click="{&quot;event_type&quot;:&quot;repository.click&quot;,&quot;payload&quot;:{&quot;target&quot;:&quot;STAR_BUTTON&quot;,&quot;repository_id&quot;:315463340,&quot;originating_url&quot;:&quot;https://github.com/mrdbourke/tensorflow-deep-learning&quot;,&quot;user_id&quot;:63025015}}" data-hydro-click-hmac="13611330a8c497736eb441d1a003017a6c106dad15366e7d0570739cf7bb3db9" data-ga-click="Repository, click star button, action:files#disambiguate; text:Star" data-aria-prefix="Star this repository" aria-label="Star this repository (5093)" type="submit" data-view-component="true" class="js-toggler-target rounded-left-2 btn-with-aria-count btn-sm btn BtnGroup-item">    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-star d-inline-block mr-2">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg><span data-view-component="true" class="d-inline">
              Star
</span>              <span id="repo-stars-counter-star" aria-label="5093 users starred this repository" data-singular-suffix="user starred this repository" data-plural-suffix="users starred this repository" data-turbo-replace="true" title="5,093" data-view-component="true" class="Counter js-social-count">5.1k</span>
</button></form>        <details id="details-user-list-315463340-unstarred" data-view-component="true" class="details-reset details-overlay BtnGroup-parent js-user-list-menu d-inline-block position-relative">
        <summary aria-label="Add this repository to a list" data-view-component="true" class="btn-sm btn BtnGroup-item px-2 float-none" aria-haspopup="menu" role="button">    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-triangle-down">
    <path d="m4.427 7.427 3.396 3.396a.25.25 0 0 0 .354 0l3.396-3.396A.25.25 0 0 0 11.396 7H4.604a.25.25 0 0 0-.177.427Z"></path>
</svg>
</summary>
  <details-menu class="SelectMenu right-0" src="/mrdbourke/tensorflow-deep-learning/lists" role="menu" data-focus-trap="active"><span class="sentinel" tabindex="0" aria-hidden="true"></span>
    <div class="SelectMenu-modal">
        <header class="SelectMenu-header">
                <h4 class="SelectMenu-title f5" id="user-lists-menu">Lists</h4>

          <button class="SelectMenu-closeButton" type="button" aria-label="Close menu" data-toggle-for="details-user-list-315463340-unstarred">
            <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
          </button>
        </header>
      <div id="filter-menu-e5e130" class="d-flex flex-column flex-1 overflow-hidden">
        <div class="SelectMenu-list">

            <include-fragment class="SelectMenu-loading" aria-label="Loading"><template shadowrootmode="open"><style>:host {display: block;}</style><slot></slot></template>
              <svg role="menuitem" style="box-sizing: content-box; color: var(--color-icon-primary);" width="32" height="32" viewBox="0 0 16 16" fill="none" aria-hidden="true" data-view-component="true" class="anim-rotate">
  <circle cx="8" cy="8" r="7" stroke="currentColor" stroke-opacity="0.25" stroke-width="2" vector-effect="non-scaling-stroke" fill="none"></circle>
  <path d="M15 8a7.002 7.002 0 00-7-7" stroke="currentColor" stroke-width="2" stroke-linecap="round" vector-effect="non-scaling-stroke"></path>
</svg>  <span class="sr-only">Loading</span>

            </include-fragment>
        </div>
        
      </div>
    </div>
  <span class="sentinel" tabindex="0" aria-hidden="true"></span></details-menu>
</details>
</div></div>
  </li>

</ul>

        </div>
      </div>

        <div class=" container-xl ">
          <div id="responsive-meta-container" data-turbo-replace="">
      <div class="d-block d-md-none mb-2 px-3 px-md-4 px-lg-5">
        <div class="d-flex gap-2 mt-n3 mb-3 flex-wrap">
          <div class="d-flex flex-row gap-2">
                  <script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/react-lib-7b7b5264f6c1.js.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_github_mini-throttle_dist_index_js-nod(4).download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_Box_Box_js-55a9038b54f0.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_Button_Button_js-b0edbf.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_TooltipV2_Tooltip_js-4d.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_clsx_dist_clsx_m_js-node_modules_primer_reac.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_ActionList_index_js-f64.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_ActionMenu_ActionMenu_j.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_Text_Text_js-node_modul.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_FormControl_FormControl.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_FilteredActionList_Filt.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_Dialog_js-node_modules_.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/ui_packages_react-core_create-browser-history_ts-ui_packages_safe.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/notifications-subscriptions-menu-be1efa498152.js.download"></script>
<link crossorigin="anonymous" media="all" rel="stylesheet" href="./github-tensorflow-deep-learning_files/notifications-subscriptions-menu.572fff1cb5c3caef1ac9.module.css">

<react-partial partial-name="notifications-subscriptions-menu" data-ssr="false" data-catalyst="" class="loaded">
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{"subscriptionType":"none","repositoryId":315463340,"repositoryName":"mrdbourke/tensorflow-deep-learning","watchersCount":158,"subscribableThreadTypes":[{"name":"Issue","enabled":true,"subscribed":false},{"name":"PullRequest","enabled":true,"subscribed":false},{"name":"Release","enabled":true,"subscribed":false},{"name":"Discussion","enabled":true,"subscribed":false},{"name":"SecurityAlert","enabled":true,"subscribed":false}],"repositoryLabels":[],"showLabelSubscriptions":false}}</script>
  <div data-target="react-partial.reactRoot"><div class="d-md-none"><button type="button" data-testid="notifications-subscriptions-menu-button-desktop" class="types__StyledButton-sc-ws60qy-0 feqCqy NotificationsSubscriptionsMenu-module__watchButton--ifxlS" aria-label="Watch: Participating in mrdbourke/tensorflow-deep-learning" aria-haspopup="true" aria-expanded="false" tabindex="0" data-loading="false" aria-describedby=":r1:-loading-announcement" id=":r1:"><span data-component="buttonContent" class="Box-sc-g0xbh4-0 kkrdEu"><span data-component="leadingVisual" class="Box-sc-g0xbh4-0 trpoQ"><svg aria-hidden="true" focusable="false" role="img" class="octicon octicon-eye" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M8 2c1.981 0 3.671.992 4.933 2.078 1.27 1.091 2.187 2.345 2.637 3.023a1.62 1.62 0 0 1 0 1.798c-.45.678-1.367 1.932-2.637 3.023C11.67 13.008 9.981 14 8 14c-1.981 0-3.671-.992-4.933-2.078C1.797 10.83.88 9.576.43 8.898a1.62 1.62 0 0 1 0-1.798c.45-.677 1.367-1.931 2.637-3.022C4.33 2.992 6.019 2 8 2ZM1.679 7.932a.12.12 0 0 0 0 .136c.411.622 1.241 1.75 2.366 2.717C5.176 11.758 6.527 12.5 8 12.5c1.473 0 2.825-.742 3.955-1.715 1.124-.967 1.954-2.096 2.366-2.717a.12.12 0 0 0 0-.136c-.412-.621-1.242-1.75-2.366-2.717C10.824 4.242 9.473 3.5 8 3.5c-1.473 0-2.825.742-3.955 1.715-1.124.967-1.954 2.096-2.366 2.717ZM8 10a2 2 0 1 1-.001-3.999A2 2 0 0 1 8 10Z"></path></svg></span><span data-component="text"></span></span></button></div><div class="d-none d-md-block"><button type="button" data-testid="notifications-subscriptions-menu-button-mobile" aria-label="Watch: Participating in mrdbourke/tensorflow-deep-learning" aria-haspopup="true" aria-expanded="false" tabindex="0" data-loading="false" data-size="small" aria-describedby=":r4:-loading-announcement" id=":r4:" class="types__StyledButton-sc-ws60qy-0 PZiaY"><span data-component="buttonContent" class="Box-sc-g0xbh4-0 kkrdEu"><span data-component="leadingVisual" class="Box-sc-g0xbh4-0 trpoQ"><svg aria-hidden="true" focusable="false" role="img" class="octicon octicon-eye" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M8 2c1.981 0 3.671.992 4.933 2.078 1.27 1.091 2.187 2.345 2.637 3.023a1.62 1.62 0 0 1 0 1.798c-.45.678-1.367 1.932-2.637 3.023C11.67 13.008 9.981 14 8 14c-1.981 0-3.671-.992-4.933-2.078C1.797 10.83.88 9.576.43 8.898a1.62 1.62 0 0 1 0-1.798c.45-.677 1.367-1.931 2.637-3.022C4.33 2.992 6.019 2 8 2ZM1.679 7.932a.12.12 0 0 0 0 .136c.411.622 1.241 1.75 2.366 2.717C5.176 11.758 6.527 12.5 8 12.5c1.473 0 2.825-.742 3.955-1.715 1.124-.967 1.954-2.096 2.366-2.717a.12.12 0 0 0 0-.136c-.412-.621-1.242-1.75-2.366-2.717C10.824 4.242 9.473 3.5 8 3.5c-1.473 0-2.825.742-3.955 1.715-1.124.967-1.954 2.096-2.366 2.717ZM8 10a2 2 0 1 1-.001-3.999A2 2 0 0 1 8 10Z"></path></svg></span><span data-component="text">Watch<span class="ml-2 Counter rounded-3 NotificationsSubscriptionsMenu-module__watchCounter--nAbhU">158</span></span></span><span data-component="trailingAction" class="Box-sc-g0xbh4-0 trpoQ"><svg aria-hidden="true" focusable="false" class="octicon octicon-triangle-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="m4.427 7.427 3.396 3.396a.25.25 0 0 0 .354 0l3.396-3.396A.25.25 0 0 0 11.396 7H4.604a.25.25 0 0 0-.177.427Z"></path></svg></span></button></div><script type="application/json" id="__PRIMER_DATA_:r0:__">{"resolvedServerColorMode":"day"}</script></div>
</react-partial>



              <div data-view-component="true" class="BtnGroup d-flex">
      <a id="fork-icon-button" variant="small" group_item="true" href="https://github.com/mrdbourke/tensorflow-deep-learning/fork" data-hydro-click="{&quot;event_type&quot;:&quot;repository.click&quot;,&quot;payload&quot;:{&quot;target&quot;:&quot;FORK_BUTTON&quot;,&quot;repository_id&quot;:315463340,&quot;originating_url&quot;:&quot;https://github.com/mrdbourke/tensorflow-deep-learning&quot;,&quot;user_id&quot;:63025015}}" data-hydro-click-hmac="c4c18ea81209c3c56f4ef925836273650d368289a232e56531d0a7333d46f7c2" data-ga-click="Repository, show fork modal, action:files#disambiguate; text:Fork" aria-labelledby="tooltip-7373f9f0-b095-4034-b55c-a579e8ae9f07" data-view-component="true" class="Button Button--iconOnly Button--secondary Button--medium">  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-repo-forked Button-visual">
    <path d="M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z"></path>
</svg>
</a><tool-tip id="tooltip-7373f9f0-b095-4034-b55c-a579e8ae9f07" for="fork-icon-button" popover="manual" data-direction="s" data-type="label" data-view-component="true" class="sr-only position-absolute" aria-hidden="true" role="tooltip"><template shadowrootmode="open"><style>
      :host {
        --tooltip-top: var(--tool-tip-position-top, 0);
        --tooltip-left: var(--tool-tip-position-left, 0);
        padding: var(--overlay-paddingBlock-condensed) var(--overlay-padding-condensed) !important;
        font: var(--text-body-shorthand-small);
        color: var(--tooltip-fgColor, var(--fgColor-onEmphasis)) !important;
        text-align: center;
        text-decoration: none;
        text-shadow: none;
        text-transform: none;
        letter-spacing: normal;
        word-wrap: break-word;
        white-space: pre;
        background: var(--tooltip-bgColor, var(--bgColor-emphasis)) !important;
        border-radius: var(--borderRadius-medium);
        border: 0 !important;
        opacity: 0;
        max-width: var(--overlay-width-small);
        word-wrap: break-word;
        white-space: normal;
        width: max-content !important;
        inset: var(--tooltip-top) auto auto var(--tooltip-left) !important;
        overflow: visible !important;
        text-wrap: balance;
      }

      :host(:is(.tooltip-n, .tooltip-nw, .tooltip-ne)) {
        --tooltip-top: calc(var(--tool-tip-position-top, 0) - var(--overlay-offset, 0.25rem));
        --tooltip-left: var(--tool-tip-position-left);
      }

      :host(:is(.tooltip-s, .tooltip-sw, .tooltip-se)) {
        --tooltip-top: calc(var(--tool-tip-position-top, 0) + var(--overlay-offset, 0.25rem));
        --tooltip-left: var(--tool-tip-position-left);
      }

      :host(.tooltip-w) {
        --tooltip-top: var(--tool-tip-position-top);
        --tooltip-left: calc(var(--tool-tip-position-left, 0) - var(--overlay-offset, 0.25rem));
      }

      :host(.tooltip-e) {
        --tooltip-top: var(--tool-tip-position-top);
        --tooltip-left: calc(var(--tool-tip-position-left, 0) + var(--overlay-offset, 0.25rem));
      }

      :host:after{
        position: absolute;
        display: block;
        right: 0;
        left: 0;
        height: var(--overlay-offset, 0.25rem);
        content: "";
      }

      :host(.tooltip-s):after,
      :host(.tooltip-se):after,
      :host(.tooltip-sw):after {
        bottom: 100%
      }

      :host(.tooltip-n):after,
      :host(.tooltip-ne):after,
      :host(.tooltip-nw):after {
        top: 100%;
      }

      @keyframes tooltip-appear {
        from {
          opacity: 0;
        }
        to {
          opacity: 1;
        }
      }

      :host(:popover-open),
      :host(:popover-open):before {
        animation-name: tooltip-appear;
        animation-duration: .1s;
        animation-fill-mode: forwards;
        animation-timing-function: ease-in;
      }

      :host(.\:popover-open) {
        animation-name: tooltip-appear;
        animation-duration: .1s;
        animation-fill-mode: forwards;
        animation-timing-function: ease-in;
      }

      @media (forced-colors: active) {
        :host {
          outline: solid 1px transparent;
        }

        :host:before {
          display: none;
        }
      }
    </style><slot></slot></template>Fork your own copy of mrdbourke/tensorflow-deep-learning</tool-tip>

</div>
              <div data-view-component="true" class="js-toggler-container starring-container">
    <!-- '"` --><!-- </textarea></xmp> --><form class="starred js-social-form" data-turbo="false" action="https://github.com/mrdbourke/tensorflow-deep-learning/unstar" accept-charset="UTF-8" method="post"><input type="hidden" name="authenticity_token" value="TU67DcNLAhvPvIucPLzjhQB1QtSwbZYKKg_bSJI9_lVoof2vklhbyJRwSYR1yWkhdQl-09jPCwEoRMan7YOHcA" autocomplete="off">
      <input type="hidden" name="context" value="repository">
      <button data-hydro-click="{&quot;event_type&quot;:&quot;repository.click&quot;,&quot;payload&quot;:{&quot;target&quot;:&quot;UNSTAR_BUTTON&quot;,&quot;repository_id&quot;:315463340,&quot;originating_url&quot;:&quot;https://github.com/mrdbourke/tensorflow-deep-learning&quot;,&quot;user_id&quot;:63025015}}" data-hydro-click-hmac="1dd7828d3f0e59cdccf75efb304918750115bc0856325adfcf9e105b6fdf1cb1" data-ga-click="Repository, click unstar button, action:files#disambiguate; text:Unstar" id="icon-button-45427c3b-67a7-4f82-b47a-a2c46fe73cca" aria-labelledby="tooltip-7218a409-f6ef-4077-928b-ad6961994761" type="submit" data-view-component="true" class="Button Button--iconOnly Button--secondary Button--medium js-toggler-target starred-button-icon">  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-star-fill Button-visual">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Z"></path>
</svg>
</button><tool-tip id="tooltip-7218a409-f6ef-4077-928b-ad6961994761" for="icon-button-45427c3b-67a7-4f82-b47a-a2c46fe73cca" popover="manual" data-direction="s" data-type="label" data-view-component="true" class="sr-only position-absolute" aria-hidden="true" role="tooltip"><template shadowrootmode="open"><style>
      :host {
        --tooltip-top: var(--tool-tip-position-top, 0);
        --tooltip-left: var(--tool-tip-position-left, 0);
        padding: var(--overlay-paddingBlock-condensed) var(--overlay-padding-condensed) !important;
        font: var(--text-body-shorthand-small);
        color: var(--tooltip-fgColor, var(--fgColor-onEmphasis)) !important;
        text-align: center;
        text-decoration: none;
        text-shadow: none;
        text-transform: none;
        letter-spacing: normal;
        word-wrap: break-word;
        white-space: pre;
        background: var(--tooltip-bgColor, var(--bgColor-emphasis)) !important;
        border-radius: var(--borderRadius-medium);
        border: 0 !important;
        opacity: 0;
        max-width: var(--overlay-width-small);
        word-wrap: break-word;
        white-space: normal;
        width: max-content !important;
        inset: var(--tooltip-top) auto auto var(--tooltip-left) !important;
        overflow: visible !important;
        text-wrap: balance;
      }

      :host(:is(.tooltip-n, .tooltip-nw, .tooltip-ne)) {
        --tooltip-top: calc(var(--tool-tip-position-top, 0) - var(--overlay-offset, 0.25rem));
        --tooltip-left: var(--tool-tip-position-left);
      }

      :host(:is(.tooltip-s, .tooltip-sw, .tooltip-se)) {
        --tooltip-top: calc(var(--tool-tip-position-top, 0) + var(--overlay-offset, 0.25rem));
        --tooltip-left: var(--tool-tip-position-left);
      }

      :host(.tooltip-w) {
        --tooltip-top: var(--tool-tip-position-top);
        --tooltip-left: calc(var(--tool-tip-position-left, 0) - var(--overlay-offset, 0.25rem));
      }

      :host(.tooltip-e) {
        --tooltip-top: var(--tool-tip-position-top);
        --tooltip-left: calc(var(--tool-tip-position-left, 0) + var(--overlay-offset, 0.25rem));
      }

      :host:after{
        position: absolute;
        display: block;
        right: 0;
        left: 0;
        height: var(--overlay-offset, 0.25rem);
        content: "";
      }

      :host(.tooltip-s):after,
      :host(.tooltip-se):after,
      :host(.tooltip-sw):after {
        bottom: 100%
      }

      :host(.tooltip-n):after,
      :host(.tooltip-ne):after,
      :host(.tooltip-nw):after {
        top: 100%;
      }

      @keyframes tooltip-appear {
        from {
          opacity: 0;
        }
        to {
          opacity: 1;
        }
      }

      :host(:popover-open),
      :host(:popover-open):before {
        animation-name: tooltip-appear;
        animation-duration: .1s;
        animation-fill-mode: forwards;
        animation-timing-function: ease-in;
      }

      :host(.\:popover-open) {
        animation-name: tooltip-appear;
        animation-duration: .1s;
        animation-fill-mode: forwards;
        animation-timing-function: ease-in;
      }

      @media (forced-colors: active) {
        :host {
          outline: solid 1px transparent;
        }

        :host:before {
          display: none;
        }
      }
    </style><slot></slot></template>Unstar this repository</tool-tip>

</form>
    <!-- '"` --><!-- </textarea></xmp> --><form class="unstarred js-social-form" data-turbo="false" action="https://github.com/mrdbourke/tensorflow-deep-learning/star" accept-charset="UTF-8" method="post"><input type="hidden" name="authenticity_token" value="s922D78WrXtSMdt4nAJBrWpnjLJgOINoi8ZGhm6MKxx6c6AKerK7rPHKvkt5ullvy2I1CIHDFv8H64RuTp7r1A" autocomplete="off">
      <input type="hidden" name="context" value="repository">
      <button data-hydro-click="{&quot;event_type&quot;:&quot;repository.click&quot;,&quot;payload&quot;:{&quot;target&quot;:&quot;STAR_BUTTON&quot;,&quot;repository_id&quot;:315463340,&quot;originating_url&quot;:&quot;https://github.com/mrdbourke/tensorflow-deep-learning&quot;,&quot;user_id&quot;:63025015}}" data-hydro-click-hmac="13611330a8c497736eb441d1a003017a6c106dad15366e7d0570739cf7bb3db9" data-ga-click="Repository, click star button, action:files#disambiguate; text:Star" id="icon-button-875f4db3-f5d1-44c6-97b8-65a9b714e75f" aria-labelledby="tooltip-6472d312-d791-40f1-8577-da53140526d4" type="submit" data-view-component="true" class="Button Button--iconOnly Button--secondary Button--medium js-toggler-target">  <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-star Button-visual">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg>
</button><tool-tip id="tooltip-6472d312-d791-40f1-8577-da53140526d4" for="icon-button-875f4db3-f5d1-44c6-97b8-65a9b714e75f" popover="manual" data-direction="s" data-type="label" data-view-component="true" class="sr-only position-absolute" aria-hidden="true" role="tooltip"><template shadowrootmode="open"><style>
      :host {
        --tooltip-top: var(--tool-tip-position-top, 0);
        --tooltip-left: var(--tool-tip-position-left, 0);
        padding: var(--overlay-paddingBlock-condensed) var(--overlay-padding-condensed) !important;
        font: var(--text-body-shorthand-small);
        color: var(--tooltip-fgColor, var(--fgColor-onEmphasis)) !important;
        text-align: center;
        text-decoration: none;
        text-shadow: none;
        text-transform: none;
        letter-spacing: normal;
        word-wrap: break-word;
        white-space: pre;
        background: var(--tooltip-bgColor, var(--bgColor-emphasis)) !important;
        border-radius: var(--borderRadius-medium);
        border: 0 !important;
        opacity: 0;
        max-width: var(--overlay-width-small);
        word-wrap: break-word;
        white-space: normal;
        width: max-content !important;
        inset: var(--tooltip-top) auto auto var(--tooltip-left) !important;
        overflow: visible !important;
        text-wrap: balance;
      }

      :host(:is(.tooltip-n, .tooltip-nw, .tooltip-ne)) {
        --tooltip-top: calc(var(--tool-tip-position-top, 0) - var(--overlay-offset, 0.25rem));
        --tooltip-left: var(--tool-tip-position-left);
      }

      :host(:is(.tooltip-s, .tooltip-sw, .tooltip-se)) {
        --tooltip-top: calc(var(--tool-tip-position-top, 0) + var(--overlay-offset, 0.25rem));
        --tooltip-left: var(--tool-tip-position-left);
      }

      :host(.tooltip-w) {
        --tooltip-top: var(--tool-tip-position-top);
        --tooltip-left: calc(var(--tool-tip-position-left, 0) - var(--overlay-offset, 0.25rem));
      }

      :host(.tooltip-e) {
        --tooltip-top: var(--tool-tip-position-top);
        --tooltip-left: calc(var(--tool-tip-position-left, 0) + var(--overlay-offset, 0.25rem));
      }

      :host:after{
        position: absolute;
        display: block;
        right: 0;
        left: 0;
        height: var(--overlay-offset, 0.25rem);
        content: "";
      }

      :host(.tooltip-s):after,
      :host(.tooltip-se):after,
      :host(.tooltip-sw):after {
        bottom: 100%
      }

      :host(.tooltip-n):after,
      :host(.tooltip-ne):after,
      :host(.tooltip-nw):after {
        top: 100%;
      }

      @keyframes tooltip-appear {
        from {
          opacity: 0;
        }
        to {
          opacity: 1;
        }
      }

      :host(:popover-open),
      :host(:popover-open):before {
        animation-name: tooltip-appear;
        animation-duration: .1s;
        animation-fill-mode: forwards;
        animation-timing-function: ease-in;
      }

      :host(.\:popover-open) {
        animation-name: tooltip-appear;
        animation-duration: .1s;
        animation-fill-mode: forwards;
        animation-timing-function: ease-in;
      }

      @media (forced-colors: active) {
        :host {
          outline: solid 1px transparent;
        }

        :host:before {
          display: none;
        }
      }
    </style><slot></slot></template>Star this repository</tool-tip>

</form></div>
          </div>
          <div class="d-flex flex-row gap-2">
            

          </div>
        </div>
      <p class="f4 mb-3 color-fg-muted">
        All course materials for the Zero to Mastery Deep Learning with TensorFlow course.
      </p>
      <div class="mb-2 d-flex flex-items-center Link--secondary">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-link flex-shrink-0 mr-2">
    <path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path>
</svg>
        <span class="flex-auto min-width-0 css-truncate css-truncate-target width-fit">
          <a title="https://dbourke.link/ZTMTFcourse" role="link" target="_blank" class="text-bold" rel="noopener noreferrer" href="https://dbourke.link/ZTMTFcourse">dbourke.link/ztmtfcourse</a>
        </span>
      </div>

    
      <h3 class="sr-only">License</h3>
  <div class="mb-2">
    <a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/LICENSE" class="Link--muted" data-analytics-event="{&quot;category&quot;:&quot;Repository Overview&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;location:sidebar;file:license&quot;}">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-law mr-2">
    <path d="M8.75.75V2h.985c.304 0 .603.08.867.231l1.29.736c.038.022.08.033.124.033h2.234a.75.75 0 0 1 0 1.5h-.427l2.111 4.692a.75.75 0 0 1-.154.838l-.53-.53.529.531-.001.002-.002.002-.006.006-.006.005-.01.01-.045.04c-.21.176-.441.327-.686.45C14.556 10.78 13.88 11 13 11a4.498 4.498 0 0 1-2.023-.454 3.544 3.544 0 0 1-.686-.45l-.045-.04-.016-.015-.006-.006-.004-.004v-.001a.75.75 0 0 1-.154-.838L12.178 4.5h-.162c-.305 0-.604-.079-.868-.231l-1.29-.736a.245.245 0 0 0-.124-.033H8.75V13h2.5a.75.75 0 0 1 0 1.5h-6.5a.75.75 0 0 1 0-1.5h2.5V3.5h-.984a.245.245 0 0 0-.124.033l-1.289.737c-.265.15-.564.23-.869.23h-.162l2.112 4.692a.75.75 0 0 1-.154.838l-.53-.53.529.531-.001.002-.002.002-.006.006-.016.015-.045.04c-.21.176-.441.327-.686.45C4.556 10.78 3.88 11 3 11a4.498 4.498 0 0 1-2.023-.454 3.544 3.544 0 0 1-.686-.45l-.045-.04-.016-.015-.006-.006-.004-.004v-.001a.75.75 0 0 1-.154-.838L2.178 4.5H1.75a.75.75 0 0 1 0-1.5h2.234a.249.249 0 0 0 .125-.033l1.288-.737c.265-.15.564-.23.869-.23h.984V.75a.75.75 0 0 1 1.5 0Zm2.945 8.477c.285.135.718.273 1.305.273s1.02-.138 1.305-.273L13 6.327Zm-10 0c.285.135.718.273 1.305.273s1.02-.138 1.305-.273L3 6.327Z"></path>
</svg>
     MIT license
    </a>
  </div>


    <div class="mb-3">
        

<ul class="d-flex flex-wrap mb-2 gap-2" aria-label="Repository details">
  <a class="Link--secondary no-underline d-block mr-2" role="listitem" href="https://github.com/mrdbourke/tensorflow-deep-learning/stargazers">
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-star mr-1">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg>
    <span class="text-bold color-fg-default">5.1k</span>
    stars
</a>  <a class="Link--secondary no-underline d-block mr-2" role="listitem" href="https://github.com/mrdbourke/tensorflow-deep-learning/forks">
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-repo-forked mr-1">
    <path d="M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z"></path>
</svg>
    <span class="text-bold color-fg-default">2.5k</span>
    forks
</a>  <a class="Link--secondary no-underline d-block mr-2" role="listitem" href="https://github.com/mrdbourke/tensorflow-deep-learning/watchers">
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-eye mr-1">
    <path d="M8 2c1.981 0 3.671.992 4.933 2.078 1.27 1.091 2.187 2.345 2.637 3.023a1.62 1.62 0 0 1 0 1.798c-.45.678-1.367 1.932-2.637 3.023C11.67 13.008 9.981 14 8 14c-1.981 0-3.671-.992-4.933-2.078C1.797 10.83.88 9.576.43 8.898a1.62 1.62 0 0 1 0-1.798c.45-.677 1.367-1.931 2.637-3.022C4.33 2.992 6.019 2 8 2ZM1.679 7.932a.12.12 0 0 0 0 .136c.411.622 1.241 1.75 2.366 2.717C5.176 11.758 6.527 12.5 8 12.5c1.473 0 2.825-.742 3.955-1.715 1.124-.967 1.954-2.096 2.366-2.717a.12.12 0 0 0 0-.136c-.412-.621-1.242-1.75-2.366-2.717C10.824 4.242 9.473 3.5 8 3.5c-1.473 0-2.825.742-3.955 1.715-1.124.967-1.954 2.096-2.366 2.717ZM8 10a2 2 0 1 1-.001-3.999A2 2 0 0 1 8 10Z"></path>
</svg>
    <span class="text-bold color-fg-default">158</span>
    watching
</a>  <a class="Link--secondary no-underline d-block mr-2" role="listitem" href="https://github.com/mrdbourke/tensorflow-deep-learning/branches">
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-git-branch mr-1">
    <path d="M9.5 3.25a2.25 2.25 0 1 1 3 2.122V6A2.5 2.5 0 0 1 10 8.5H6a1 1 0 0 0-1 1v1.128a2.251 2.251 0 1 1-1.5 0V5.372a2.25 2.25 0 1 1 1.5 0v1.836A2.493 2.493 0 0 1 6 7h4a1 1 0 0 0 1-1v-.628A2.25 2.25 0 0 1 9.5 3.25Zm-6 0a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Zm8.25-.75a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5ZM4.25 12a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Z"></path>
</svg>
    <strong class="color-fg-default">2</strong>
<span class="color-fg-muted">Branches</span>

</a>  <a class="Link--secondary no-underline d-block mr-2" role="listitem" href="https://github.com/mrdbourke/tensorflow-deep-learning/tags">
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-tag mr-1">
    <path d="M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.752 1.752 0 0 1 1 7.775Zm1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2Z"></path>
</svg>
    <strong class="color-fg-default">0</strong>
<span class="color-fg-muted">Tags</span>

</a>  <a class="Link--secondary no-underline d-block mr-2" role="listitem" href="https://github.com/mrdbourke/tensorflow-deep-learning/activity">
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-pulse mr-1">
    <path d="M6 2c.306 0 .582.187.696.471L10 10.731l1.304-3.26A.751.751 0 0 1 12 7h3.25a.75.75 0 0 1 0 1.5h-2.742l-1.812 4.528a.751.751 0 0 1-1.392 0L6 4.77 4.696 8.03A.75.75 0 0 1 4 8.5H.75a.75.75 0 0 1 0-1.5h2.742l1.812-4.529A.751.751 0 0 1 6 2Z"></path>
</svg>
    <span>Activity</span>
</a>
</ul>

<div class="mb-2 d-flex color-fg-muted">
  <div class="d-flex flex-items-center" style="height: 21px">
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-globe flex-shrink-0 mr-2">
    <path d="M8 0a8 8 0 1 1 0 16A8 8 0 0 1 8 0ZM5.78 8.75a9.64 9.64 0 0 0 1.363 4.177c.255.426.542.832.857 1.215.245-.296.551-.705.857-1.215A9.64 9.64 0 0 0 10.22 8.75Zm4.44-1.5a9.64 9.64 0 0 0-1.363-4.177c-.307-.51-.612-.919-.857-1.215a9.927 9.927 0 0 0-.857 1.215A9.64 9.64 0 0 0 5.78 7.25Zm-5.944 1.5H1.543a6.507 6.507 0 0 0 4.666 5.5c-.123-.181-.24-.365-.352-.552-.715-1.192-1.437-2.874-1.581-4.948Zm-2.733-1.5h2.733c.144-2.074.866-3.756 1.58-4.948.12-.197.237-.381.353-.552a6.507 6.507 0 0 0-4.666 5.5Zm10.181 1.5c-.144 2.074-.866 3.756-1.58 4.948-.12.197-.237.381-.353.552a6.507 6.507 0 0 0 4.666-5.5Zm2.733-1.5a6.507 6.507 0 0 0-4.666-5.5c.123.181.24.365.353.552.714 1.192 1.436 2.874 1.58 4.948Z"></path>
</svg>
  </div>
  <span class="flex-auto min-width-0 width-fit">
    Public repository
  </span>
</div>

    </div>

  </div>

</div>

          <div class="border-bottom  mx-xl-5 "></div>
        </div>

  </div>




<turbo-frame id="repo-content-turbo-frame" target="_top" data-turbo-action="advance" class="">
    <div id="repo-content-pjax-container" class="repository-content ">
      <a href="https://github.dev/" class="d-none js-github-dev-shortcut" data-hotkey=".,Mod+Alt+.">Open in github.dev</a>
  <a href="https://github.dev/" class="d-none js-github-dev-new-tab-shortcut" data-hotkey="Shift+.,Shift+&gt;,&gt;" target="_blank" rel="noopener noreferrer">Open in a new github.dev tab</a>
    <a class="d-none" data-hotkey=",,Mod+Alt+," target="_blank" href="https://github.com/codespaces/new/mrdbourke/tensorflow-deep-learning?resume=1">Open in codespace</a>




    
      
  <h1 class="sr-only">mrdbourke/tensorflow-deep-learning</h1>
  <div class="clearfix container-xl px-md-4 px-lg-5 px-3">
    <div>

  <div id="spoof-warning" class="mt-0 pb-3" hidden="" aria-hidden="">
  <div data-view-component="true" class="flash flash-warn mt-0 clearfix">
  
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert float-left mt-1">
    <path d="M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path>
</svg>

      <div class="overflow-hidden">This commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.</div>


  
</div></div>

  



  <div style="max-width: 100%" data-view-component="true" class="Layout Layout--flowRow-until-md react-repos-overview-margin Layout--sidebarPosition-end Layout--sidebarPosition-flowRow-end">
  <div data-view-component="true" class="Layout-main">      <script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_react-router-dom_dist_index_js-c5568c29d405..download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_UnderlineNav_index_js-a.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_behaviors_dist_esm_anchored-pos(1).download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_AvatarStack_AvatarStack.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/vendors-node_modules_primer_react_lib-esm_Dialog_Dialog_js-(1).download"></script>

<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/ui_packages_ref-selector_RefSelector_tsx-7b0796d1324c.js.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/ui_packages_copy-to-clipboard_index_ts-ui_packages_react-core_use.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/ui_packages_code-view-shared_hooks_use-canonical-object_ts-ui_pac.download"></script>
<script crossorigin="anonymous" defer="defer" type="application/javascript" src="./github-tensorflow-deep-learning_files/repos-overview-84420f9ffa55.js.download"></script>
<link crossorigin="anonymous" media="all" rel="stylesheet" href="./github-tensorflow-deep-learning_files/repos-overview.47cf64b9ae0677ccb350.module.css">

<react-partial partial-name="repos-overview" data-ssr="true" data-catalyst="" class="loaded">
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{"initialPayload":{"allShortcutsEnabled":true,"path":"/","repo":{"id":315463340,"defaultBranch":"main","name":"tensorflow-deep-learning","ownerLogin":"mrdbourke","currentUserCanPush":false,"isFork":false,"isEmpty":false,"createdAt":"2020-11-23T15:11:42.000-08:00","ownerAvatar":"https://avatars.githubusercontent.com/u/16750345?v=4","public":true,"private":false,"isOrgOwned":false},"currentUser":{"id":63025015,"login":"xroadtraveler","userEmail":"xroadtraveler@gmail.com"},"refInfo":{"name":"main","listCacheKey":"v0:1714626893.0","canEdit":true,"refType":"branch","currentOid":"bd065b806249f7b1155e5b1fabd130c5cfc9d184"},"tree":{"items":[{"name":".github/workflows","path":".github/workflows","contentType":"directory","hasSimplifiedPath":true},{"name":"docs","path":"docs","contentType":"directory"},{"name":"extras","path":"extras","contentType":"directory"},{"name":"images","path":"images","contentType":"directory"},{"name":"slides","path":"slides","contentType":"directory"},{"name":"video_notebooks","path":"video_notebooks","contentType":"directory"},{"name":".gitignore","path":".gitignore","contentType":"file"},{"name":"00_tensorflow_fundamentals.ipynb","path":"00_tensorflow_fundamentals.ipynb","contentType":"file"},{"name":"01_neural_network_regression_in_tensorflow.ipynb","path":"01_neural_network_regression_in_tensorflow.ipynb","contentType":"file"},{"name":"02_neural_network_classification_in_tensorflow.ipynb","path":"02_neural_network_classification_in_tensorflow.ipynb","contentType":"file"},{"name":"03_convolutional_neural_networks_in_tensorflow.ipynb","path":"03_convolutional_neural_networks_in_tensorflow.ipynb","contentType":"file"},{"name":"04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb","path":"04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb","contentType":"file"},{"name":"05_transfer_learning_in_tensorflow_part_2_fine_tuning.ipynb","path":"05_transfer_learning_in_tensorflow_part_2_fine_tuning.ipynb","contentType":"file"},{"name":"06_transfer_learning_in_tensorflow_part_3_scaling_up.ipynb","path":"06_transfer_learning_in_tensorflow_part_3_scaling_up.ipynb","contentType":"file"},{"name":"07_food_vision_milestone_project_1.ipynb","path":"07_food_vision_milestone_project_1.ipynb","contentType":"file"},{"name":"08_introduction_to_nlp_in_tensorflow.ipynb","path":"08_introduction_to_nlp_in_tensorflow.ipynb","contentType":"file"},{"name":"09_SkimLit_nlp_milestone_project_2.ipynb","path":"09_SkimLit_nlp_milestone_project_2.ipynb","contentType":"file"},{"name":"10_time_series_forecasting_in_tensorflow.ipynb","path":"10_time_series_forecasting_in_tensorflow.ipynb","contentType":"file"},{"name":"11_passing_the_tensorflow_developer_certification_exam.md","path":"11_passing_the_tensorflow_developer_certification_exam.md","contentType":"file"},{"name":"LICENSE","path":"LICENSE","contentType":"file"},{"name":"README.md","path":"README.md","contentType":"file"},{"name":"mkdocs.yml","path":"mkdocs.yml","contentType":"file"}],"templateDirectorySuggestionUrl":null,"readme":null,"totalCount":22,"showBranchInfobar":false},"fileTree":null,"fileTreeProcessingTime":null,"foldersToFetch":[],"treeExpanded":false,"symbolsExpanded":false,"isOverview":true,"overview":{"banners":{"shouldRecommendReadme":false,"isPersonalRepo":false,"showUseActionBanner":false,"actionSlug":null,"actionId":null,"showProtectBranchBanner":false,"publishBannersInfo":{"dismissActionNoticePath":"/settings/dismiss-notice/publish_action_from_repo","releasePath":"/mrdbourke/tensorflow-deep-learning/releases/new?marketplace=true","showPublishActionBanner":false},"interactionLimitBanner":null,"showInvitationBanner":false,"inviterName":null,"actionsMigrationBannerInfo":{"releaseTags":[],"showImmutableActionsMigrationBanner":false}},"codeButton":{"contactPath":"/contact","isEnterprise":false,"local":{"protocolInfo":{"httpAvailable":true,"sshAvailable":true,"httpUrl":"https://github.com/mrdbourke/tensorflow-deep-learning.git","showCloneWarning":true,"sshUrl":"git@github.com:mrdbourke/tensorflow-deep-learning.git","sshCertificatesRequired":false,"sshCertificatesAvailable":null,"ghCliUrl":"gh repo clone mrdbourke/tensorflow-deep-learning","defaultProtocol":"http","newSshKeyUrl":"/settings/ssh/new","setProtocolPath":"/users/set_protocol"},"platformInfo":{"cloneUrl":"x-github-client://openRepo/https://github.com/mrdbourke/tensorflow-deep-learning","showVisualStudioCloneButton":false,"visualStudioCloneUrl":"https://windows.github.com","showXcodeCloneButton":false,"xcodeCloneUrl":"https://developer.apple.com","zipballUrl":"/mrdbourke/tensorflow-deep-learning/archive/refs/heads/main.zip"}},"repoPolicyInfo":{"allowed":true,"canBill":true,"changesWouldBeSafe":true,"disabledByBusiness":false,"disabledByOrganization":false,"hasIpAllowLists":false},"currentUserIsEnterpriseManaged":false,"enterpriseManagedBusinessName":null,"codespacesEnabled":true,"hasAccessToCodespaces":true},"popovers":{"rename":null,"renamedParentRepo":null},"commitCount":"592","overviewFiles":[{"displayName":"README.md","repoName":"tensorflow-deep-learning","refName":"main","path":"README.md","preferredFileType":"readme","tabName":"README","richText":"\u003carticle class=\"markdown-body entry-content container-lg\" itemprop=\"text\"\u003e\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch1 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eZero to Mastery Deep Learning with TensorFlow\u003c/h1\u003e\u003ca id=\"user-content-zero-to-mastery-deep-learning-with-tensorflow\" class=\"anchor\" aria-label=\"Permalink: Zero to Mastery Deep Learning with TensorFlow\" href=\"#zero-to-mastery-deep-learning-with-tensorflow\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003eAll of the course materials for the \u003ca href=\"https://dbourke.link/ZTMTFcourse\" rel=\"nofollow\"\u003eZero to Mastery Deep Learning with TensorFlow course\u003c/a\u003e.\u003c/p\u003e\n\u003cp dir=\"auto\"\u003eThis course will teach you the foundations of deep learning and how to build and train neural networks for various problem types with TensorFlow/Keras.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eImportant links\u003c/h2\u003e\u003ca id=\"user-content-important-links\" class=\"anchor\" aria-label=\"Permalink: Important links\" href=\"#important-links\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e Watch the \u003ca href=\"https://dbourke.link/tfpart1part2\" rel=\"nofollow\"\u003efirst 14-hours of the course on YouTube\u003c/a\u003e (notebooks 00, 01, 02)\u003c/li\u003e\n\u003cli\u003e Read the \u003ca href=\"https://dev.mrdbourke.com/tensorflow-deep-learning/\" rel=\"nofollow\"\u003ebeautiful online book version of the course\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e \u003ca href=\"https://dbourke.link/ZTMTFcourse\" rel=\"nofollow\"\u003eSign up\u003c/a\u003e to the full course on the Zero to Mastery Academy (videos for notebooks 03-10)\u003c/li\u003e\n\u003cli\u003e Got questions about the course? Check out the \u003ca href=\"https://youtu.be/rqAqcFcfeK8\" rel=\"nofollow\"\u003elivestream Q\u0026amp;A for the course launch\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e Get a quick overview of TensorFlow with the \u003ca href=\"https://zerotomastery.io/cheatsheets/tensorflow-cheat-sheet/\" rel=\"nofollow\"\u003eTensorFlow Cheatsheet\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eContents of this page\u003c/h2\u003e\u003ca id=\"user-content-contents-of-this-page\" class=\"anchor\" aria-label=\"Permalink: Contents of this page\" href=\"#contents-of-this-page\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning#fixes-and-updates\"\u003eFixes and updates\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning#course-materials\"\u003eCourse materials\u003c/a\u003e (everything you'll need for completing the course)\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning#course-structure\"\u003eCourse structure\u003c/a\u003e (how this course is taught)\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning#should-you-do-this-course\"\u003eShould you do this course?\u003c/a\u003e (decide by answering a couple simple questions)\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning#prerequisites\"\u003ePrerequisites\u003c/a\u003e (what skills you'll need to do this course)\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning#-exercises---extra-curriculum\"\u003eExercises \u0026amp; Extra-curriculum\u003c/a\u003e (challenges to practice what you've learned and resources to learn more)\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning#ask-questions\"\u003eAsk a question\u003c/a\u003e (like to know more? go here)\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning#status\"\u003eStatus\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning#log\"\u003eLog\u003c/a\u003e (updates, changes and progress)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eFixes and updates\u003c/h2\u003e\u003ca id=\"user-content-fixes-and-updates\" class=\"anchor\" aria-label=\"Permalink: Fixes and updates\" href=\"#fixes-and-updates\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e2 May 2024 - Update section 11 to reflect closing of TensorFlow Developer Certification program by Google (see \u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/discussions/645\" data-hovercard-type=\"discussion\" data-hovercard-url=\"/mrdbourke/tensorflow-deep-learning/discussions/645/hovercard\"\u003e#645\u003c/a\u003e for more)\u003c/li\u003e\n\u003cli\u003e18 Aug 2023 - Update \u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/05_transfer_learning_in_tensorflow_part_2_fine_tuning.ipynb\"\u003eNotebook 05\u003c/a\u003e to fix \u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/issues/544\" data-hovercard-type=\"issue\" data-hovercard-url=\"/mrdbourke/tensorflow-deep-learning/issues/544/hovercard\"\u003e#544\u003c/a\u003e and \u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/issues/553\" data-hovercard-type=\"issue\" data-hovercard-url=\"/mrdbourke/tensorflow-deep-learning/issues/553/hovercard\"\u003e#553\u003c/a\u003e, see \u003ca class=\"issue-link js-issue-link\" data-error-text=\"Failed to load title\" data-id=\"5529218\" data-permission-text=\"Title is private\" data-url=\"https://github.com/mrdbourke/tensorflow-deep-learning/discussions/575\" data-hovercard-type=\"discussion\" data-hovercard-url=\"/mrdbourke/tensorflow-deep-learning/discussions/575/hovercard\" href=\"https://github.com/mrdbourke/tensorflow-deep-learning/discussions/575\"\u003e#575\u003c/a\u003e for full notes\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eIn short, if you're using \u003ccode\u003etf.keras.applications.EfficientNetB0\u003c/code\u003e and facing errors, swap to \u003ca href=\"https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet_v2/EfficientNetV2B0\" rel=\"nofollow\"\u003e\u003ccode\u003etf.keras.applications.efficientnet_v2.EfficientNetV2B0\u003c/code\u003e\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e26 May 2023 - Update \u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/08_introduction_to_nlp_in_tensorflow.ipynb\"\u003eNotebook 08\u003c/a\u003e for new version of TensorFlow + update \u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/09_SkimLit_nlp_milestone_project_2.ipynb\"\u003eNotebook 09\u003c/a\u003e for new version of TensorFlow \u0026amp; spaCy, see update notes for 09: \u003ca class=\"issue-link js-issue-link\" data-error-text=\"Failed to load title\" data-id=\"5234715\" data-permission-text=\"Title is private\" data-url=\"https://github.com/mrdbourke/tensorflow-deep-learning/discussions/557\" data-hovercard-type=\"discussion\" data-hovercard-url=\"/mrdbourke/tensorflow-deep-learning/discussions/557/hovercard\" href=\"https://github.com/mrdbourke/tensorflow-deep-learning/discussions/557\"\u003e#557\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e19 May 2023 - Update \u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/07_food_vision_milestone_project_1.ipynb\"\u003eNotebook 07\u003c/a\u003e for new version of TensorFlow + fix model loading errors (TensorFlow 2.13+ required), see: \u003ca class=\"issue-link js-issue-link\" data-error-text=\"Failed to load title\" data-id=\"5208147\" data-permission-text=\"Title is private\" data-url=\"https://github.com/mrdbourke/tensorflow-deep-learning/discussions/550\" data-hovercard-type=\"discussion\" data-hovercard-url=\"/mrdbourke/tensorflow-deep-learning/discussions/550/hovercard\" href=\"https://github.com/mrdbourke/tensorflow-deep-learning/discussions/550\"\u003e#550\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e18 May 2023 - Update Notebook 06 for new TensorFlow namespaces (no major functionality change, just different imports), see: \u003ca class=\"issue-link js-issue-link\" data-error-text=\"Failed to load title\" data-id=\"5207679\" data-permission-text=\"Title is private\" data-url=\"https://github.com/mrdbourke/tensorflow-deep-learning/discussions/549\" data-hovercard-type=\"discussion\" data-hovercard-url=\"/mrdbourke/tensorflow-deep-learning/discussions/549/hovercard\" href=\"https://github.com/mrdbourke/tensorflow-deep-learning/discussions/549\"\u003e#549\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e12 May 2023 - Notebook 05 new namespaces added for \u003ccode\u003etf.keras.layers\u003c/code\u003e, see \u003ca class=\"issue-link js-issue-link\" data-error-text=\"Failed to load title\" data-id=\"5187992\" data-permission-text=\"Title is private\" data-url=\"https://github.com/mrdbourke/tensorflow-deep-learning/discussions/547\" data-hovercard-type=\"discussion\" data-hovercard-url=\"/mrdbourke/tensorflow-deep-learning/discussions/547/hovercard\" href=\"https://github.com/mrdbourke/tensorflow-deep-learning/discussions/547\"\u003e#547\u003c/a\u003e, also add fix for issue with \u003ccode\u003emodel.load_weights()\u003c/code\u003e in Notebook 05, see \u003ca class=\"issue-link js-issue-link\" data-error-text=\"Failed to load title\" data-id=\"1686834553\" data-permission-text=\"Title is private\" data-url=\"https://github.com/mrdbourke/tensorflow-deep-learning/issues/544\" data-hovercard-type=\"issue\" data-hovercard-url=\"/mrdbourke/tensorflow-deep-learning/issues/544/hovercard\" href=\"https://github.com/mrdbourke/tensorflow-deep-learning/issues/544\"\u003e#544\u003c/a\u003e, if you're having trouble saving/loading the model weights, also see \u003ca class=\"issue-link js-issue-link\" data-error-text=\"Failed to load title\" data-id=\"1721260828\" data-permission-text=\"Title is private\" data-url=\"https://github.com/mrdbourke/tensorflow-deep-learning/issues/553\" data-hovercard-type=\"issue\" data-hovercard-url=\"/mrdbourke/tensorflow-deep-learning/issues/553/hovercard\" href=\"https://github.com/mrdbourke/tensorflow-deep-learning/issues/553\"\u003e#553\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e12 May 2023 - Newer versions of TensorFlow (2.10+) use \u003ccode\u003elearning_rate\u003c/code\u003e instead of \u003ccode\u003elr\u003c/code\u003e in \u003ccode\u003etf.keras.optimizers\u003c/code\u003e (e.g. \u003ccode\u003etf.keras.optimizers.Adam(learning_rate=0.001)\u003c/code\u003e, old \u003ccode\u003elr\u003c/code\u003e still works but is deprecated\u003c/li\u003e\n\u003cli\u003e02 Dec 2021 - Added fix for TensorFlow 2.7.0+ for notebook 02, \u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/discussions/278\" data-hovercard-type=\"discussion\" data-hovercard-url=\"/mrdbourke/tensorflow-deep-learning/discussions/278/hovercard\"\u003esee discussion for more\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e11 Nov 2021 - Added fix for TensorFlow 2.7.0+ for notebook 01,  \u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/discussions/256\" data-hovercard-type=\"discussion\" data-hovercard-url=\"/mrdbourke/tensorflow-deep-learning/discussions/256/hovercard\"\u003esee discussion for more\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCourse materials\u003c/h2\u003e\u003ca id=\"user-content-course-materials\" class=\"anchor\" aria-label=\"Permalink: Course materials\" href=\"#course-materials\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003eThis table is the ground truth for course materials. All the links you need for everything will be here.\u003c/p\u003e\n\u003cp dir=\"auto\"\u003eKey:\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003cstrong\u003eNumber:\u003c/strong\u003e The number of the target notebook (this may not match the video section of the course but it ties together all of the materials in the table)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eNotebook:\u003c/strong\u003e The notebook for a particular module with lots of code and text annotations (notebooks from the videos are based on these)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eData/model:\u003c/strong\u003e Links to datasets/pre-trained models for the associated notebook\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eExercises \u0026amp; Extra-curriculum:\u003c/strong\u003e Each module comes with a set of exercises and extra-curriculum to help practice your skills and learn more, I suggest going through these \u003cstrong\u003ebefore\u003c/strong\u003e you move onto the next module\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSlides:\u003c/strong\u003e Although we focus on writing TensorFlow code, we sometimes use pretty slides to describe different concepts, you'll find them here\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eNote:\u003c/strong\u003e You can get all of the notebook code created during the videos in the \u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/tree/main/video_notebooks\"\u003e\u003ccode\u003evideo_notebooks\u003c/code\u003e\u003c/a\u003e directory.\u003c/p\u003e\n\u003cmarkdown-accessiblity-table\u003e\u003ctable\u003e\n\u003cthead\u003e\n\u003ctr\u003e\n\u003cth\u003eNumber\u003c/th\u003e\n\u003cth\u003eNotebook\u003c/th\u003e\n\u003cth\u003eData/Model\u003c/th\u003e\n\u003cth\u003eExercises \u0026amp; Extra-curriculum\u003c/th\u003e\n\u003cth\u003eSlides\u003c/th\u003e\n\u003c/tr\u003e\n\u003c/thead\u003e\n\u003ctbody\u003e\n\u003ctr\u003e\n\u003ctd\u003e00\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/00_tensorflow_fundamentals.ipynb\"\u003eTensorFlow Fundamentals\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning#-00-tensorflow-fundamentals-exercises\"\u003eGo to exercises \u0026amp; extra-curriculum\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/slides/00_introduction_to_tensorflow_and_deep_learning.pdf\"\u003eGo to slides\u003c/a\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e01\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/01_neural_network_regression_in_tensorflow.ipynb\"\u003eTensorFlow Regression\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning#-01-neural-network-regression-with-tensorflow-exercises\"\u003eGo to exercises \u0026amp; extra-curriculum\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/slides/01_neural_network_regression_with_tensorflow.pdf\"\u003eGo to slides\u003c/a\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e02\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/02_neural_network_classification_in_tensorflow.ipynb\"\u003eTensorFlow Classification\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning#-02-neural-network-classification-with-tensorflow-exercises\"\u003eGo to exercises \u0026amp; extra-curriculum\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/slides/02_neural_network_classification_with_tensorflow.pdf\"\u003eGo to slides\u003c/a\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e03\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/03_convolutional_neural_networks_in_tensorflow.ipynb\"\u003eTensorFlow Computer Vision\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip\" rel=\"nofollow\"\u003e\u003ccode\u003epizza_steak\u003c/code\u003e\u003c/a\u003e, \u003ca href=\"https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\" rel=\"nofollow\"\u003e\u003ccode\u003e10_food_classes_all_data\u003c/code\u003e\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning#-03-computer-vision--convolutional-neural-networks-in-tensorflow-exercises\"\u003eGo to exercises \u0026amp; extra-curriculum\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/slides/03_convolution_neural_networks_and_computer_vision_with_tensorflow.pdf\"\u003eGo to slides\u003c/a\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e04\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb\"\u003eTransfer Learning Part 1: Feature extraction\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\" rel=\"nofollow\"\u003e\u003ccode\u003e10_food_classes_10_percent\u003c/code\u003e\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning#-04-transfer-learning-in-tensorflow-part-1-feature-extraction-exercises\"\u003eGo to exercises \u0026amp; extra-curriculum\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/slides/04_transfer_learning_with_tensorflow_part_1_feature_extraction.pdf\"\u003eGo to slides\u003c/a\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e05\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/05_transfer_learning_in_tensorflow_part_2_fine_tuning.ipynb\"\u003eTransfer Learning Part 2: Fine-tuning\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\" rel=\"nofollow\"\u003e\u003ccode\u003e10_food_classes_10_percent\u003c/code\u003e\u003c/a\u003e, \u003ca href=\"https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_1_percent.zip\" rel=\"nofollow\"\u003e\u003ccode\u003e10_food_classes_1_percent\u003c/code\u003e\u003c/a\u003e, \u003ca href=\"https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\" rel=\"nofollow\"\u003e\u003ccode\u003e10_food_classes_all_data\u003c/code\u003e\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning#-05-transfer-learning-in-tensorflow-part-2-fine-tuning-exercises\"\u003eGo to exercises \u0026amp; extra-curriculum\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/slides/05_transfer_learning_with_tensorflow_part_2_fine_tuning.pdf\"\u003eGo to slides\u003c/a\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e06\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/06_transfer_learning_in_tensorflow_part_3_scaling_up.ipynb\"\u003eTransfer Learning Part 3: Scaling up\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip\" rel=\"nofollow\"\u003e\u003ccode\u003e101_food_classes_10_percent\u003c/code\u003e\u003c/a\u003e, \u003ca href=\"https://storage.googleapis.com/ztm_tf_course/food_vision/custom_food_images.zip\" rel=\"nofollow\"\u003e\u003ccode\u003ecustom_food_images\u003c/code\u003e\u003c/a\u003e, \u003ca href=\"https://storage.googleapis.com/ztm_tf_course/food_vision/06_101_food_class_10_percent_saved_big_dog_model.zip\" rel=\"nofollow\"\u003e\u003ccode\u003efine_tuned_efficientnet_model\u003c/code\u003e\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning#-06-transfer-learning-in-tensorflow-part-3-scaling-up-exercises\"\u003eGo to exercises \u0026amp; extra-curriculum\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/slides/06_transfer_learning_with_tensorflow_part_3_scaling_up.pdf\"\u003eGo to slides\u003c/a\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e07\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/07_food_vision_milestone_project_1.ipynb\"\u003eMilestone Project 1: Food Vision \u003c/a\u003e, \u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/TEMPLATE_07_food_vision_milestone_project_1.ipynb\"\u003eTemplate (your challenge)\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://storage.googleapis.com/ztm_tf_course/food_vision/07_efficientnetb0_feature_extract_model_mixed_precision.zip\" rel=\"nofollow\"\u003e\u003ccode\u003efeature_extraction_mixed_precision_efficientnet_model\u003c/code\u003e\u003c/a\u003e, \u003ca href=\"https://storage.googleapis.com/ztm_tf_course/food_vision/07_efficientnetb0_fine_tuned_101_classes_mixed_precision.zip\" rel=\"nofollow\"\u003e\u003ccode\u003efine_tuned_mixed_precision_efficientnet_model\u003c/code\u003e\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning#-07-milestone-project-1--food-vision-big-exercises\"\u003eGo to exercises \u0026amp; extra-curriculum\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/slides/07_milestone_project_1_food_vision.pdf\"\u003eGo to slides\u003c/a\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e08\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/08_introduction_to_nlp_in_tensorflow.ipynb\"\u003eTensorFlow NLP Fundamentals\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\" rel=\"nofollow\"\u003e\u003ccode\u003ediaster_or_no_diaster_tweets\u003c/code\u003e\u003c/a\u003e, \u003ca href=\"https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip\" rel=\"nofollow\"\u003e\u003ccode\u003eUSE_feature_extractor_model\u003c/code\u003e\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning#-08-introduction-to-nlp-natural-language-processing-in-tensorflow-exercises\"\u003eGo to exercises \u0026amp; extra-curriculum\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/slides/08_natural_language_processing_in_tensorflow.pdf\"\u003eGo to slides\u003c/a\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e09\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/09_SkimLit_nlp_milestone_project_2.ipynb\"\u003eMilestone Project 2: SkimLit \u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/Franck-Dernoncourt/pubmed-rct.git\"\u003e\u003ccode\u003epubmed_RCT_200k_dataset\u003c/code\u003e\u003c/a\u003e, \u003ca href=\"https://storage.googleapis.com/ztm_tf_course/skimlit/skimlit_tribrid_model.zip\" rel=\"nofollow\"\u003e\u003ccode\u003eskimlit_tribrid_model\u003c/code\u003e\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning#-09-milestone-project-2-skimlit--exercises\"\u003eGo to exercises \u0026amp; extra-curriculum\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/slides/09_milestone_project_2_skimlit.pdf\"\u003eGo to slides\u003c/a\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e10\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/10_time_series_forecasting_in_tensorflow.ipynb\"\u003eTensorFlow Time Series Fundamentals \u0026amp; Milestone Project 3: BitPredict \u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv\" rel=\"nofollow\"\u003e\u003ccode\u003ebitcoin_price_data_USD_2013-10-01_2021-05-18.csv\u003c/code\u003e\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning#-10-time-series-fundamentals-and-milestone-project-3-bitpredict--exercises\"\u003eGo to exercises \u0026amp; extra-curriculum\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/slides/10_time_series_fundamentals_and_milestone_project_3_bitpredict.pdf\"\u003eGo to slides\u003c/a\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003ctr\u003e\n\u003ctd\u003e11\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/11_passing_the_tensorflow_developer_certification_exam.md\"\u003ePreparing to Pass the TensorFlow Developer Certification Exam (archive)\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning#-11-passing-the-tensorflow-developer-certification-exercises\"\u003eGo to exercises \u0026amp; extra-curriculum\u003c/a\u003e\u003c/td\u003e\n\u003ctd\u003e\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/slides/11_passing_the_tensorflow_developer_certification_exam.pdf\"\u003eGo to slides\u003c/a\u003e\u003c/td\u003e\n\u003c/tr\u003e\n\u003c/tbody\u003e\n\u003c/table\u003e\u003c/markdown-accessiblity-table\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eCourse structure\u003c/h2\u003e\u003ca id=\"user-content-course-structure\" class=\"anchor\" aria-label=\"Permalink: Course structure\" href=\"#course-structure\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003eThis course is code first. The goal is to get you writing deep learning code as soon as possible.\u003c/p\u003e\n\u003cp dir=\"auto\"\u003eIt is taught with the following mantra:\u003c/p\u003e\n\u003cdiv class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"Code -\u0026gt; Concept -\u0026gt; Code -\u0026gt; Concept -\u0026gt; Code -\u0026gt; Concept\"\u003e\u003cpre class=\"notranslate\"\u003e\u003ccode\u003eCode -\u0026gt; Concept -\u0026gt; Code -\u0026gt; Concept -\u0026gt; Code -\u0026gt; Concept\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003eThis means we write code first then step through the concepts behind it.\u003c/p\u003e\n\u003cp dir=\"auto\"\u003eIf you've got 6-months experience writing Python code and a willingness to learn (most important), you'll be able to do the course.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eShould you do this course?\u003c/h2\u003e\u003ca id=\"user-content-should-you-do-this-course\" class=\"anchor\" aria-label=\"Permalink: Should you do this course?\" href=\"#should-you-do-this-course\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cblockquote\u003e\n\u003cp dir=\"auto\"\u003eDo you have 1+ years experience with deep learning and writing TensorFlow code?\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp dir=\"auto\"\u003eIf yes, no you shouldn't, use your skills to build something.\u003c/p\u003e\n\u003cp dir=\"auto\"\u003eIf no, move onto the next question.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp dir=\"auto\"\u003eHave you done at least one beginner machine learning course and would like to learn about deep learning/how to build neural networks with TensorFlow?\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp dir=\"auto\"\u003eIf yes, this course is for you.\u003c/p\u003e\n\u003cp dir=\"auto\"\u003eIf no, go and do a beginner machine learning course and if you decide you want to learn TensorFlow, this page will still be here.\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003ePrerequisites\u003c/h2\u003e\u003ca id=\"user-content-prerequisites\" class=\"anchor\" aria-label=\"Permalink: Prerequisites\" href=\"#prerequisites\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cblockquote\u003e\n\u003cp dir=\"auto\"\u003eWhat do I need to know to go through this course?\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003cstrong\u003e6+ months writing Python code.\u003c/strong\u003e Can you write a Python function which accepts and uses parameters? Thats good enough. If you dont know what that means, spend another month or two writing Python code and then come back here.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAt least one beginner machine learning course.\u003c/strong\u003e Are you familiar with the idea of training, validation and test sets? Do you know what supervised learning is? Have you used pandas, NumPy or Matplotlib before? If no to any of these, Id going through at least one machine learning course which teaches these first and then coming back.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eComfortable using Google Colab/Jupyter Notebooks.\u003c/strong\u003e This course uses Google Colab throughout. If you have never used Google Colab before, it works very similar to Jupyter Notebooks with a few extra features. If youre not familiar with Google Colab notebooks, Id suggest going through the Introduction to Google Colab notebook.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePlug:\u003c/strong\u003e The \u003ca href=\"https://dbourke.link/ZTMMLcourse\" rel=\"nofollow\"\u003eZero to Mastery beginner-friendly machine learning course\u003c/a\u003e (I also teach this) teaches all of the above (and this course is designed as a follow on).\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e Exercises \u0026amp;  Extra-curriculum\u003c/h2\u003e\u003ca id=\"user-content--exercises---extra-curriculum\" class=\"anchor\" aria-label=\"Permalink:  Exercises \u0026amp;  Extra-curriculum\" href=\"#-exercises---extra-curriculum\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003eTo prevent the course from being 100+ hours (deep learning is a broad field), various external resources for different sections are recommended to puruse under your own discretion.\u003c/p\u003e\n\u003cp dir=\"auto\"\u003eYou can find solutions to the exercises in \u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/tree/main/extras/solutions\"\u003e\u003ccode\u003eextras/solutions/\u003c/code\u003e\u003c/a\u003e, there's a notebook per set of exercises (one for 00, 01, 02... etc). Thank you to \u003ca href=\"https://github.com/ashikshafi08\"\u003eAshik Shafi\u003c/a\u003e for all of the efforts creating these.\u003c/p\u003e\n\u003chr\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e 00. TensorFlow Fundamentals Exercises\u003c/h3\u003e\u003ca id=\"user-content--00-tensorflow-fundamentals-exercises\" class=\"anchor\" aria-label=\"Permalink:  00. TensorFlow Fundamentals Exercises\" href=\"#-00-tensorflow-fundamentals-exercises\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003eCreate a vector, scalar, matrix and tensor with values of your choosing using \u003ccode\u003etf.constant()\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eFind the shape, rank and size of the tensors you created in 1.\u003c/li\u003e\n\u003cli\u003eCreate two tensors containing random values between 0 and 1 with shape \u003ccode\u003e[5, 300]\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eMultiply the two tensors you created in 3 using matrix multiplication.\u003c/li\u003e\n\u003cli\u003eMultiply the two tensors you created in 3 using dot product.\u003c/li\u003e\n\u003cli\u003eCreate a tensor with random values between 0 and 1 with shape \u003ccode\u003e[224, 224, 3]\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eFind the min and max values of the tensor you created in 6 along the first axis.\u003c/li\u003e\n\u003cli\u003eCreated a tensor with random values of shape \u003ccode\u003e[1, 224, 224, 3]\u003c/code\u003e then squeeze it to change the shape to \u003ccode\u003e[224, 224, 3]\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eCreate a tensor with shape \u003ccode\u003e[10]\u003c/code\u003e using your own choice of values, then find the index which has the maximum value.\u003c/li\u003e\n\u003cli\u003eOne-hot encode the tensor you created in 9.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e 00. TensorFlow Fundamentals Extra-curriculum\u003c/h3\u003e\u003ca id=\"user-content--00-tensorflow-fundamentals-extra-curriculum\" class=\"anchor\" aria-label=\"Permalink:  00. TensorFlow Fundamentals Extra-curriculum\" href=\"#-00-tensorflow-fundamentals-extra-curriculum\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eRead through the \u003ca href=\"https://www.tensorflow.org/api_docs/python/\" rel=\"nofollow\"\u003elist of TensorFlow Python APIs\u003c/a\u003e, pick one we haven't gone through in this notebook, reverse engineer it (write out the documentation code for yourself) and figure out what it does.\u003c/li\u003e\n\u003cli\u003eTry to create a series of tensor functions to calculate your most recent grocery bill (it's okay if you don't use the names of the items, just the price in numerical form).\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eHow would you calculate your grocery bill for the month and for the year using tensors?\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eGo through the \u003ca href=\"https://www.tensorflow.org/tutorials/quickstart/beginner\" rel=\"nofollow\"\u003eTensorFlow 2.x quick start for beginners\u003c/a\u003e tutorial (be sure to type out all of the code yourself, even if you don't understand it).\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eAre there any functions we used in here that match what's used in there? Which are the same? Which haven't you seen before?\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eWatch the video \u003ca href=\"https://www.youtube.com/watch?v=f5liqUk0ZTw\" rel=\"nofollow\"\u003e\"What's a tensor?\"\u003c/a\u003e - a great visual introduction to many of the concepts we've covered in this notebook.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e 01. Neural network regression with TensorFlow Exercises\u003c/h3\u003e\u003ca id=\"user-content--01-neural-network-regression-with-tensorflow-exercises\" class=\"anchor\" aria-label=\"Permalink:  01. Neural network regression with TensorFlow Exercises\" href=\"#-01-neural-network-regression-with-tensorflow-exercises\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003eCreate your own regression dataset (or make the one we created in \"Create data to view and fit\" bigger) and build fit a model to it.\u003c/li\u003e\n\u003cli\u003eTry building a neural network with 4 Dense layers and fitting it to your own regression dataset, how does it perform?\u003c/li\u003e\n\u003cli\u003eTry and improve the results we got on the insurance dataset, some things you might want to try include:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eBuilding a larger model (how does one with 4 dense layers go?).\u003c/li\u003e\n\u003cli\u003eIncreasing the number of units in each layer.\u003c/li\u003e\n\u003cli\u003eLookup the documentation of \u003ca href=\"https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\" rel=\"nofollow\"\u003eAdam\u003c/a\u003e and find out what the first parameter is, what happens if you increase it by 10x?\u003c/li\u003e\n\u003cli\u003eWhat happens if you train for longer (say 300 epochs instead of 200)?\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"4\" dir=\"auto\"\u003e\n\u003cli\u003eImport the \u003ca href=\"https://www.tensorflow.org/api_docs/python/tf/keras/datasets/boston_housing/load_data\" rel=\"nofollow\"\u003eBoston pricing dataset\u003c/a\u003e from TensorFlow \u003ca href=\"https://www.tensorflow.org/api_docs/python/tf/keras/datasets\" rel=\"nofollow\"\u003e\u003ccode\u003etf.keras.datasets\u003c/code\u003e\u003c/a\u003e and model it.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e 01. Neural network regression with TensorFlow Extra-curriculum\u003c/h3\u003e\u003ca id=\"user-content--01-neural-network-regression-with-tensorflow-extra-curriculum\" class=\"anchor\" aria-label=\"Permalink:  01. Neural network regression with TensorFlow Extra-curriculum\" href=\"#-01-neural-network-regression-with-tensorflow-extra-curriculum\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=7sB052Pz0sQ\u0026amp;ab_channel=AlexanderAmini\" rel=\"nofollow\"\u003eMIT introduction deep learning lecture 1\u003c/a\u003e - gives a great overview of what's happening behind all of the code we're running.\u003c/li\u003e\n\u003cli\u003eReading: 1-hour of \u003ca href=\"http://neuralnetworksanddeeplearning.com/chap1.html\" rel=\"nofollow\"\u003eChapter 1 of Neural Networks and Deep Learning\u003c/a\u003e by Michael Nielson - a great in-depth and hands-on example of the intuition behind neural networks.\u003c/li\u003e\n\u003cli\u003eTo practice your regression modelling with TensorFlow, I'd also encourage you to look through \u003ca href=\"https://www.kaggle.com/data\" rel=\"nofollow\"\u003eKaggle's datasets\u003c/a\u003e, find a regression dataset which sparks your interest and try to model.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e 02. Neural network classification with TensorFlow Exercises\u003c/h3\u003e\u003ca id=\"user-content--02-neural-network-classification-with-tensorflow-exercises\" class=\"anchor\" aria-label=\"Permalink:  02. Neural network classification with TensorFlow Exercises\" href=\"#-02-neural-network-classification-with-tensorflow-exercises\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003ePlay with neural networks in the \u003ca href=\"https://playground.tensorflow.org/\" rel=\"nofollow\"\u003eTensorFlow Playground\u003c/a\u003e for 10-minutes. Especially try different values of the learning, what happens when you decrease it? What happens when you increase it?\u003c/li\u003e\n\u003cli\u003eReplicate the model pictured in the \u003ca href=\"https://playground.tensorflow.org/#activation=relu\u0026amp;batchSize=10\u0026amp;dataset=circle\u0026amp;regDataset=reg-plane\u0026amp;learningRate=0.001\u0026amp;regularizationRate=0\u0026amp;noise=0\u0026amp;networkShape=6,6,6,6,6\u0026amp;seed=0.51287\u0026amp;showTestData=false\u0026amp;discretize=false\u0026amp;percTrainData=50\u0026amp;x=true\u0026amp;y=true\u0026amp;xTimesY=false\u0026amp;xSquared=false\u0026amp;ySquared=false\u0026amp;cosX=false\u0026amp;sinX=false\u0026amp;cosY=false\u0026amp;sinY=false\u0026amp;collectStats=false\u0026amp;problem=classification\u0026amp;initZero=false\u0026amp;hideText=false\u0026amp;regularization_hide=true\u0026amp;discretize_hide=true\u0026amp;regularizationRate_hide=true\u0026amp;percTrainData_hide=true\u0026amp;dataset_hide=true\u0026amp;problem_hide=true\u0026amp;noise_hide=true\u0026amp;batchSize_hide=true\" rel=\"nofollow\"\u003eTensorFlow Playground diagram\u003c/a\u003e below using TensorFlow code. Compile it using the Adam optimizer, binary crossentropy loss and accuracy metric. Once it's compiled check a summary of the model.\n\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/02-tensorflow-playground-replication-exercise.png\"\u003e\u003cimg src=\"https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/02-tensorflow-playground-replication-exercise.png\" alt=\"tensorflow playground example neural network\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003cem\u003eTry this network out for yourself on the \u003ca href=\"https://playground.tensorflow.org/#activation=relu\u0026amp;batchSize=10\u0026amp;dataset=circle\u0026amp;regDataset=reg-plane\u0026amp;learningRate=0.001\u0026amp;regularizationRate=0\u0026amp;noise=0\u0026amp;networkShape=6,6,6,6,6\u0026amp;seed=0.51287\u0026amp;showTestData=false\u0026amp;discretize=false\u0026amp;percTrainData=50\u0026amp;x=true\u0026amp;y=true\u0026amp;xTimesY=false\u0026amp;xSquared=false\u0026amp;ySquared=false\u0026amp;cosX=false\u0026amp;sinX=false\u0026amp;cosY=false\u0026amp;sinY=false\u0026amp;collectStats=false\u0026amp;problem=classification\u0026amp;initZero=false\u0026amp;hideText=false\u0026amp;regularization_hide=true\u0026amp;discretize_hide=true\u0026amp;regularizationRate_hide=true\u0026amp;percTrainData_hide=true\u0026amp;dataset_hide=true\u0026amp;problem_hide=true\u0026amp;noise_hide=true\u0026amp;batchSize_hide=true\" rel=\"nofollow\"\u003eTensorFlow Playground website\u003c/a\u003e. Hint: there are 5 hidden layers but the output layer isn't pictured, you'll have to decide what the output layer should be based on the input data.\u003c/em\u003e\u003c/li\u003e\n\u003cli\u003eCreate a classification dataset using Scikit-Learn's \u003ca href=\"https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html\" rel=\"nofollow\"\u003e\u003ccode\u003emake_moons()\u003c/code\u003e\u003c/a\u003e function, visualize it and then build a model to fit it at over 85% accuracy.\u003c/li\u003e\n\u003cli\u003eTrain a model to get 88%+ accuracy on the fashion MNIST test set. Plot a confusion matrix to see the results after.\u003c/li\u003e\n\u003cli\u003eRecreate \u003ca href=\"https://www.tensorflow.org/api_docs/python/tf/keras/activations/softmax\" rel=\"nofollow\"\u003eTensorFlow's\u003c/a\u003e \u003ca href=\"https://en.wikipedia.org/wiki/Softmax_function\" rel=\"nofollow\"\u003esoftmax activation function\u003c/a\u003e in your own code. Make sure it can accept a tensor and return that tensor after having the softmax function applied to it.\u003c/li\u003e\n\u003cli\u003eCreate a function (or write code) to visualize multiple image predictions for the fashion MNIST at the same time. Plot at least three different images and their prediction labels at the same time. Hint: see the \u003ca href=\"https://www.tensorflow.org/tutorials/keras/classification\" rel=\"nofollow\"\u003eclassification tutorial in the TensorFlow documentation\u003c/a\u003e for ideas.\u003c/li\u003e\n\u003cli\u003eMake a function to show an image of a certain class of the fashion MNIST dataset and make a prediction on it. For example, plot 3 images of the \u003ccode\u003eT-shirt\u003c/code\u003e class with their predictions.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e 02. Neural network classification with TensorFlow Extra-curriculum\u003c/h3\u003e\u003ca id=\"user-content--02-neural-network-classification-with-tensorflow-extra-curriculum\" class=\"anchor\" aria-label=\"Permalink:  02. Neural network classification with TensorFlow Extra-curriculum\" href=\"#-02-neural-network-classification-with-tensorflow-extra-curriculum\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eWatch 3Blue1Brown's neural networks video 2: \u003ca href=\"https://www.youtube.com/watch?v=IHZwWFHWa-w\" rel=\"nofollow\"\u003e\u003cem\u003eGradient descent, how neural networks learn\u003c/em\u003e\u003c/a\u003e. After you're done, write 100 words about what you've learned.\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eIf you haven't already, watch video 1: \u003ca href=\"https://www.youtube.com/watch?v=aircAruvnKk\" rel=\"nofollow\"\u003e\u003cem\u003eBut what is a Neural Network?\u003c/em\u003e\u003c/a\u003e. Note the activation function they talk about at the end.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eWatch \u003ca href=\"https://youtu.be/njKP3FqW3Sk\" rel=\"nofollow\"\u003eMIT's introduction to deep learning lecture 1\u003c/a\u003e (if you haven't already) to get an idea of the concepts behind using linear and non-linear functions.\u003c/li\u003e\n\u003cli\u003eSpend 1-hour reading \u003ca href=\"http://neuralnetworksanddeeplearning.com/index.html\" rel=\"nofollow\"\u003eMichael Nielsen's Neural Networks and Deep Learning book\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003eRead the \u003ca href=\"https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html\" rel=\"nofollow\"\u003eML-Glossary documentation on activation functions\u003c/a\u003e. Which one is your favourite?\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eAfter you've read the ML-Glossary, see which activation functions are available in TensorFlow by searching \"tensorflow activation functions\".\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e 03. Computer vision \u0026amp; convolutional neural networks in TensorFlow Exercises\u003c/h3\u003e\u003ca id=\"user-content--03-computer-vision--convolutional-neural-networks-in-tensorflow-exercises\" class=\"anchor\" aria-label=\"Permalink:  03. Computer vision \u0026amp; convolutional neural networks in TensorFlow Exercises\" href=\"#-03-computer-vision--convolutional-neural-networks-in-tensorflow-exercises\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003eSpend 20-minutes reading and interacting with the \u003ca href=\"https://poloclub.github.io/cnn-explainer/\" rel=\"nofollow\"\u003eCNN explainer website\u003c/a\u003e.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eWhat are the key terms? e.g. explain convolution in your own words, pooling in your own words\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"2\" dir=\"auto\"\u003e\n\u003cli\u003ePlay around with the \"understanding hyperparameters\" section in the \u003ca href=\"https://poloclub.github.io/cnn-explainer/\" rel=\"nofollow\"\u003eCNN explainer\u003c/a\u003e website for 10-minutes.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eWhat is the kernel size?\u003c/li\u003e\n\u003cli\u003eWhat is the stride?\u003c/li\u003e\n\u003cli\u003eHow could you adjust each of these in TensorFlow code?\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"3\" dir=\"auto\"\u003e\n\u003cli\u003eTake 10 photos of two different things and build your own CNN image classifier using the techniques we've built here.\u003c/li\u003e\n\u003cli\u003eFind an ideal learning rate for a simple convolutional neural network model on your the 10 class dataset.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e 03. Computer vision \u0026amp; convolutional neural networks in TensorFlow Extra-curriculum\u003c/h3\u003e\u003ca id=\"user-content--03-computer-vision--convolutional-neural-networks-in-tensorflow-extra-curriculum\" class=\"anchor\" aria-label=\"Permalink:  03. Computer vision \u0026amp; convolutional neural networks in TensorFlow Extra-curriculum\" href=\"#-03-computer-vision--convolutional-neural-networks-in-tensorflow-extra-curriculum\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003cstrong\u003eWatch:\u003c/strong\u003e \u003ca href=\"https://www.youtube.com/watch?v=uapdILWYTzE\u0026amp;list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI\u0026amp;index=3\u0026amp;ab_channel=AlexanderAmini\" rel=\"nofollow\"\u003eMIT's Introduction to Deep Computer Vision\u003c/a\u003e lecture. This will give you a great intuition behind convolutional neural networks.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eWatch:\u003c/strong\u003e Deep dive on \u003ca href=\"https://youtu.be/-_4Zi8fCZO4\" rel=\"nofollow\"\u003emini-batch gradient descent\u003c/a\u003e by deeplearning.ai. If you're still curious about why we use \u003cstrong\u003ebatches\u003c/strong\u003e to train models, this technical overview covers many of the reasons why.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRead:\u003c/strong\u003e \u003ca href=\"https://cs231n.github.io/convolutional-networks/\" rel=\"nofollow\"\u003eCS231n Convolutional Neural Networks for Visual Recognition\u003c/a\u003e class notes. This will give a very deep understanding of what's going on behind the scenes of the convolutional neural network architectures we're writing.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRead:\u003c/strong\u003e \u003ca href=\"https://arxiv.org/pdf/1603.07285.pdf\" rel=\"nofollow\"\u003e\"A guide to convolution arithmetic for deep learning\"\u003c/a\u003e. This paper goes through all of the mathematics running behind the scenes of our convolutional layers.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCode practice:\u003c/strong\u003e \u003ca href=\"https://www.tensorflow.org/tutorials/images/data_augmentation\" rel=\"nofollow\"\u003eTensorFlow Data Augmentation Tutorial\u003c/a\u003e. For a more in-depth introduction on data augmentation with TensorFlow, spend an hour or two reading through this tutorial.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e 04. Transfer Learning in TensorFlow Part 1: Feature Extraction Exercises\u003c/h3\u003e\u003ca id=\"user-content--04-transfer-learning-in-tensorflow-part-1-feature-extraction-exercises\" class=\"anchor\" aria-label=\"Permalink:  04. Transfer Learning in TensorFlow Part 1: Feature Extraction Exercises\" href=\"#-04-transfer-learning-in-tensorflow-part-1-feature-extraction-exercises\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003eBuild and fit a model using the same data we have here but with the MobileNetV2 architecture feature extraction (\u003ca href=\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\" rel=\"nofollow\"\u003e\u003ccode\u003emobilenet_v2_100_224/feature_vector\u003c/code\u003e\u003c/a\u003e) from TensorFlow Hub, how does it perform compared to our other models?\u003c/li\u003e\n\u003cli\u003eName 3 different image classification models on TensorFlow Hub that we haven't used.\u003c/li\u003e\n\u003cli\u003eBuild a model to classify images of two different things you've taken photos of.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eYou can use any feature extraction layer from TensorFlow Hub you like for this.\u003c/li\u003e\n\u003cli\u003eYou should aim to have at least 10 images of each class, for example to build a fridge versus oven classifier, you'll want 10 images of fridges and 10 images of ovens.\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"4\" dir=\"auto\"\u003e\n\u003cli\u003eWhat is the current best performing model on ImageNet?\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eHint: you might want to check \u003ca href=\"https://www.sotabench.com\" rel=\"nofollow\"\u003esotabench.com\u003c/a\u003e for this.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e 04. Transfer Learning in TensorFlow Part 1: Feature Extraction Extra-curriculum\u003c/h3\u003e\u003ca id=\"user-content--04-transfer-learning-in-tensorflow-part-1-feature-extraction-extra-curriculum\" class=\"anchor\" aria-label=\"Permalink:  04. Transfer Learning in TensorFlow Part 1: Feature Extraction Extra-curriculum\" href=\"#-04-transfer-learning-in-tensorflow-part-1-feature-extraction-extra-curriculum\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eRead through the \u003ca href=\"https://www.tensorflow.org/tutorials/images/transfer_learning\" rel=\"nofollow\"\u003eTensorFlow Transfer Learning Guide\u003c/a\u003e and define the main two types of transfer learning in your own words.\u003c/li\u003e\n\u003cli\u003eGo through the \u003ca href=\"https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub\" rel=\"nofollow\"\u003eTransfer Learning with TensorFlow Hub tutorial\u003c/a\u003e on the TensorFlow website and rewrite all of the code yourself into a new Google Colab notebook making comments about what each step does along the way.\u003c/li\u003e\n\u003cli\u003eWe haven't covered fine-tuning with TensorFlow Hub in this notebook, but if you'd like to know more, go through the \u003ca href=\"https://www.tensorflow.org/hub/tf2_saved_model#fine-tuning\" rel=\"nofollow\"\u003efine-tuning a TensorFlow Hub model tutorial\u003c/a\u003e on the TensorFlow homepage.How to fine-tune a tensorflow hub model:\u003c/li\u003e\n\u003cli\u003eLook into \u003ca href=\"https://www.wandb.com/experiment-tracking\" rel=\"nofollow\"\u003eexperiment tracking with Weights \u0026amp; Biases\u003c/a\u003e, how could you integrate it with our existing TensorBoard logs?\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e 05. Transfer Learning in TensorFlow Part 2: Fine-tuning Exercises\u003c/h3\u003e\u003ca id=\"user-content--05-transfer-learning-in-tensorflow-part-2-fine-tuning-exercises\" class=\"anchor\" aria-label=\"Permalink:  05. Transfer Learning in TensorFlow Part 2: Fine-tuning Exercises\" href=\"#-05-transfer-learning-in-tensorflow-part-2-fine-tuning-exercises\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003eUse feature-extraction to train a transfer learning model on 10% of the Food Vision data for 10 epochs using \u003ca href=\"https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB0\" rel=\"nofollow\"\u003e\u003ccode\u003etf.keras.applications.EfficientNetB0\u003c/code\u003e\u003c/a\u003e as the base model. Use the \u003ca href=\"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint\" rel=\"nofollow\"\u003e\u003ccode\u003eModelCheckpoint\u003c/code\u003e\u003c/a\u003e callback to save the weights to file.\u003c/li\u003e\n\u003cli\u003eFine-tune the last 20 layers of the base model you trained in 2 for another 10 epochs. How did it go?\u003c/li\u003e\n\u003cli\u003eFine-tune the last 30 layers of the base model you trained in 2 for another 10 epochs. How did it go?\u003c/li\u003e\n\u003cli\u003eWrite a function to visualize an image from any dataset (train or test file) and any class (e.g. \"steak\", \"pizza\"... etc), visualize it and make a prediction on it using a trained model.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e 05. Transfer Learning in TensorFlow Part 2: Fine-tuning Extra-curriculum\u003c/h3\u003e\u003ca id=\"user-content--05-transfer-learning-in-tensorflow-part-2-fine-tuning-extra-curriculum\" class=\"anchor\" aria-label=\"Permalink:  05. Transfer Learning in TensorFlow Part 2: Fine-tuning Extra-curriculum\" href=\"#-05-transfer-learning-in-tensorflow-part-2-fine-tuning-extra-curriculum\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eRead the \u003ca href=\"https://www.tensorflow.org/tutorials/images/data_augmentation\" rel=\"nofollow\"\u003edocumentation on data augmentation\u003c/a\u003e in TensorFlow.\u003c/li\u003e\n\u003cli\u003eRead the \u003ca href=\"https://arxiv.org/abs/1801.06146\" rel=\"nofollow\"\u003eULMFit paper\u003c/a\u003e (technical) for an introduction to the concept of freezing and unfreezing different layers.\u003c/li\u003e\n\u003cli\u003eRead up on learning rate scheduling (there's a \u003ca href=\"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LearningRateScheduler\" rel=\"nofollow\"\u003eTensorFlow callback\u003c/a\u003e for this), how could this influence our model training?\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eIf you're training for longer, you probably want to reduce the learning rate as you go... the closer you get to the bottom of the hill, the smaller steps you want to take. Imagine it like finding a coin at the bottom of your couch. In the beginning your arm movements are going to be large and the closer you get, the smaller your movements become.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e 06. Transfer Learning in TensorFlow Part 3: Scaling-up Exercises\u003c/h3\u003e\u003ca id=\"user-content--06-transfer-learning-in-tensorflow-part-3-scaling-up-exercises\" class=\"anchor\" aria-label=\"Permalink:  06. Transfer Learning in TensorFlow Part 3: Scaling-up Exercises\" href=\"#-06-transfer-learning-in-tensorflow-part-3-scaling-up-exercises\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003eTake 3 of your own photos of food and use the trained model to make predictions on them, share your predictions with the other students in Discord and show off your Food Vision model .\u003c/li\u003e\n\u003cli\u003eTrain a feature-extraction transfer learning model for 10 epochs on the same data and compare its performance versus a model which used feature extraction for 5 epochs and fine-tuning for 5 epochs (like we've used in this notebook). Which method is better?\u003c/li\u003e\n\u003cli\u003eRecreate the first model (the feature extraction model) with \u003ca href=\"https://www.tensorflow.org/guide/mixed_precision\" rel=\"nofollow\"\u003e\u003ccode\u003emixed_precision\u003c/code\u003e\u003c/a\u003e turned on.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eDoes it make the model train faster?\u003c/li\u003e\n\u003cli\u003eDoes it effect the accuracy or performance of our model?\u003c/li\u003e\n\u003cli\u003eWhat's the advantages of using \u003ccode\u003emixed_precision\u003c/code\u003e training?\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e 06. Transfer Learning in TensorFlow Part 3: Scaling-up Extra-curriculum\u003c/h3\u003e\u003ca id=\"user-content--06-transfer-learning-in-tensorflow-part-3-scaling-up-extra-curriculum\" class=\"anchor\" aria-label=\"Permalink:  06. Transfer Learning in TensorFlow Part 3: Scaling-up Extra-curriculum\" href=\"#-06-transfer-learning-in-tensorflow-part-3-scaling-up-extra-curriculum\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eSpend 15-minutes reading up on the \u003ca href=\"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\" rel=\"nofollow\"\u003eEarlyStopping callback\u003c/a\u003e. What does it do? How could we use it in our model training?\u003c/li\u003e\n\u003cli\u003eSpend an hour reading about \u003ca href=\"https://www.streamlit.io/\" rel=\"nofollow\"\u003eStreamlit\u003c/a\u003e. What does it do? How might you integrate some of the things we've done in this notebook in a Streamlit app?\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e 07. Milestone Project 1:  Food Vision Big Exercises\u003c/h3\u003e\u003ca id=\"user-content--07-milestone-project-1--food-vision-big-exercises\" class=\"anchor\" aria-label=\"Permalink:  07. Milestone Project 1:  Food Vision Big Exercises\" href=\"#-07-milestone-project-1--food-vision-big-exercises\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eNote:\u003c/strong\u003e The chief exercise for Milestone Project 1 is to finish the \"TODO\" sections in the \u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/TEMPLATE_07_food_vision_milestone_project_1.ipynb\"\u003eMilestone Project 1 Template notebook\u003c/a\u003e. After doing so, move onto the following.\u003c/p\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003eUse the same evaluation techniques on the large-scale Food Vision model as you did in the previous notebook (\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/06_transfer_learning_in_tensorflow_part_3_scaling_up.ipynb\"\u003eTransfer Learning Part 3: Scaling up\u003c/a\u003e). More specifically, it would be good to see:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eA confusion matrix between all of the model's predictions and true labels.\u003c/li\u003e\n\u003cli\u003eA graph showing the f1-scores of each class.\u003c/li\u003e\n\u003cli\u003eA visualization of the model making predictions on various images and comparing the predictions to the ground truth.\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eFor example, plot a sample image from the test dataset and have the title of the plot show the prediction, the prediction probability and the ground truth label.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eNote:\u003c/strong\u003e To compare predicted labels to test labels, it might be a good idea when loading the test data to set \u003ccode\u003eshuffle=False\u003c/code\u003e (so the ordering of test data is preserved alongside the order of predicted labels).\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"2\" dir=\"auto\"\u003e\n\u003cli\u003eTake 3 of your own photos of food and use the Food Vision model to make predictions on them. How does it go? Share your images/predictions with the other students.\u003c/li\u003e\n\u003cli\u003eRetrain the model (feature extraction and fine-tuning) we trained in this notebook, except this time use \u003ca href=\"https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB4\" rel=\"nofollow\"\u003e\u003ccode\u003eEfficientNetB4\u003c/code\u003e\u003c/a\u003e as the base model instead of \u003ccode\u003eEfficientNetB0\u003c/code\u003e. Do you notice an improvement in performance? Does it take longer to train? Are there any tradeoffs to consider?\u003c/li\u003e\n\u003cli\u003eName one important benefit of mixed precision training, how does this benefit take place?\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e 07. Milestone Project 1:  Food Vision Big Extra-curriculum\u003c/h3\u003e\u003ca id=\"user-content--07-milestone-project-1--food-vision-big-extra-curriculum\" class=\"anchor\" aria-label=\"Permalink:  07. Milestone Project 1:  Food Vision Big Extra-curriculum\" href=\"#-07-milestone-project-1--food-vision-big-extra-curriculum\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eRead up on learning rate scheduling and the \u003ca href=\"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LearningRateScheduler\" rel=\"nofollow\"\u003elearning rate scheduler callback\u003c/a\u003e. What is it? And how might it be helpful to this project?\u003c/li\u003e\n\u003cli\u003eRead up on TensorFlow data loaders (\u003ca href=\"https://www.tensorflow.org/guide/data_performance\" rel=\"nofollow\"\u003eimproving TensorFlow data loading performance\u003c/a\u003e). Is there anything we've missed? What methods you keep in mind whenever loading data in TensorFlow? Hint: check the summary at the bottom of the page for a great round up of ideas.\u003c/li\u003e\n\u003cli\u003eRead up on the documentation for \u003ca href=\"https://www.tensorflow.org/guide/mixed_precision\" rel=\"nofollow\"\u003eTensorFlow mixed precision training\u003c/a\u003e. What are the important things to keep in mind when using mixed precision training?\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e 08. Introduction to NLP (Natural Language Processing) in TensorFlow Exercises\u003c/h3\u003e\u003ca id=\"user-content--08-introduction-to-nlp-natural-language-processing-in-tensorflow-exercises\" class=\"anchor\" aria-label=\"Permalink:  08. Introduction to NLP (Natural Language Processing) in TensorFlow Exercises\" href=\"#-08-introduction-to-nlp-natural-language-processing-in-tensorflow-exercises\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003eRebuild, compile and train \u003ccode\u003emodel_1\u003c/code\u003e, \u003ccode\u003emodel_2\u003c/code\u003e and \u003ccode\u003emodel_5\u003c/code\u003e using the \u003ca href=\"https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\" rel=\"nofollow\"\u003eKeras Sequential API\u003c/a\u003e instead of the Functional API.\u003c/li\u003e\n\u003cli\u003eRetrain the baseline model with 10% of the training data. How does perform compared to the Universal Sentence Encoder model with 10% of the training data?\u003c/li\u003e\n\u003cli\u003eTry fine-tuning the TF Hub Universal Sentence Encoder model by setting \u003ccode\u003etraining=True\u003c/code\u003e when instantiating it as a Keras layer.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"snippet-clipboard-content notranslate position-relative overflow-auto\" data-snippet-clipboard-copy-content=\"# We can use this encoding layer in place of our text_vectorizer and embedding layer\nsentence_encoder_layer = hub.KerasLayer(\u0026quot;https://tfhub.dev/google/universal-sentence-encoder/4\u0026quot;,\n                                        input_shape=[],\n                                        dtype=tf.string,\n                                        trainable=True) # turn training on to fine-tune the TensorFlow Hub model\"\u003e\u003cpre class=\"notranslate\"\u003e\u003ccode\u003e# We can use this encoding layer in place of our text_vectorizer and embedding layer\nsentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n                                        input_shape=[],\n                                        dtype=tf.string,\n                                        trainable=True) # turn training on to fine-tune the TensorFlow Hub model\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\n\u003col start=\"4\" dir=\"auto\"\u003e\n\u003cli\u003eRetrain the best model you've got so far on the whole training set (no validation split). Then use this trained model to make predictions on the test dataset and format the predictions into the same format as the \u003ccode\u003esample_submission.csv\u003c/code\u003e file from Kaggle (see the Files tab in Colab for what the \u003ccode\u003esample_submission.csv\u003c/code\u003e file looks like). Once you've done this, \u003ca href=\"https://www.kaggle.com/c/nlp-getting-started/data\" rel=\"nofollow\"\u003emake a submission to the Kaggle competition\u003c/a\u003e, how did your model perform?\u003c/li\u003e\n\u003cli\u003eCombine the ensemble predictions using the majority vote (mode), how does this perform compare to averaging the prediction probabilities of each model?\u003c/li\u003e\n\u003cli\u003eMake a confusion matrix with the best performing model's predictions on the validation set and the validation ground truth labels.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e 08. Introduction to NLP (Natural Language Processing) in TensorFlow Extra-curriculum\u003c/h3\u003e\u003ca id=\"user-content--08-introduction-to-nlp-natural-language-processing-in-tensorflow-extra-curriculum\" class=\"anchor\" aria-label=\"Permalink:  08. Introduction to NLP (Natural Language Processing) in TensorFlow Extra-curriculum\" href=\"#-08-introduction-to-nlp-natural-language-processing-in-tensorflow-extra-curriculum\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003eTo practice what you've learned, a good idea would be to spend an hour on 3 of the following (3-hours total, you could through them all if you want) and then write a blog post about what you've learned.\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eFor an overview of the different problems within NLP and how to solve them read through:\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32\" rel=\"nofollow\"\u003eA Simple Introduction to Natural Language Processing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e\" rel=\"nofollow\"\u003eHow to solve 90% of NLP problems: a step-by-step guide\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eGo through \u003ca href=\"https://youtu.be/SEnXr6v2ifU\" rel=\"nofollow\"\u003eMIT's Recurrent Neural Networks lecture\u003c/a\u003e. This will be one of the greatest additions to what's happening behind the RNN model's you've been building.\u003c/li\u003e\n\u003cli\u003eRead through the \u003ca href=\"https://www.tensorflow.org/tutorials/text/word_embeddings\" rel=\"nofollow\"\u003eword embeddings page on the TensorFlow website\u003c/a\u003e. Embeddings are such a large part of NLP. We've covered them throughout this notebook but extra practice would be well worth it. A good exercise would be to write out all the code in the guide in a new notebook.\u003c/li\u003e\n\u003cli\u003eFor more on RNN's in TensorFlow, read and reproduce \u003ca href=\"https://www.tensorflow.org/guide/keras/rnn\" rel=\"nofollow\"\u003ethe TensorFlow RNN guide\u003c/a\u003e. We've covered many of the concepts in this guide, but it's worth writing the code again for yourself.\u003c/li\u003e\n\u003cli\u003eText data doesn't always come in a nice package like the data we've downloaded. So if you're after more on preparing different text sources for being with your TensorFlow deep learning models, it's worth checking out the following:\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://www.tensorflow.org/tutorials/load_data/text\" rel=\"nofollow\"\u003eTensorFlow text loading tutorial\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://realpython.com/read-write-files-python/\" rel=\"nofollow\"\u003eReading text files with Python\u003c/a\u003e by Real Python.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eThis notebook has focused on writing NLP code. For a mathematically rich overview of how NLP with Deep Learning happens, read \u003ca href=\"https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes01-wordvecs1.pdf\" rel=\"nofollow\"\u003eStanford's Natural Language Processing with Deep Learning lecture notes Part 1\u003c/a\u003e.\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eFor an even deeper dive, you could even do the whole \u003ca href=\"http://web.stanford.edu/class/cs224n/\" rel=\"nofollow\"\u003eCS224n\u003c/a\u003e (Natural Language Processing with Deep Learning) course.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eGreat blog posts to read:\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eAndrei Karpathy's \u003ca href=\"https://karpathy.github.io/2015/05/21/rnn-effectiveness/\" rel=\"nofollow\"\u003eThe Unreasonable Effectiveness of RNNs\u003c/a\u003e dives into generating Shakespeare text with RNNs.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://towardsdatascience.com/text-classification-with-nlp-tf-idf-vs-word2vec-vs-bert-41ff868d1794\" rel=\"nofollow\"\u003eText Classification with NLP: Tf-Idf vs Word2Vec vs BERT\u003c/a\u003e by Mauro Di Pietro. An overview of different techniques for turning text into numbers and then classifying it.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://machinelearningmastery.com/what-are-word-embeddings/\" rel=\"nofollow\"\u003eWhat are word embeddings?\u003c/a\u003e by Machine Learning Mastery.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eOther topics worth looking into:\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\" rel=\"nofollow\"\u003eAttention mechanisms\u003c/a\u003e. These are a foundational component of the transformer architecture and also often add improvements to deep NLP models.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://jalammar.github.io/illustrated-transformer/\" rel=\"nofollow\"\u003eTransformer architectures\u003c/a\u003e. This model architecture has recently taken the NLP world by storm, achieving state of the art on many benchmarks. However, it does take a little more processing to get off the ground, the \u003ca href=\"https://huggingface.co/models/\" rel=\"nofollow\"\u003eHuggingFace Models (formerly HuggingFace Transformers) library\u003c/a\u003e is probably your best quick start.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e 09. Milestone Project 2: SkimLit  Exercises\u003c/h3\u003e\u003ca id=\"user-content--09-milestone-project-2-skimlit--exercises\" class=\"anchor\" aria-label=\"Permalink:  09. Milestone Project 2: SkimLit  Exercises\" href=\"#-09-milestone-project-2-skimlit--exercises\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003eTrain \u003ccode\u003emodel_5\u003c/code\u003e on all of the data in the training dataset for as many epochs until it stops improving. Since this might take a while, you might want to use:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint\" rel=\"nofollow\"\u003e\u003ccode\u003etf.keras.callbacks.ModelCheckpoint\u003c/code\u003e\u003c/a\u003e to save the model's best weights only.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\" rel=\"nofollow\"\u003e\u003ccode\u003etf.keras.callbacks.EarlyStopping\u003c/code\u003e\u003c/a\u003e to stop the model from training once the validation loss has stopped improving for ~3 epochs.\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"2\" dir=\"auto\"\u003e\n\u003cli\u003eCheckout the \u003ca href=\"https://keras.io/examples/nlp/pretrained_word_embeddings/\" rel=\"nofollow\"\u003eKeras guide on using pretrained GloVe embeddings\u003c/a\u003e. Can you get this working with one of our models?\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eHint: You'll want to incorporate it with a custom token \u003ca href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\" rel=\"nofollow\"\u003eEmbedding\u003c/a\u003e layer.\u003c/li\u003e\n\u003cli\u003eIt's up to you whether or not you fine-tune the GloVe embeddings or leave them frozen.\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"3\" dir=\"auto\"\u003e\n\u003cli\u003eTry replacing the TensorFlow Hub Universal Sentence Encoder pretrained  embedding for the \u003ca href=\"https://tfhub.dev/google/experts/bert/pubmed/2\" rel=\"nofollow\"\u003eTensorFlow Hub BERT PubMed expert\u003c/a\u003e (a language model pretrained on PubMed texts) pretrained embedding. Does this effect results?\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eNote: Using the BERT PubMed expert pretrained embedding requires an extra preprocessing step for sequences (as detailed in the \u003ca href=\"https://tfhub.dev/google/experts/bert/pubmed/2\" rel=\"nofollow\"\u003eTensorFlow Hub guide\u003c/a\u003e).\u003c/li\u003e\n\u003cli\u003eDoes the BERT model beat the results mentioned in this paper? \u003ca href=\"https://arxiv.org/pdf/1710.06071.pdf\" rel=\"nofollow\"\u003ehttps://arxiv.org/pdf/1710.06071.pdf\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"4\" dir=\"auto\"\u003e\n\u003cli\u003eWhat happens if you were to merge our \u003ccode\u003eline_number\u003c/code\u003e and \u003ccode\u003etotal_lines\u003c/code\u003e features for each sequence? For example, created a \u003ccode\u003eX_of_Y\u003c/code\u003e feature instead? Does this effect model performance?\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eAnother example: \u003ccode\u003eline_number=1\u003c/code\u003e and \u003ccode\u003etotal_lines=11\u003c/code\u003e turns into \u003ccode\u003eline_of_X=1_of_11\u003c/code\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"5\" dir=\"auto\"\u003e\n\u003cli\u003eWrite a function (or series of functions) to take a sample abstract string, preprocess it (in the same way our model has been trained), make a prediction on each sequence in the abstract and return the abstract in the format:\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ccode\u003ePREDICTED_LABEL\u003c/code\u003e: \u003ccode\u003eSEQUENCE\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ePREDICTED_LABEL\u003c/code\u003e: \u003ccode\u003eSEQUENCE\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ePREDICTED_LABEL\u003c/code\u003e: \u003ccode\u003eSEQUENCE\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ePREDICTED_LABEL\u003c/code\u003e: \u003ccode\u003eSEQUENCE\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e...\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eYou can find your own unstructured RCT abstract from PubMed or try this one from: \u003ca href=\"https://pubmed.ncbi.nlm.nih.gov/22244707/\" rel=\"nofollow\"\u003e\u003cem\u003eBaclofen promotes alcohol abstinence in alcohol dependent cirrhotic patients with hepatitis C virus (HCV) infection\u003c/em\u003e\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e 09. Milestone Project 2: SkimLit  Extra-curriculum\u003c/h3\u003e\u003ca id=\"user-content--09-milestone-project-2-skimlit--extra-curriculum\" class=\"anchor\" aria-label=\"Permalink:  09. Milestone Project 2: SkimLit  Extra-curriculum\" href=\"#-09-milestone-project-2-skimlit--extra-curriculum\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eFor more on working with text/spaCy, see \u003ca href=\"https://course.spacy.io/en/\" rel=\"nofollow\"\u003espaCy's advanced NLP course\u003c/a\u003e. If you're going to be working on production-level NLP problems, you'll probably end up using spaCy.\u003c/li\u003e\n\u003cli\u003eFor another look at how to approach a text classification problem like the one we've just gone through, I'd suggest going through \u003ca href=\"https://developers.google.com/machine-learning/guides/text-classification\" rel=\"nofollow\"\u003eGoogle's Machine Learning Course for text classification\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003eSince our dataset has imbalanced classes (as with many real-world datasets), so it might be worth looking into the \u003ca href=\"https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\" rel=\"nofollow\"\u003eTensorFlow guide for different methods to training a model with imbalanced classes\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e 10. Time series fundamentals and Milestone Project 3: BitPredict  Exercises\u003c/h3\u003e\u003ca id=\"user-content--10-time-series-fundamentals-and-milestone-project-3-bitpredict--exercises\" class=\"anchor\" aria-label=\"Permalink:  10. Time series fundamentals and Milestone Project 3: BitPredict  Exercises\" href=\"#-10-time-series-fundamentals-and-milestone-project-3-bitpredict--exercises\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003eDoes scaling the data help for univariate/multivariate data? (e.g. getting all of the values between 0 \u0026amp; 1)\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eTry doing this for a univariate model (e.g. \u003ccode\u003emodel_1\u003c/code\u003e) and a multivariate model (e.g. \u003ccode\u003emodel_6\u003c/code\u003e) and see if it effects model training or evaluation results.\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"2\" dir=\"auto\"\u003e\n\u003cli\u003eGet the most up to date data on Bitcoin, train a model \u0026amp; see how it goes (our data goes up to May 18 2021).\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eYou can download the Bitcoin historical data for free from \u003ca href=\"https://www.coindesk.com/price/bitcoin\" rel=\"nofollow\"\u003ecoindesk.com/price/bitcoin\u003c/a\u003e and clicking \"Export Data\" -\u0026gt; \"CSV\".\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"3\" dir=\"auto\"\u003e\n\u003cli\u003eFor most of our models we used \u003ccode\u003eWINDOW_SIZE=7\u003c/code\u003e, but is there a better window size?\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eSetup a series of experiments to find whether or not there's a better window size.\u003c/li\u003e\n\u003cli\u003eFor example, you might train 10 different models with \u003ccode\u003eHORIZON=1\u003c/code\u003e but with window sizes ranging from 2-12.\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"4\" dir=\"auto\"\u003e\n\u003cli\u003eCreate a windowed dataset just like the ones we used for \u003ccode\u003emodel_1\u003c/code\u003e using \u003ca href=\"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/timeseries_dataset_from_array\" rel=\"nofollow\"\u003e\u003ccode\u003etf.keras.preprocessing.timeseries_dataset_from_array()\u003c/code\u003e\u003c/a\u003e and retrain \u003ccode\u003emodel_1\u003c/code\u003e using the recreated dataset.\u003c/li\u003e\n\u003cli\u003eFor our multivariate modelling experiment, we added the Bitcoin block reward size as an extra feature to make our time series multivariate.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eAre there any other features you think you could add?\u003c/li\u003e\n\u003cli\u003eIf so, try it out, how do these affect the model?\u003c/li\u003e\n\u003c/ul\u003e\n\u003col start=\"6\" dir=\"auto\"\u003e\n\u003cli\u003eMake prediction intervals for future forecasts. To do so, one way would be to train an ensemble model on all of the data, make future forecasts with it and calculate the prediction intervals of the ensemble just like we did for \u003ccode\u003emodel_8\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eFor future predictions, try to make a prediction, retrain a model on the predictions, make a prediction, retrain a model, make a prediction, retrain a model, make a prediction (retrain a model each time a new prediction is made). Plot the results, how do they look compared to the future predictions where a model wasn't retrained for every forecast (\u003ccode\u003emodel_9\u003c/code\u003e)?\u003c/li\u003e\n\u003cli\u003eThroughout this notebook, we've only tried algorithms we've handcrafted ourselves. But it's worth seeing how a purpose built forecasting algorithm goes.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eTry out one of the extra algorithms listed in the modelling experiments part such as:\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/facebookresearch/Kats\"\u003eFacebook's Kats library\u003c/a\u003e - there are many models in here, remember the machine learning practioner's motto: experiment, experiment, experiment.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/linkedin/greykite\"\u003eLinkedIn's Greykite library\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e 10. Time series fundamentals and Milestone Project 3: BitPredict  Extra-curriculum\u003c/h3\u003e\u003ca id=\"user-content--10-time-series-fundamentals-and-milestone-project-3-bitpredict--extra-curriculum\" class=\"anchor\" aria-label=\"Permalink:  10. Time series fundamentals and Milestone Project 3: BitPredict  Extra-curriculum\" href=\"#-10-time-series-fundamentals-and-milestone-project-3-bitpredict--extra-curriculum\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003eWe've only really scratched the surface with time series forecasting and time series modelling in general. But the good news is, you've got plenty of hands-on coding experience with it already.\u003c/p\u003e\n\u003cp dir=\"auto\"\u003eIf you'd like to dig deeper in to the world of time series, I'd recommend the following:\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://otexts.com/fpp3/\" rel=\"nofollow\"\u003eForecasting: Principles and Practice\u003c/a\u003e is an outstanding online textbook which discusses at length many of the most important concepts in time series forecasting. I'd especially recommend reading at least Chapter 1 in full.\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eI'd definitely recommend at least checking out chapter 1 as well as the chapter on forecasting accuracy measures.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e \u003ca href=\"https://youtu.be/wqQKFu41FIw\" rel=\"nofollow\"\u003eIntroduction to machine learning and time series\u003c/a\u003e by Markus Loning goes through different time series problems and how to approach them. It focuses on using the \u003ccode\u003esktime\u003c/code\u003e library (Scikit-Learn for time series), though the principles are applicable elsewhere.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://towardsdatascience.com/why-you-should-care-about-the-nate-silver-vs-nassim-taleb-twitter-war-a581dce1f5fc\" rel=\"nofollow\"\u003e\u003cem\u003eWhy you should care about the Nate Silver vs. Nassim Taleb Twitter war\u003c/em\u003e\u003c/a\u003e by Isaac Faber is an outstanding discussion insight into the role of uncertainty in the example of election prediction.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.tensorflow.org/tutorials/structured_data/time_series\" rel=\"nofollow\"\u003eTensorFlow time series tutorial\u003c/a\u003e - A tutorial on using TensorFlow to forecast weather time series data with TensorFlow.\u003c/li\u003e\n\u003cli\u003e \u003ca href=\"https://en.wikipedia.org/wiki/The_Black_Swan:_The_Impact_of_the_Highly_Improbable\" rel=\"nofollow\"\u003e\u003cem\u003eThe Black Swan\u003c/em\u003e\u003c/a\u003e by Nassim Nicholas Taleb - Nassim Taleb was a pit trader (a trader who trades on their own behalf) for 25 years, this book compiles many of the lessons he learned from first-hand experience. It changed my whole perspective on our ability to predict.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://towardsdatascience.com/3-facts-about-time-series-forecasting-that-surprise-experienced-machine-learning-practitioners-69c18ee89387\" rel=\"nofollow\"\u003e\u003cem\u003e3 facts about time series forecasting that surprise experienced machine learning practitioners\u003c/em\u003e\u003c/a\u003e by Skander Hannachi, Ph.D - time series data is different to other kinds of data, if you've worked on other kinds of machine learning problems before, getting into time series might require some adjustments, Hannachi outlines 3 of the most common.\u003c/li\u003e\n\u003cli\u003e World-class lectures by\nJordan Kern, watching these will take you from 0 to 1 with time series problems:\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"https://youtu.be/Prpu_U5tKkE\" rel=\"nofollow\"\u003eTime Series Analysis\u003c/a\u003e - how to analyse time series data.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=s3XH7fTHMb4\" rel=\"nofollow\"\u003eTime Series Modelling\u003c/a\u003e - different techniques for modelling time series data (many of which aren't deep learning).\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eTensorFlow Developer Certificate (archive)\u003c/h2\u003e\u003ca id=\"user-content-tensorflow-developer-certificate-archive\" class=\"anchor\" aria-label=\"Permalink: TensorFlow Developer Certificate (archive)\" href=\"#tensorflow-developer-certificate-archive\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cblockquote\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003eNote:\u003c/strong\u003e As of 1 May 2024, the TensorFlow Developer Certification is no longer available for purchase. After being in contact with the TensorFlow Certification team, they stated they were closing the program with no official next steps (see \u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/discussions/645\" data-hovercard-type=\"discussion\" data-hovercard-url=\"/mrdbourke/tensorflow-deep-learning/discussions/645/hovercard\"\u003e#645\u003c/a\u003e for more).\u003c/p\u003e\n\u003cp dir=\"auto\"\u003eWith this in mind, the exercises/extra-curriculum below are for archive purposes only. The rest of the course materials are still valid.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e 11. Passing the TensorFlow Developer Certification Exercises (archive)\u003c/h3\u003e\u003ca id=\"user-content--11-passing-the-tensorflow-developer-certification-exercises-archive\" class=\"anchor\" aria-label=\"Permalink:  11. Passing the TensorFlow Developer Certification Exercises (archive)\" href=\"#-11-passing-the-tensorflow-developer-certification-exercises-archive\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePreparing your brain\u003c/strong\u003e\u003c/p\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003eRead through the \u003ca href=\"https://www.tensorflow.org/extras/cert/TF_Certificate_Candidate_Handbook.pdf\" rel=\"nofollow\"\u003eTensorFlow Developer Certificate Candidate Handbook\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003eGo through the Skills checklist section of the TensorFlow Developer Certification Candidate Handbook and create a notebook which covers all of the skills required, write code for each of these (this notebook can be used as a point of reference during the exam).\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp dir=\"auto\"\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/11-map-the-skills-checklist-to-a-notebook.png\"\u003e\u003cimg src=\"https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/11-map-the-skills-checklist-to-a-notebook.png\" alt=\"mapping the TensorFlow Developer handbook to code in a notebook\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003cem\u003eExample of mapping the Skills checklist section of the TensorFlow Developer Certification Candidate handbook to a notebook.\u003c/em\u003e\u003c/p\u003e\n\u003cp dir=\"auto\"\u003e\u003cstrong\u003ePrearing your computer\u003c/strong\u003e\u003c/p\u003e\n\u003col dir=\"auto\"\u003e\n\u003cli\u003eGo through the \u003ca href=\"https://www.jetbrains.com/pycharm/learning-center/\" rel=\"nofollow\"\u003ePyCharm quick start\u003c/a\u003e tutorials to make sure you're familiar with PyCharm (the exam uses PyCharm, you can download the free version).\u003c/li\u003e\n\u003cli\u003eRead through and follow the suggested steps in the \u003ca href=\"https://www.tensorflow.org/extras/cert/Setting_Up_TF_Developer_Certificate_Exam.pdf\" rel=\"nofollow\"\u003esetting up for the TensorFlow Developer Certificate Exam guide\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003eAfter going through (2), go into PyCharm and make sure you can train a model in TensorFlow. The model and dataset in the example \u003ccode\u003eimage_classification_test.py\u003c/code\u003e \u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/image_classification_test.py\"\u003escript on GitHub\u003c/a\u003e should be enough. If you can train and save the model in under 5-10 minutes, your computer will be powerful enough to train the models in the exam.\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eMake sure you've got experience running models locally in PyCharm before taking the exam. Google Colab (what we used through the course) is a little different to PyCharm.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp dir=\"auto\"\u003e\u003ca target=\"_blank\" rel=\"noopener noreferrer nofollow\" href=\"https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/11-getting-example-script-to-run-in-pycharm.png\"\u003e\u003cimg src=\"https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/11-getting-example-script-to-run-in-pycharm.png\" alt=\"before taking the TensorFlow Developer certification exam, make sure you can run TensorFlow code in PyCharm on your local machine\" style=\"max-width: 100%;\"\u003e\u003c/a\u003e\n\u003cem\u003eBefore taking the exam make sure you can run TensorFlow code on your local machine in PyCharm. If the \u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/image_classification_test.py\"\u003eexample \u003ccode\u003eimage_class_test.py\u003c/code\u003e script\u003c/a\u003e can run completely in under 5-10 minutes on your local machine, your local machine can handle the exam (if not, you can use Google Colab to train, save and download models to submit for the exam).\u003c/em\u003e\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch3 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003e 11. Passing the TensorFlow Developer Certification Extra-curriculum (archive)\u003c/h3\u003e\u003ca id=\"user-content--11-passing-the-tensorflow-developer-certification-extra-curriculum-archive\" class=\"anchor\" aria-label=\"Permalink:  11. Passing the TensorFlow Developer Certification Extra-curriculum (archive)\" href=\"#-11-passing-the-tensorflow-developer-certification-extra-curriculum-archive\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003eIf you'd like some extra materials to go through to further your skills with TensorFlow and deep learning in general or to prepare more for the exam, I'd highly recommend the following:\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e \u003cstrong\u003eRead:\u003c/strong\u003e \u003ca href=\"https://www.mrdbourke.com/how-i-got-tensorflow-developer-certified/\" rel=\"nofollow\"\u003eHow I got TensorFlow Developer Certified (and how you can too)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e \u003cstrong\u003eWatch:\u003c/strong\u003e \u003ca href=\"https://youtu.be/ya5NwvKafDk\" rel=\"nofollow\"\u003eHow I passed the TensorFlow Developer Certification exam (and how you can too)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eGo through the \u003ca href=\"https://dbourke.link/tfinpractice\" rel=\"nofollow\"\u003eTensorFlow in Practice Specialization on Coursera\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eRead through the second half of \u003ca href=\"https://amzn.to/3aYexF2\" rel=\"nofollow\"\u003eHands-On Machine Learning with Scikit-Learn, Keras \u0026amp; TensorFlow 2nd Edition\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eWhat this course is missing\u003c/h2\u003e\u003ca id=\"user-content-what-this-course-is-missing\" class=\"anchor\" aria-label=\"Permalink: What this course is missing\" href=\"#what-this-course-is-missing\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003eDeep learning is a broad topic. So this course doesn't cover it all.\u003c/p\u003e\n\u003cp dir=\"auto\"\u003eHere are some of the main topics you might want to look into next:\u003c/p\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003eTransformers (the neural network architecture taking the NLP world by storm)\u003c/li\u003e\n\u003cli\u003eMulti-modal models (models which use more than one data source such as text \u0026amp; images)\u003c/li\u003e\n\u003cli\u003eReinforcement learning\u003c/li\u003e\n\u003cli\u003eUnsupervised learning\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eExtensions (possible places to go after the course)\u003c/h2\u003e\u003ca id=\"user-content-extensions-possible-places-to-go-after-the-course\" class=\"anchor\" aria-label=\"Permalink: Extensions (possible places to go after the course)\" href=\"#extensions-possible-places-to-go-after-the-course\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e\u003ca href=\"http://neuralnetworksanddeeplearning.com/\" rel=\"nofollow\"\u003eNeural Networks and Deep Learning Book\u003c/a\u003e by Michael Nielsen - If the Zero to Mastery TensorFlow for Deep Learning course is top down, this book is bottom up. A fantastic resource to sandwich your knowledge.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.deeplearning.ai\" rel=\"nofollow\"\u003eDeeplearning.AI specializations\u003c/a\u003e - The ZTM TensorFLow course focuses on code-first, the deeplearning.ai specializations will teach you what's going on behind the code.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/\" rel=\"nofollow\"\u003eHands-on Machine Learning with Scikit-Learn, Keras and TensorFlow Book\u003c/a\u003e (especially the 2nd half) - Many of the materials in this course were inspired by and guided by the pages of this beautiful text book.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://fullstackdeeplearning.com\" rel=\"nofollow\"\u003eFull Stack Deep Learning\u003c/a\u003e - Learn how to turn your models into machine learning-powered applications.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://madewithml.com/#mlops\" rel=\"nofollow\"\u003eMade with ML MLOps materials\u003c/a\u003e - Similar to Full Stack Deep Learning but comprised into many small lessons around all the pieces of the puzzle (data collection, labelling, deployment and more) required to build a full-stack machine learning-powered application.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.fast.ai\" rel=\"nofollow\"\u003efast.ai Curriculum\u003c/a\u003e - One of the best (and free) AI/deep learning courses online. Enough said.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.mrdbourke.com/how-can-a-beginner-data-scientist-like-me-gain-experience/\" rel=\"nofollow\"\u003e\"How does a beginner data scientist like me gain experience?\"\u003c/a\u003e by Daniel Bourke - Read this on how to get experience for a job after studying online/at unveristy (start the job before you have it).\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eAsk questions\u003c/h2\u003e\u003ca id=\"user-content-ask-questions\" class=\"anchor\" aria-label=\"Permalink: Ask questions\" href=\"#ask-questions\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cp dir=\"auto\"\u003eContact \u003ca href=\"mailto:daniel@mrdbourke.com\"\u003eDaniel Bourke\u003c/a\u003e or \u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/discussions\"\u003eadd a discussion\u003c/a\u003e (preferred).\u003c/p\u003e\n\u003cdiv class=\"markdown-heading\" dir=\"auto\"\u003e\u003ch2 tabindex=\"-1\" class=\"heading-element\" dir=\"auto\"\u003eLog\u003c/h2\u003e\u003ca id=\"user-content-log\" class=\"anchor\" aria-label=\"Permalink: Log\" href=\"#log\"\u003e\u003csvg class=\"octicon octicon-link\" viewBox=\"0 0 16 16\" version=\"1.1\" width=\"16\" height=\"16\" aria-hidden=\"true\"\u003e\u003cpath d=\"m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z\"\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/div\u003e\n\u003cul dir=\"auto\"\u003e\n\u003cli\u003e2 May 2024 - update materials to reflect closing of TensorFlow Developer Certification exam by Google (see \u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/discussions/645\" data-hovercard-type=\"discussion\" data-hovercard-url=\"/mrdbourke/tensorflow-deep-learning/discussions/645/hovercard\"\u003e#645\u003c/a\u003e for more)\u003c/li\u003e\n\u003cli\u003e12 May 2023 - update several course notebooks for latest version of TensorFlow, several API updates for Notebook 05 here: \u003ca class=\"issue-link js-issue-link\" data-error-text=\"Failed to load title\" data-id=\"5187992\" data-permission-text=\"Title is private\" data-url=\"https://github.com/mrdbourke/tensorflow-deep-learning/discussions/547\" data-hovercard-type=\"discussion\" data-hovercard-url=\"/mrdbourke/tensorflow-deep-learning/discussions/547/hovercard\" href=\"https://github.com/mrdbourke/tensorflow-deep-learning/discussions/547\"\u003e#547\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e02 Dec 2021 - add fix for TensorFlow 2.7 to notebook 02\u003c/li\u003e\n\u003cli\u003e11 Nov 2021 - add fix for TensorFlow 2.7 to notebook 01\u003c/li\u003e\n\u003cli\u003e14 Aug 2021 - added a discussion with TensorFlow 2.6 updates and EfficientNetV2 notes: \u003ca class=\"issue-link js-issue-link\" data-error-text=\"Failed to load title\" data-id=\"3520570\" data-permission-text=\"Title is private\" data-url=\"https://github.com/mrdbourke/tensorflow-deep-learning/discussions/166\" data-hovercard-type=\"discussion\" data-hovercard-url=\"/mrdbourke/tensorflow-deep-learning/discussions/166/hovercard\" href=\"https://github.com/mrdbourke/tensorflow-deep-learning/discussions/166\"\u003e#166\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e16 Jul 2021 - added 35 videos to ZTM Academy + Udemy versions of the course for time series and how to pass TensorFlow Developer Certification\u003c/li\u003e\n\u003cli\u003e10 Jul 2021 - added 29 edited time series videos to ZTM Academy + Udemy versions of the course, more to come soon\u003c/li\u003e\n\u003cli\u003e07 Jul 2021 - recorded 5 videos for passing TensorFlow Developer Certification exam section - ALL VIDEOS FOR COURSE DONE!!! time to edit/upload! \u003c/li\u003e\n\u003cli\u003e06 Jul 2021 - (archived) added guide to TensorFlow Certification Exam: \u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/11_passing_the_tensorflow_developer_certification_exam.md\"\u003ehttps://github.com/mrdbourke/tensorflow-deep-learning/blob/main/11_passing_the_tensorflow_developer_certification_exam.md\u003c/a\u003e - going to record videos for it tomorrow\u003c/li\u003e\n\u003cli\u003e05 Jul 2021 - making materials for TF certification exam (what/why/how)\u003c/li\u003e\n\u003cli\u003e02 Jul 2021 - FINISHED RECORDING VIDEOS FOR TIME SERIES SECTION!!!!! time to upload\u003c/li\u003e\n\u003cli\u003e30 Jun 2021 - recorded 12 videos for time series section, total heading past 60 (the biggest section yet), nearly done!!!\u003c/li\u003e\n\u003cli\u003e29 Jun 2021 - recorded 10 videos for time series section, total heading towards 60\u003c/li\u003e\n\u003cli\u003e28 Jun 2021 - recorded 10 videos for time series section, the line below says 40 videos total, actually more like 50\u003c/li\u003e\n\u003cli\u003e26 Jun 2021 - recorded 4 videos for time series section, looks like it'll be about 40 videos total\u003c/li\u003e\n\u003cli\u003e25 Jun 2021 - recorded 8 videos for time series section + fixed a bunch of typos in time series notebook\u003c/li\u003e\n\u003cli\u003e24 Jun 2021 - recorded 14 videos for time series section, more to come tomorrow\u003c/li\u003e\n\u003cli\u003e23 Jun 2021 - finished adding images to time series notebook, now to start video recording\u003c/li\u003e\n\u003cli\u003e22 Jun 2021 - added a bunch of images to the time series notebook/started making slides\u003c/li\u003e\n\u003cli\u003e21 Jun 2021 - code for time series notebook is done, now creating slides/images to prepare for recording\u003c/li\u003e\n\u003cli\u003e19 Jun 2021 - turned curriculum into an online book, you can read it here: \u003ca href=\"https://dev.mrdbourke.com/tensorflow-deep-learning/\" rel=\"nofollow\"\u003ehttps://dev.mrdbourke.com/tensorflow-deep-learning/\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e18 Jun 2021 - add exercises/extra-curriculum/outline to time series notebook\u003c/li\u003e\n\u003cli\u003e17 Jun 2021 - add annotations for turkey problem and model comparison in time series notebook, next is outline/images\u003c/li\u003e\n\u003cli\u003e16 Jun 2021 - add annotations for uncertainty and future predictions in time series notebook, next is turkey problem\u003c/li\u003e\n\u003cli\u003e14 Jun 2021 - add annotations for ensembling, begin on prediction intervals\u003c/li\u003e\n\u003cli\u003e10 Jun 2021 - finished annotations for N-BEATS algorithm, now onto ensembling/prediction intervals\u003c/li\u003e\n\u003cli\u003e9 Jun 2021 - add annotations for N-BEATS algorithm implementation for time series notebook\u003c/li\u003e\n\u003cli\u003e8 Jun 2021 - add annotations to time series notebook, all will be finished by end of week (failed)\u003c/li\u003e\n\u003cli\u003e4 Jun 2021 - more annotation updates to time series notebook, brick by brick!\u003c/li\u003e\n\u003cli\u003e3 Jun 2021 - added a bunch of annotations/explanations to time series notebook, momentum building, plenty more to come!\u003c/li\u003e\n\u003cli\u003e2 Jun 2021 - started adding annotations explaining the code + resources to learn more, will continue for next few days\u003c/li\u003e\n\u003cli\u003e1 Jun 2021 - added turkey problem to time series notebook, cleaned up a bunch of code, draft code is ready, now to write annotations/explanations\u003c/li\u003e\n\u003cli\u003e28 May 2021 - added future forecasts, added ensemble model, added prediction intervals to time series notebook\u003c/li\u003e\n\u003cli\u003e25 May 2021 - added multivariate time series to time series notebook, fix LSTM model, next we add TensorFlow windowing/experimenting with window sizes\u003c/li\u003e\n\u003cli\u003e24 May 2021 - fixed broken preprocessing function in time series notebook, LSTM model is broken, more material to come\u003c/li\u003e\n\u003cli\u003e20 May 2021 - more time series material creation\u003c/li\u003e\n\u003cli\u003e19 May 2021 - more time series material creation, streaming much of it live on Twitch - \u003ca href=\"https://twitch.tv/mrdbourke\" rel=\"nofollow\"\u003ehttps://twitch.tv/mrdbourke\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e18 May 2021 - added time series forecasting notebook outline (\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/10_time_series_forecasting_in_tensorflow.ipynb\"\u003enotebook 10\u003c/a\u003e), going to really start ramping up the materials here\u003c/li\u003e\n\u003cli\u003e12 May 2021 - all videos for 09 have now been released on Udemy \u0026amp; ZTM!!! enjoy build SkimLit \u003c/li\u003e\n\u003cli\u003e11 May 2021 - 40+ section 08 \u0026amp; 09 videos released on Udemy \u0026amp; ZTM!!!\u003c/li\u003e\n\u003cli\u003e10 May 2021 - time series materials research + preparation\u003c/li\u003e\n\u003cli\u003e08 May 2021 - time series materials research + preparation\u003c/li\u003e\n\u003cli\u003e05 May 2021 - ~20+ videos edited for 08, ~10+ videos edited for 09, time series materials in 1st draft mode\u003c/li\u003e\n\u003cli\u003e04 May 2021 - fixed the remaining videos for 08 (audio missing), now onto making time series materials!\u003c/li\u003e\n\u003cli\u003e03 May 2021 - rerecorded 10 videos for 08 fixing the sound isse, these are going straight to editing and should be uploaded by end of week\u003c/li\u003e\n\u003cli\u003e02 May 2021 - found an issue with videos 09-20 of section 08 (no audio), going to rerecord them\u003c/li\u003e\n\u003cli\u003e29 Apr 2021 -  launched on Udemy!!! \u003c/li\u003e\n\u003cli\u003e22 Apr 2021 - finished recording videos for 09! added slides and video notebook 09\u003c/li\u003e\n\u003cli\u003e21 Apr 2021 - recorded 14 videos for 09! biggggg day of recording! getting closer to finishing 09\u003c/li\u003e\n\u003cli\u003e20 Apr 2021 - recorded 10 videos for 09\u003c/li\u003e\n\u003cli\u003e19 Apr 2021 - recorded 9 videos for 09\u003c/li\u003e\n\u003cli\u003e16 Apr 2021 - slides done for 09, ready to start recording!\u003c/li\u003e\n\u003cli\u003e15 Apr 2021 - added slides, extra-curriculum, exercises and video notebook for 08, started making slides for 09, will finish tomorrow\u003c/li\u003e\n\u003cli\u003e14 Apr 2021 - recorded 12 videos for notebook 08, finished the section! time to make slides for 09 and get into it\u003c/li\u003e\n\u003cli\u003e10 Apr 2021 - recorded 4 videos for notebook 08\u003c/li\u003e\n\u003cli\u003e9 Apr 2021 - recorded 6 videos for notebook 08\u003c/li\u003e\n\u003cli\u003e8 Apr 2021 - recorded 10 videos for notebook 08! more coming tomorrow! home stretch baby!!!\u003c/li\u003e\n\u003cli\u003e7 Apr 2021 - added a whole bunch of images to notebook 08, getting ready for recording tomorrow!\u003c/li\u003e\n\u003cli\u003e1 Apr 2021 - added \u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/09_SkimLit_nlp_milestone_project_2.ipynb\"\u003enotebook 09: SkimLit\u003c/a\u003e, almost finished, a little cleaning and we'll be ready for slide making!\u003c/li\u003e\n\u003cli\u003e31 Mar 2021 - added notebook 08, going to finish tomorrow, then onto 09!\u003c/li\u003e\n\u003cli\u003e24 Mar 2021 - Recorded 8 videos for 07, finished! onto materials (slides/notebooks) for 08, 09\u003c/li\u003e\n\u003cli\u003e23 Mar 2021 - Recorded 6 videos for 07 (finally), going to finish tomorrow\u003c/li\u003e\n\u003cli\u003e22 Mar 2021 - Polished notebook 07 ready for recording, made slides for 07, added template for 07 (for a student to go through and practice), ready to record!\u003c/li\u003e\n\u003cli\u003e17 Mar 2021 - 99% finished notebook 07, added links to first 14 hours of the course on YouTube (\u003ca href=\"https://youtu.be/tpCFfeUEGs8\" rel=\"nofollow\"\u003e10 hours in part 1\u003c/a\u003e, \u003ca href=\"https://youtu.be/ZUKz4125WNI\" rel=\"nofollow\"\u003e4 hours in part 2\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003e11 Mar 2021 - added even more text annotations to notebook 07, finishing tomorrow, then slides\u003c/li\u003e\n\u003cli\u003e10 Mar 2021 - Typed a whole bunch of explanations into notebook 07, continuing tomorrow\u003c/li\u003e\n\u003cli\u003e09 Mar 2021 - fixed plenty of code in notebook 07, should run end to end very cleanly (though loading times are still a thing)\u003c/li\u003e\n\u003cli\u003e05 Mar 2021 - added draft notebook 07 (heaps of data loading and model training improvements in this one!), gonna fix up over next few days\u003c/li\u003e\n\u003cli\u003e01 Mar 2021 - Added slides for 06 (\u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/slides/06_transfer_learning_with_tensorflow_part_3_scaling_up.pdf\"\u003esee them here\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003e26 Feb 2021 -  LAUNCHED!!!!! also finished recording videos for 06, onto 07, 08, 09 for next release\u003c/li\u003e\n\u003cli\u003e24 Feb 2021 - recorded 9 videos for section 06, launch inbound!!!\u003c/li\u003e\n\u003cli\u003e23 Feb 2021 - rearranged GitHub in preparation for launch \u003c/li\u003e\n\u003cli\u003e18 Feb 2021 - recorded 8 videos for 05 and... it's done! onto polishing the GitHub\u003c/li\u003e\n\u003cli\u003e17 Feb 2021 - recorded 10 videos for 05! going to finish tomorrow \u003c/li\u003e\n\u003cli\u003e16 Feb 2021 - polished slides for 05 and started recording videos, got 7 videos done for 05\u003c/li\u003e\n\u003cli\u003e15 Feb 2021 - finished videos for 04, now preparing to record for 05!\u003c/li\u003e\n\u003cli\u003e12 Feb 2021 - recored 7 videos for section 04... wanted 10 but we'll take 7 ( this seems to have happened before)\u003c/li\u003e\n\u003cli\u003e11 Feb 2021 - NO PROGRESS - gave a Machine Learning deployment tutorial for \u003ca href=\"https://stanford-cs329s.github.io/syllabus.html\" rel=\"nofollow\"\u003eStanford's CS329s\u003c/a\u003e (using the model code from this course!!!) - \u003ca href=\"https://github.com/mrdbourke/cs329s-ml-deployment-tutorial\"\u003esee the full tutorial materials\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e08 Feb 2021 - recorded 10 videos for section 03... and section 03 is done!  onto section 04\u003c/li\u003e\n\u003cli\u003e30 Jan 2021 - 07 Feb 2021: NO PROGRESS (working on a ML deployment lecture for \u003ca href=\"https://stanford-cs329s.github.io/syllabus.html\" rel=\"nofollow\"\u003eStanford's CS329s\u003c/a\u003e... more on this later)\u003c/li\u003e\n\u003cli\u003e29 Jan 2021 - recorded 9 videos for section 03... closer to 10 than yesterday but still not there\u003c/li\u003e\n\u003cli\u003e28 Jan 2021 - recorded 7 videos for section 03... wanted 10 but we'll take 7\u003c/li\u003e\n\u003cli\u003e27 Jan 2021 - recorded 10 videos for section 03\u003c/li\u003e\n\u003cli\u003e26 Jan 2021 - polished GitHub README (what you're looking at) with a \u003ca href=\"https://github.com/mrdbourke/tensorflow-deep-learning#course-materials\"\u003enice table\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e23 Jan 2021 - finished slides of 06\u003c/li\u003e\n\u003cli\u003e22 Jan 2021 - finished review of notebook 06 \u0026amp; started slides of 06\u003c/li\u003e\n\u003cli\u003e21 Jan 2021 - finished slides for 05 \u0026amp; started review of 06\u003c/li\u003e\n\u003cli\u003e20 Jan 2021 - finished notebook 05 \u0026amp; 95% slides for 05\u003c/li\u003e\n\u003cli\u003e19 Jan 2021 - found a storage idea for data during course (use Google Storage in same region as Colab Notebooks, cheapest/fastest)\u003c/li\u003e\n\u003cli\u003e18 Jan 2021 - reviewed notebook 05 \u0026amp; slides for 05\u003c/li\u003e\n\u003cli\u003e17 Jan 2021 - finished notebook 04 \u0026amp; slides for 04\u003c/li\u003e\n\u003cli\u003e16 Jan 2021 - review notebook 04 \u0026amp; made slides for transfer learning\u003c/li\u003e\n\u003cli\u003e13 Jan 2021 - review notebook 03 again \u0026amp; finished slides for 03, BIGGGGG updates to the README, notebook 03 99% done, just need to figure out optimum way to transfer data (e.g. when a student downloads it, where's best to store it in the meantime? Dropbox? S3? \u003cdel\u003eGS\u003c/del\u003e (too expensive)\u003c/li\u003e\n\u003cli\u003e11 Jan 2021 - reviewed notebook 03, 95% ready for recording, onto slides for 03\u003c/li\u003e\n\u003cli\u003e9 Jan 2021 - I'm back baby! Finished all videos for 02, now onto slides/materials for 03, 04, 05 (then I'll get back in the lab)\u003c/li\u003e\n\u003cli\u003e19 Dec 2020 - ON HOLD (family holiday until Jan 02 2021)\u003c/li\u003e\n\u003cli\u003e18 Dec 2020 - recorded 75% of videos for 02\u003c/li\u003e\n\u003cli\u003e17 Dec 2020 - recorded 50% of videos for 02\u003c/li\u003e\n\u003cli\u003e16 Dec 2020 - recorded 100% of videos for 01\u003c/li\u003e\n\u003cli\u003e15 Dec 2020 - recorded 90% of videos for 01\u003c/li\u003e\n\u003cli\u003e09 Dec 2020 - finished recording videos for 00\u003c/li\u003e\n\u003cli\u003e08 Dec 2020 - recorded 90% of videos for 00\u003c/li\u003e\n\u003cli\u003e05 Dec 2020 - trialled recording studio for ~6 videos with notebook 00 material\u003c/li\u003e\n\u003cli\u003e04 Dec 2020 - setup \u003ca href=\"https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/misc-studio-setup.jpeg\" rel=\"nofollow\"\u003erecording studio in closet\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e03 Dec 2020 - finished notebook 02, finished slides for 02, time to setup recording studio\u003c/li\u003e\n\u003cli\u003e02 Dec 2020 - notebook 02 95% done, slides for 02 90% done\u003c/li\u003e\n\u003cli\u003e01 Dec 2020 - added notebook 02 (90% polished), start preparing slides for 02\u003c/li\u003e\n\u003cli\u003e27 Nov 2020 - polished notebook 01, made slides for notebook 01\u003c/li\u003e\n\u003cli\u003e26 Nov 2020 - polished notebook 00, made slides for notebook 00\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/article\u003e","loaded":true,"timedOut":false,"errorMessage":null,"headerInfo":{"toc":[{"level":1,"text":"Zero to Mastery Deep Learning with TensorFlow","anchor":"zero-to-mastery-deep-learning-with-tensorflow","htmlText":"Zero to Mastery Deep Learning with TensorFlow"},{"level":2,"text":"Important links","anchor":"important-links","htmlText":"Important links"},{"level":2,"text":"Contents of this page","anchor":"contents-of-this-page","htmlText":"Contents of this page"},{"level":2,"text":"Fixes and updates","anchor":"fixes-and-updates","htmlText":"Fixes and updates"},{"level":2,"text":"Course materials","anchor":"course-materials","htmlText":"Course materials"},{"level":2,"text":"Course structure","anchor":"course-structure","htmlText":"Course structure"},{"level":2,"text":"Should you do this course?","anchor":"should-you-do-this-course","htmlText":"Should you do this course?"},{"level":2,"text":"Prerequisites","anchor":"prerequisites","htmlText":"Prerequisites"},{"level":2,"text":" Exercises \u0026  Extra-curriculum","anchor":"-exercises---extra-curriculum","htmlText":" Exercises \u0026amp;  Extra-curriculum"},{"level":3,"text":" 00. TensorFlow Fundamentals Exercises","anchor":"-00-tensorflow-fundamentals-exercises","htmlText":" 00. TensorFlow Fundamentals Exercises"},{"level":3,"text":" 00. TensorFlow Fundamentals Extra-curriculum","anchor":"-00-tensorflow-fundamentals-extra-curriculum","htmlText":" 00. TensorFlow Fundamentals Extra-curriculum"},{"level":3,"text":" 01. Neural network regression with TensorFlow Exercises","anchor":"-01-neural-network-regression-with-tensorflow-exercises","htmlText":" 01. Neural network regression with TensorFlow Exercises"},{"level":3,"text":" 01. Neural network regression with TensorFlow Extra-curriculum","anchor":"-01-neural-network-regression-with-tensorflow-extra-curriculum","htmlText":" 01. Neural network regression with TensorFlow Extra-curriculum"},{"level":3,"text":" 02. Neural network classification with TensorFlow Exercises","anchor":"-02-neural-network-classification-with-tensorflow-exercises","htmlText":" 02. Neural network classification with TensorFlow Exercises"},{"level":3,"text":" 02. Neural network classification with TensorFlow Extra-curriculum","anchor":"-02-neural-network-classification-with-tensorflow-extra-curriculum","htmlText":" 02. Neural network classification with TensorFlow Extra-curriculum"},{"level":3,"text":" 03. Computer vision \u0026 convolutional neural networks in TensorFlow Exercises","anchor":"-03-computer-vision--convolutional-neural-networks-in-tensorflow-exercises","htmlText":" 03. Computer vision \u0026amp; convolutional neural networks in TensorFlow Exercises"},{"level":3,"text":" 03. Computer vision \u0026 convolutional neural networks in TensorFlow Extra-curriculum","anchor":"-03-computer-vision--convolutional-neural-networks-in-tensorflow-extra-curriculum","htmlText":" 03. Computer vision \u0026amp; convolutional neural networks in TensorFlow Extra-curriculum"},{"level":3,"text":" 04. Transfer Learning in TensorFlow Part 1: Feature Extraction Exercises","anchor":"-04-transfer-learning-in-tensorflow-part-1-feature-extraction-exercises","htmlText":" 04. Transfer Learning in TensorFlow Part 1: Feature Extraction Exercises"},{"level":3,"text":" 04. Transfer Learning in TensorFlow Part 1: Feature Extraction Extra-curriculum","anchor":"-04-transfer-learning-in-tensorflow-part-1-feature-extraction-extra-curriculum","htmlText":" 04. Transfer Learning in TensorFlow Part 1: Feature Extraction Extra-curriculum"},{"level":3,"text":" 05. Transfer Learning in TensorFlow Part 2: Fine-tuning Exercises","anchor":"-05-transfer-learning-in-tensorflow-part-2-fine-tuning-exercises","htmlText":" 05. Transfer Learning in TensorFlow Part 2: Fine-tuning Exercises"},{"level":3,"text":" 05. Transfer Learning in TensorFlow Part 2: Fine-tuning Extra-curriculum","anchor":"-05-transfer-learning-in-tensorflow-part-2-fine-tuning-extra-curriculum","htmlText":" 05. Transfer Learning in TensorFlow Part 2: Fine-tuning Extra-curriculum"},{"level":3,"text":" 06. Transfer Learning in TensorFlow Part 3: Scaling-up Exercises","anchor":"-06-transfer-learning-in-tensorflow-part-3-scaling-up-exercises","htmlText":" 06. Transfer Learning in TensorFlow Part 3: Scaling-up Exercises"},{"level":3,"text":" 06. Transfer Learning in TensorFlow Part 3: Scaling-up Extra-curriculum","anchor":"-06-transfer-learning-in-tensorflow-part-3-scaling-up-extra-curriculum","htmlText":" 06. Transfer Learning in TensorFlow Part 3: Scaling-up Extra-curriculum"},{"level":3,"text":" 07. Milestone Project 1:  Food Vision Big Exercises","anchor":"-07-milestone-project-1--food-vision-big-exercises","htmlText":" 07. Milestone Project 1:  Food Vision Big Exercises"},{"level":3,"text":" 07. Milestone Project 1:  Food Vision Big Extra-curriculum","anchor":"-07-milestone-project-1--food-vision-big-extra-curriculum","htmlText":" 07. Milestone Project 1:  Food Vision Big Extra-curriculum"},{"level":3,"text":" 08. Introduction to NLP (Natural Language Processing) in TensorFlow Exercises","anchor":"-08-introduction-to-nlp-natural-language-processing-in-tensorflow-exercises","htmlText":" 08. Introduction to NLP (Natural Language Processing) in TensorFlow Exercises"},{"level":3,"text":" 08. Introduction to NLP (Natural Language Processing) in TensorFlow Extra-curriculum","anchor":"-08-introduction-to-nlp-natural-language-processing-in-tensorflow-extra-curriculum","htmlText":" 08. Introduction to NLP (Natural Language Processing) in TensorFlow Extra-curriculum"},{"level":3,"text":" 09. Milestone Project 2: SkimLit  Exercises","anchor":"-09-milestone-project-2-skimlit--exercises","htmlText":" 09. Milestone Project 2: SkimLit  Exercises"},{"level":3,"text":" 09. Milestone Project 2: SkimLit  Extra-curriculum","anchor":"-09-milestone-project-2-skimlit--extra-curriculum","htmlText":" 09. Milestone Project 2: SkimLit  Extra-curriculum"},{"level":3,"text":" 10. Time series fundamentals and Milestone Project 3: BitPredict  Exercises","anchor":"-10-time-series-fundamentals-and-milestone-project-3-bitpredict--exercises","htmlText":" 10. Time series fundamentals and Milestone Project 3: BitPredict  Exercises"},{"level":3,"text":" 10. Time series fundamentals and Milestone Project 3: BitPredict  Extra-curriculum","anchor":"-10-time-series-fundamentals-and-milestone-project-3-bitpredict--extra-curriculum","htmlText":" 10. Time series fundamentals and Milestone Project 3: BitPredict  Extra-curriculum"},{"level":2,"text":"TensorFlow Developer Certificate (archive)","anchor":"tensorflow-developer-certificate-archive","htmlText":"TensorFlow Developer Certificate (archive)"},{"level":3,"text":" 11. Passing the TensorFlow Developer Certification Exercises (archive)","anchor":"-11-passing-the-tensorflow-developer-certification-exercises-archive","htmlText":" 11. Passing the TensorFlow Developer Certification Exercises (archive)"},{"level":3,"text":" 11. Passing the TensorFlow Developer Certification Extra-curriculum (archive)","anchor":"-11-passing-the-tensorflow-developer-certification-extra-curriculum-archive","htmlText":" 11. Passing the TensorFlow Developer Certification Extra-curriculum (archive)"},{"level":2,"text":"What this course is missing","anchor":"what-this-course-is-missing","htmlText":"What this course is missing"},{"level":2,"text":"Extensions (possible places to go after the course)","anchor":"extensions-possible-places-to-go-after-the-course","htmlText":"Extensions (possible places to go after the course)"},{"level":2,"text":"Ask questions","anchor":"ask-questions","htmlText":"Ask questions"},{"level":2,"text":"Log","anchor":"log","htmlText":"Log"}],"siteNavLoginPath":"/login?return_to=https%3A%2F%2Fgithub.com%2Fmrdbourke%2Ftensorflow-deep-learning"}},{"displayName":"LICENSE","repoName":"tensorflow-deep-learning","refName":"main","path":"LICENSE","preferredFileType":"license","tabName":"MIT","richText":null,"loaded":false,"timedOut":false,"errorMessage":null,"headerInfo":{"toc":null,"siteNavLoginPath":"/login?return_to=https%3A%2F%2Fgithub.com%2Fmrdbourke%2Ftensorflow-deep-learning"}}],"overviewFilesProcessingTime":0,"createFromTemplatePath":"/new?template_name=tensorflow-deep-learning\u0026template_owner=mrdbourke"}},"appPayload":{"helpUrl":"https://docs.github.com","findFileWorkerPath":"/assets-cdn/worker/find-file-worker-1583894afd38.js","findInFileWorkerPath":"/assets-cdn/worker/find-in-file-worker-3a63a487027b.js","githubDevUrl":"https://github.dev/","enabled_features":{"code_nav_ui_events":false,"overview_shared_code_dropdown_button":false,"react_blob_overlay":true,"copilot_conversational_ux_embedding_update":false,"copilot_smell_icebreaker_ux":true,"copilot_workspace":false}}}}</script>
  <div data-target="react-partial.reactRoot"> <!-- --> <!-- --> <div class="Box-sc-g0xbh4-0 izjvBm"><div class="Box-sc-g0xbh4-0 rPQgy"><div class="Box-sc-g0xbh4-0 eUMEDg"></div></div><div class="Box-sc-g0xbh4-0 eLcVee"><div class="Box-sc-g0xbh4-0 hsfLlq"><div class="Box-sc-g0xbh4-0 gpKoUz"><button type="button" aria-haspopup="true" aria-expanded="false" tabindex="0" aria-label="main branch" data-testid="anchor-button" class="types__StyledButton-sc-ws60qy-0 jwBfae overview-ref-selector width-full" data-loading="false" aria-describedby="branch-picker-repos-header-ref-selector-loading-announcement" id="branch-picker-repos-header-ref-selector" data-hotkey="w"><span data-component="buttonContent" class="Box-sc-g0xbh4-0 kkrdEu"><span data-component="text"><div class="Box-sc-g0xbh4-0 bKgizp"><div class="Box-sc-g0xbh4-0 iPGYsi"><svg aria-hidden="true" focusable="false" role="img" class="octicon octicon-git-branch" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path d="M9.5 3.25a2.25 2.25 0 1 1 3 2.122V6A2.5 2.5 0 0 1 10 8.5H6a1 1 0 0 0-1 1v1.128a2.251 2.251 0 1 1-1.5 0V5.372a2.25 2.25 0 1 1 1.5 0v1.836A2.493 2.493 0 0 1 6 7h4a1 1 0 0 0 1-1v-.628A2.25 2.25 0 0 1 9.5 3.25Zm-6 0a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Zm8.25-.75a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5ZM4.25 12a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Z"></path></svg></div><div class="Box-sc-g0xbh4-0 caeYDk ref-selector-button-text-container"><span class="Text-sc-17v1xeu-0 bOMzPg">&nbsp;<!-- -->main</span></div></div></span><span data-component="trailingVisual" class="Box-sc-g0xbh4-0 trpoQ"><svg aria-hidden="true" focusable="false" role="img" class="octicon octicon-triangle-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path d="m4.427 7.427 3.396 3.396a.25.25 0 0 0 .354 0l3.396-3.396A.25.25 0 0 0 11.396 7H4.604a.25.25 0 0 0-.177.427Z"></path></svg></span></span></button><button hidden="" data-hotkey-scope="read-only-cursor-text-area" data-hotkey="w"></button></div><div class="Box-sc-g0xbh4-0 laYubZ"><a style="--button-color:fg.muted" type="button" href="https://github.com/mrdbourke/tensorflow-deep-learning/branches" data-loading="false" aria-describedby=":Rclab:-loading-announcement" class="types__StyledButton-sc-ws60qy-0 eybzoG"><span data-component="buttonContent" class="Box-sc-g0xbh4-0 kkrdEu"><span data-component="leadingVisual" class="Box-sc-g0xbh4-0 trpoQ"><svg aria-hidden="true" focusable="false" role="img" class="octicon octicon-git-branch" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path d="M9.5 3.25a2.25 2.25 0 1 1 3 2.122V6A2.5 2.5 0 0 1 10 8.5H6a1 1 0 0 0-1 1v1.128a2.251 2.251 0 1 1-1.5 0V5.372a2.25 2.25 0 1 1 1.5 0v1.836A2.493 2.493 0 0 1 6 7h4a1 1 0 0 0 1-1v-.628A2.25 2.25 0 0 1 9.5 3.25Zm-6 0a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Zm8.25-.75a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5ZM4.25 12a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Z"></path></svg></span><span data-component="text"><div class="Box-sc-g0xbh4-0"><strong class="color-fg-default">2</strong>
<span class="color-fg-muted">Branches</span>
</div></span></span></a><a style="--button-color:fg.muted" type="button" href="https://github.com/mrdbourke/tensorflow-deep-learning/tags" data-loading="false" aria-describedby=":Rklab:-loading-announcement" class="types__StyledButton-sc-ws60qy-0 eybzoG"><span data-component="buttonContent" class="Box-sc-g0xbh4-0 kkrdEu"><span data-component="leadingVisual" class="Box-sc-g0xbh4-0 trpoQ"><svg aria-hidden="true" focusable="false" role="img" class="octicon octicon-tag" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path d="M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.752 1.752 0 0 1 1 7.775Zm1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2Z"></path></svg></span><span data-component="text"><div class="Box-sc-g0xbh4-0"><strong class="color-fg-default">0</strong>
<span class="color-fg-muted">Tags</span>
</div></span></span></a></div><div class="Box-sc-g0xbh4-0 swnaL"><a style="--button-color:fg.muted" type="button" aria-label="Go to Branches page" href="https://github.com/mrdbourke/tensorflow-deep-learning/branches" data-loading="false" data-no-visuals="true" aria-describedby=":Relab:-loading-announcement" class="types__StyledButton-sc-ws60qy-0 kPKwzC"><svg aria-hidden="true" focusable="false" role="img" class="octicon octicon-git-branch" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path d="M9.5 3.25a2.25 2.25 0 1 1 3 2.122V6A2.5 2.5 0 0 1 10 8.5H6a1 1 0 0 0-1 1v1.128a2.251 2.251 0 1 1-1.5 0V5.372a2.25 2.25 0 1 1 1.5 0v1.836A2.493 2.493 0 0 1 6 7h4a1 1 0 0 0 1-1v-.628A2.25 2.25 0 0 1 9.5 3.25Zm-6 0a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Zm8.25-.75a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5ZM4.25 12a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Z"></path></svg></a><a style="--button-color:fg.muted" type="button" aria-label="Go to Tags page" href="https://github.com/mrdbourke/tensorflow-deep-learning/tags" data-loading="false" data-no-visuals="true" aria-describedby=":Rmlab:-loading-announcement" class="types__StyledButton-sc-ws60qy-0 kPKwzC"><svg aria-hidden="true" focusable="false" role="img" class="octicon octicon-tag" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path d="M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.752 1.752 0 0 1 1 7.775Zm1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2Z"></path></svg></a></div></div><div class="Box-sc-g0xbh4-0 bWpuBf"><div class="Box-sc-g0xbh4-0 grHjNb"><button hidden="" data-hotkey="t,Shift+T"></button><div class="Box-sc-g0xbh4-0 dXTsqj"><div class="Box-sc-g0xbh4-0 ggfwQp"><span class="TextInputWrapper__TextInputBaseWrapper-sc-1mqhpbi-0 TextInputWrapper-sc-1mqhpbi-1 cXNreu jbzqwE TextInput-wrapper" aria-busy="false"><span class="TextInput-icon"><svg aria-hidden="true" focusable="false" role="img" class="octicon octicon-search" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M10.68 11.74a6 6 0 0 1-7.922-8.982 6 6 0 0 1 8.982 7.922l3.04 3.04a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215ZM11.5 7a4.499 4.499 0 1 0-8.997 0A4.499 4.499 0 0 0 11.5 7Z"></path></svg></span><input type="text" aria-label="Go to file" role="combobox" aria-controls="file-results-list" aria-expanded="false" aria-haspopup="dialog" autocorrect="off" spellcheck="false" placeholder="Go to file" data-component="input" class="UnstyledTextInput-sc-14ypya-0 cDLBls" value=""><span class="TextInput-icon"><div class="Box-sc-g0xbh4-0 cNvKlH"><kbd>t</kbd></div></span></span></div></div><div class="Box-sc-g0xbh4-0 dCOrmu"><button type="button" data-loading="false" data-no-visuals="true" aria-describedby=":Rr5ab:-loading-announcement" class="types__StyledButton-sc-ws60qy-0 feqCqy"><span data-component="buttonContent" class="Box-sc-g0xbh4-0 kkrdEu"><span data-component="text">Go to file</span></span></button></div><div class="react-directory-add-file-icon"><h2 class="Heading__StyledHeading-sc-1c1dgg0-0 fpGZrB sr-only" data-testid="screen-reader-heading">Add file</h2><button data-component="IconButton" type="button" aria-label="Add file" aria-haspopup="true" aria-expanded="false" tabindex="0" data-loading="false" data-no-visuals="true" aria-describedby=":R535ab:-loading-announcement" id=":R535ab:" class="types__StyledButton-sc-ws60qy-0 feqCqy"><svg aria-hidden="true" focusable="false" role="img" class="octicon octicon-plus" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path d="M7.75 2a.75.75 0 0 1 .75.75V7h4.25a.75.75 0 0 1 0 1.5H8.5v4.25a.75.75 0 0 1-1.5 0V8.5H2.75a.75.75 0 0 1 0-1.5H7V2.75A.75.75 0 0 1 7.75 2Z"></path></svg></button></div><div class="react-directory-remove-file-icon"><h2 class="Heading__StyledHeading-sc-1c1dgg0-0 fpGZrB sr-only" data-testid="screen-reader-heading">Add file</h2><button type="button" aria-haspopup="true" aria-expanded="false" tabindex="0" data-loading="false" aria-describedby=":R5b5ab:-loading-announcement" id=":R5b5ab:" class="types__StyledButton-sc-ws60qy-0 feqCqy"><span data-component="buttonContent" class="Box-sc-g0xbh4-0 kkrdEu"><span data-component="text">Add file</span></span><span data-component="trailingAction" class="Box-sc-g0xbh4-0 trpoQ"><svg aria-hidden="true" focusable="false" class="octicon octicon-triangle-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path d="m4.427 7.427 3.396 3.396a.25.25 0 0 0 .354 0l3.396-3.396A.25.25 0 0 0 11.396 7H4.604a.25.25 0 0 0-.177.427Z"></path></svg></span></button></div></div><button type="button" aria-haspopup="true" aria-expanded="false" tabindex="0" data-loading="false" aria-describedby=":R55ab:-loading-announcement" id=":R55ab:" class="types__StyledButton-sc-ws60qy-0 dLirOd"><span data-component="buttonContent" class="Box-sc-g0xbh4-0 kkrdEu"><span data-component="leadingVisual" class="Box-sc-g0xbh4-0 trpoQ"><div class="Box-sc-g0xbh4-0 bVvbgP"><svg aria-hidden="true" focusable="false" role="img" class="octicon octicon-code" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"></path></svg></div></span><span data-component="text">Code</span></span><span data-component="trailingAction" class="Box-sc-g0xbh4-0 trpoQ"><svg aria-hidden="true" focusable="false" class="octicon octicon-triangle-down" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path d="m4.427 7.427 3.396 3.396a.25.25 0 0 0 .354 0l3.396-3.396A.25.25 0 0 0 11.396 7H4.604a.25.25 0 0 0-.177.427Z"></path></svg></span></button><div class="Box-sc-g0xbh4-0 bNDvfp"><button data-component="IconButton" type="button" aria-label="Open more actions menu" aria-haspopup="true" aria-expanded="false" tabindex="0" data-loading="false" data-no-visuals="true" aria-describedby=":R75ab:-loading-announcement" id=":R75ab:" class="types__StyledButton-sc-ws60qy-0 feqCqy"><svg aria-hidden="true" focusable="false" role="img" class="octicon octicon-kebab-horizontal" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path d="M8 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3ZM1.5 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Zm13 0a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z"></path></svg></button></div></div></div><div class="Box-sc-g0xbh4-0 yfPnm"><div data-hpc="true"><button hidden="" data-testid="focus-next-element-button" data-hotkey="j"></button><button hidden="" data-testid="focus-previous-element-button" data-hotkey="k"></button><h2 class="Heading__StyledHeading-sc-1c1dgg0-0 fpGZrB sr-only" data-testid="screen-reader-heading" id="folders-and-files">Folders and files</h2><table aria-labelledby="folders-and-files" class="Box-sc-g0xbh4-0 cAQuiW"><thead class="Box-sc-g0xbh4-0 iiUlLN"><tr class="Box-sc-g0xbh4-0 jmggSN"><th colspan="2" class="Box-sc-g0xbh4-0 kvYunM"><span class="text-bold">Name</span></th><th colspan="1" class="Box-sc-g0xbh4-0 hrLuxA"><span class="text-bold">Name</span></th><th class="hide-sm"><div title="Last commit message" class="Truncate__StyledTruncate-sc-23o1d2-0 dliONX width-fit"><span class="text-bold">Last commit message</span></div></th><th colspan="1" class="Box-sc-g0xbh4-0 cuEKae"><div title="Last commit date" class="Truncate__StyledTruncate-sc-23o1d2-0 dliONX width-fit"><span class="text-bold">Last commit date</span></div></th></tr></thead><tbody><tr class="Box-sc-g0xbh4-0 jEbBOT"><td colspan="3" class="bgColor-muted p-1 rounded-top-2"><div class="Box-sc-g0xbh4-0 brJRqk"><h2 class="Heading__StyledHeading-sc-1c1dgg0-0 fpGZrB sr-only" data-testid="screen-reader-heading">Latest commit</h2><div data-testid="latest-commit" class="Box-sc-g0xbh4-0 bIwQEu"><div class="Box-sc-g0xbh4-0 eScEiW"><div data-testid="author-avatar" class="Box-sc-g0xbh4-0 hLLhje"><a href="https://github.com/mrdbourke" data-testid="avatar-icon-link" data-hovercard-url="/users/mrdbourke/hovercard" class="Link__StyledLink-sc-14289xe-0 dheQRw"><img data-component="Avatar" alt="mrdbourke" size="20" src="./github-tensorflow-deep-learning_files/16750345(1)" data-testid="github-avatar" aria-label="mrdbourke" height="20" width="20" class="Avatar__StyledAvatar-sc-2lv0r8-0 kYMvPL"></a><a href="https://github.com/mrdbourke/tensorflow-deep-learning/commits?author=mrdbourke" aria-label="commits by mrdbourke" data-hovercard-url="/users/mrdbourke/hovercard" class="Link__StyledLink-sc-14289xe-0 XuJeD">mrdbourke</a></div><span class=""></span></div><div class="Box-sc-g0xbh4-0 fqNQBl d-none d-sm-flex"><div class="Truncate flex-items-center f5"><span class="Text-sc-17v1xeu-0 gPDEWA Truncate-text" data-testid="latest-commit-html"><a href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/bd065b806249f7b1155e5b1fabd130c5cfc9d184" class="Link--secondary" data-pjax="true" data-hovercard-url="/mrdbourke/tensorflow-deep-learning/commit/bd065b806249f7b1155e5b1fabd130c5cfc9d184/hovercard">update image link and docs title for section 11</a></span></div><span role="tooltip" aria-label="success" id=":rk:" class="Tooltip__TooltipBase-sc-17tf59c-0 hgqwGf tooltipped-se"><button data-component="IconButton" type="button" data-testid="checks-status-badge-icon" data-loading="false" data-no-visuals="true" data-size="small" aria-describedby=":rm:-loading-announcement" aria-labelledby=":rk:" class="types__StyledButton-sc-ws60qy-0 lgZqHN"><svg aria-hidden="true" focusable="false" role="img" class="octicon octicon-check" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path></svg></button></span></div><span class="d-flex d-sm-none fgColor-muted f6"><relative-time class="sc-bcXHqe" tense="past" datetime="2024-05-02T05:17:49.000Z" title="May 1, 2024, 10:17 PM PDT"><template shadowrootmode="open">4 months ago</template>May 1, 2024</relative-time></span></div><div class="d-flex flex-shrink-0 gap-2"><div data-testid="latest-commit-details" class="d-none d-sm-flex flex-items-center"><span class="d-flex flex-nowrap fgColor-muted f6"><a class="Link__StyledLink-sc-14289xe-0 dheQRw Link--secondary" aria-label="Commit bd065b8" data-hovercard-url="/mrdbourke/tensorflow-deep-learning/commit/bd065b806249f7b1155e5b1fabd130c5cfc9d184/hovercard" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/bd065b806249f7b1155e5b1fabd130c5cfc9d184">bd065b8</a>&nbsp;&nbsp;<relative-time class="sc-bcXHqe" tense="past" datetime="2024-05-02T05:17:49.000Z" title="May 1, 2024, 10:17 PM PDT"><template shadowrootmode="open">4 months ago</template>May 1, 2024</relative-time></span></div><div class="d-flex gap-2"><h2 class="Heading__StyledHeading-sc-1c1dgg0-0 fpGZrB sr-only" data-testid="screen-reader-heading">History</h2><a class="types__StyledButton-sc-ws60qy-0 emYRmJ d-none d-lg-flex LinkButton-module__code-view-link-button--xvCGA flex-items-center fgColor-default" href="https://github.com/mrdbourke/tensorflow-deep-learning/commits/main/" data-loading="false" data-size="small" aria-describedby=":Raqj8pab:-loading-announcement"><span data-component="buttonContent" class="Box-sc-g0xbh4-0 kkrdEu"><span data-component="leadingVisual" class="Box-sc-g0xbh4-0 trpoQ"><svg aria-hidden="true" focusable="false" role="img" class="octicon octicon-history" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path d="m.427 1.927 1.215 1.215a8.002 8.002 0 1 1-1.6 5.685.75.75 0 1 1 1.493-.154 6.5 6.5 0 1 0 1.18-4.458l1.358 1.358A.25.25 0 0 1 3.896 6H.25A.25.25 0 0 1 0 5.75V2.104a.25.25 0 0 1 .427-.177ZM7.75 4a.75.75 0 0 1 .75.75v2.992l2.028.812a.75.75 0 0 1-.557 1.392l-2.5-1A.751.751 0 0 1 7 8.25v-3.5A.75.75 0 0 1 7.75 4Z"></path></svg></span><span data-component="text"><span class="fgColor-default">592 Commits</span></span></span></a><div class="d-sm-none"><button data-component="IconButton" type="button" aria-label="Open commit details" aria-pressed="false" aria-expanded="false" data-testid="latest-commit-details-toggle" data-loading="false" data-no-visuals="true" data-size="small" aria-describedby=":rn:-loading-announcement" class="types__StyledButton-sc-ws60qy-0 ljyQZt"><svg aria-hidden="true" focusable="false" role="img" class="octicon octicon-ellipsis" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M0 5.75C0 4.784.784 4 1.75 4h12.5c.966 0 1.75.784 1.75 1.75v4.5A1.75 1.75 0 0 1 14.25 12H1.75A1.75 1.75 0 0 1 0 10.25ZM12 7a1 1 0 1 0 0 2 1 1 0 0 0 0-2ZM7 8a1 1 0 1 0 2 0 1 1 0 0 0-2 0ZM4 7a1 1 0 1 0 0 2 1 1 0 0 0 0-2Z"></path></svg></button></div><div class="d-flex d-lg-none"><span role="tooltip" aria-label="592 Commits" id="history-icon-button-tooltip" class="Tooltip__TooltipBase-sc-17tf59c-0 gNgnVl tooltipped-n"><a class="types__StyledButton-sc-ws60qy-0 emYRmJ LinkButton-module__code-view-link-button--xvCGA flex-items-center fgColor-default" href="https://github.com/mrdbourke/tensorflow-deep-learning/commits/main/" data-loading="false" data-size="small" aria-describedby=":R1iqj8pab:-loading-announcement history-icon-button-tooltip"><span data-component="buttonContent" class="Box-sc-g0xbh4-0 kkrdEu"><span data-component="leadingVisual" class="Box-sc-g0xbh4-0 trpoQ"><svg aria-hidden="true" focusable="false" role="img" class="octicon octicon-history" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path d="m.427 1.927 1.215 1.215a8.002 8.002 0 1 1-1.6 5.685.75.75 0 1 1 1.493-.154 6.5 6.5 0 1 0 1.18-4.458l1.358 1.358A.25.25 0 0 1 3.896 6H.25A.25.25 0 0 1 0 5.75V2.104a.25.25 0 0 1 .427-.177ZM7.75 4a.75.75 0 0 1 .75.75v2.992l2.028.812a.75.75 0 0 1-.557 1.392l-2.5-1A.751.751 0 0 1 7 8.25v-3.5A.75.75 0 0 1 7.75 4Z"></path></svg></span></span></a></span></div></div></div></div></td></tr><tr class="react-directory-row undefined" id="folder-row-0"><td class="react-directory-row-name-cell-small-screen" colspan="2"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="icon-directory" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="This path skips through empty directories" aria-label=".github/workflows, (Directory)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/tree/main/.github/workflows"><span class="react-directory-default-color" data-testid="path-name-segment">.github/</span><span class="" data-testid="path-name-segment">workflows</span></a></div></div></div></div></td><td class="react-directory-row-name-cell-large-screen" colspan="1"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="icon-directory" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="This path skips through empty directories" aria-label=".github/workflows, (Directory)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/tree/main/.github/workflows"><span class="react-directory-default-color" data-testid="path-name-segment">.github/</span><span class="" data-testid="path-name-segment">workflows</span></a></div></div></div></div></td><td class="react-directory-row-commit-cell"><div><div class="react-directory-commit-message"><a data-pjax="true" title="Update make_docs.yml" class="Link--secondary" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/30dfd73b59c7bc191fd799461d8211a241e67ef6">Update make_docs.yml</a></div></div></td><td><div class="react-directory-commit-age"><relative-time class="sc-bcXHqe" tense="past" datetime="2022-03-14T04:25:20.000Z" title="Mar 13, 2022, 9:25 PM PDT"><template shadowrootmode="open">2 years ago</template>Mar 13, 2022</relative-time></div></td></tr><tr class="react-directory-row undefined" id="folder-row-1"><td class="react-directory-row-name-cell-small-screen" colspan="2"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="icon-directory" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="docs" aria-label="docs, (Directory)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/tree/main/docs">docs</a></div></div></div></div></td><td class="react-directory-row-name-cell-large-screen" colspan="1"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="icon-directory" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="docs" aria-label="docs, (Directory)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/tree/main/docs">docs</a></div></div></div></div></td><td class="react-directory-row-commit-cell"><div><div class="react-directory-commit-message"><a data-pjax="true" title="update materials to reflect TensorFlow Developer Certificate closing" class="Link--secondary" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/8d87bd37746f1650851fde3b6724e0685592aea2">update materials to reflect TensorFlow Developer Certificate closing</a></div></div></td><td><div class="react-directory-commit-age"><relative-time class="sc-bcXHqe" tense="past" datetime="2024-05-02T05:08:21.000Z" title="May 1, 2024, 10:08 PM PDT"><template shadowrootmode="open">4 months ago</template>May 1, 2024</relative-time></div></td></tr><tr class="react-directory-row undefined" id="folder-row-2"><td class="react-directory-row-name-cell-small-screen" colspan="2"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="icon-directory" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="extras" aria-label="extras, (Directory)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/tree/main/extras">extras</a></div></div></div></div></td><td class="react-directory-row-name-cell-large-screen" colspan="1"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="icon-directory" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="extras" aria-label="extras, (Directory)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/tree/main/extras">extras</a></div></div></div></div></td><td class="react-directory-row-commit-cell"><div><div class="react-directory-commit-message"><a data-pjax="true" title="Added interactive version of notebook 01" class="Link--secondary" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/2916b21688ee6f69238403b2eaf9520a9a6fc172">Added interactive version of notebook 01</a></div></div></td><td><div class="react-directory-commit-age"><relative-time class="sc-bcXHqe" tense="past" datetime="2021-12-20T20:44:14.000Z" title="Dec 20, 2021, 12:44 PM PST"><template shadowrootmode="open">3 years ago</template>Dec 20, 2021</relative-time></div></td></tr><tr class="react-directory-row undefined" id="folder-row-3"><td class="react-directory-row-name-cell-small-screen" colspan="2"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="icon-directory" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="images" aria-label="images, (Directory)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/tree/main/images">images</a></div></div></div></div></td><td class="react-directory-row-name-cell-large-screen" colspan="1"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="icon-directory" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="images" aria-label="images, (Directory)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/tree/main/images">images</a></div></div></div></div></td><td class="react-directory-row-commit-cell"><div><div class="react-directory-commit-message"><a data-pjax="true" title="update materials to reflect TensorFlow Developer Certificate closing" class="Link--secondary" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/8d87bd37746f1650851fde3b6724e0685592aea2">update materials to reflect TensorFlow Developer Certificate closing</a></div></div></td><td><div class="react-directory-commit-age"><relative-time class="sc-bcXHqe" tense="past" datetime="2024-05-02T05:08:21.000Z" title="May 1, 2024, 10:08 PM PDT"><template shadowrootmode="open">4 months ago</template>May 1, 2024</relative-time></div></td></tr><tr class="react-directory-row undefined" id="folder-row-4"><td class="react-directory-row-name-cell-small-screen" colspan="2"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="icon-directory" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="slides" aria-label="slides, (Directory)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/tree/main/slides">slides</a></div></div></div></div></td><td class="react-directory-row-name-cell-large-screen" colspan="1"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="icon-directory" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="slides" aria-label="slides, (Directory)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/tree/main/slides">slides</a></div></div></div></div></td><td class="react-directory-row-commit-cell"><div><div class="react-directory-commit-message"><a data-pjax="true" title="add slides for 11" class="Link--secondary" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/c3ee3024b0bad6bb7e7d0d574c0a228d555c0ed8">add slides for 11</a></div></div></td><td><div class="react-directory-commit-age"><relative-time class="sc-bcXHqe" tense="past" datetime="2021-07-07T04:14:30.000Z" title="Jul 6, 2021, 9:14 PM PDT"><template shadowrootmode="open">3 years ago</template>Jul 6, 2021</relative-time></div></td></tr><tr class="react-directory-row undefined" id="folder-row-5"><td class="react-directory-row-name-cell-small-screen" colspan="2"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="icon-directory" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="video_notebooks" aria-label="video_notebooks, (Directory)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/tree/main/video_notebooks">video_notebooks</a></div></div></div></div></td><td class="react-directory-row-name-cell-large-screen" colspan="1"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="icon-directory" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M1.75 1A1.75 1.75 0 0 0 0 2.75v10.5C0 14.216.784 15 1.75 15h12.5A1.75 1.75 0 0 0 16 13.25v-8.5A1.75 1.75 0 0 0 14.25 3H7.5a.25.25 0 0 1-.2-.1l-.9-1.2C6.07 1.26 5.55 1 5 1H1.75Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="video_notebooks" aria-label="video_notebooks, (Directory)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/tree/main/video_notebooks">video_notebooks</a></div></div></div></div></td><td class="react-directory-row-commit-cell"><div><div class="react-directory-commit-message"><a data-pjax="true" title="correct specific word

# correct specific word" class="Link--secondary" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/cb12591d22eaa70f33ee17060d8cef7eabb22978">correct specific word</a></div></div></td><td><div class="react-directory-commit-age"><relative-time class="sc-bcXHqe" tense="past" datetime="2023-02-25T19:49:12.000Z" title="Feb 25, 2023, 11:49 AM PST"><template shadowrootmode="open">last year</template>Feb 25, 2023</relative-time></div></td></tr><tr class="react-directory-row undefined" id="folder-row-6"><td class="react-directory-row-name-cell-small-screen" colspan="2"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title=".gitignore" aria-label=".gitignore, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/.gitignore">.gitignore</a></div></div></div></div></td><td class="react-directory-row-name-cell-large-screen" colspan="1"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title=".gitignore" aria-label=".gitignore, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/.gitignore">.gitignore</a></div></div></div></div></td><td class="react-directory-row-commit-cell"><div><div class="react-directory-commit-message"><a data-pjax="true" title="update gitignore" class="Link--secondary" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/72c9efeb57038df2918bcbdf95a5d71048616ad9">update gitignore</a></div></div></td><td><div class="react-directory-commit-age"><relative-time class="sc-bcXHqe" tense="past" datetime="2021-06-20T21:57:44.000Z" title="Jun 20, 2021, 2:57 PM PDT"><template shadowrootmode="open">3 years ago</template>Jun 20, 2021</relative-time></div></td></tr><tr class="react-directory-row undefined" id="folder-row-7"><td class="react-directory-row-name-cell-small-screen" colspan="2"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="00_tensorflow_fundamentals.ipynb" aria-label="00_tensorflow_fundamentals.ipynb, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/00_tensorflow_fundamentals.ipynb">00_tensorflow_fundamentals.ipynb</a></div></div></div></div></td><td class="react-directory-row-name-cell-large-screen" colspan="1"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="00_tensorflow_fundamentals.ipynb" aria-label="00_tensorflow_fundamentals.ipynb, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/00_tensorflow_fundamentals.ipynb">00_tensorflow_fundamentals.ipynb</a></div></div></div></div></td><td class="react-directory-row-commit-cell"><div><div class="react-directory-commit-message"><a data-pjax="true" title="upgrade tensorflow version (make sure code works)" class="Link--secondary" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/2405ed317f821dc8d0018d24725e7dca22888935">upgrade tensorflow version (make sure code works)</a></div></div></td><td><div class="react-directory-commit-age"><relative-time class="sc-bcXHqe" tense="past" datetime="2023-04-25T05:24:54.000Z" title="Apr 24, 2023, 10:24 PM PDT"><template shadowrootmode="open">last year</template>Apr 24, 2023</relative-time></div></td></tr><tr class="react-directory-row undefined" id="folder-row-8"><td class="react-directory-row-name-cell-small-screen" colspan="2"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="01_neural_network_regression_in_tensorflow.ipynb" aria-label="01_neural_network_regression_in_tensorflow.ipynb, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/01_neural_network_regression_in_tensorflow.ipynb">01_neural_network_regression_in_tensorflow.ipynb</a></div></div></div></div></td><td class="react-directory-row-name-cell-large-screen" colspan="1"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="01_neural_network_regression_in_tensorflow.ipynb" aria-label="01_neural_network_regression_in_tensorflow.ipynb, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/01_neural_network_regression_in_tensorflow.ipynb">01_neural_network_regression_in_tensorflow.ipynb</a></div></div></div></div></td><td class="react-directory-row-commit-cell"><div><div class="react-directory-commit-message"><a data-pjax="true" title="Merge pull request #534 from sanfordmascarenhas/patch-1

fix typos" class="Link--secondary" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/d74369f7701e4c76cc9222a42b192ac43941d12c">Merge pull request</a> <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="1649868315" data-permission-text="Title is private" data-url="https://github.com/mrdbourke/tensorflow-deep-learning/issues/534" data-hovercard-type="pull_request" data-hovercard-url="/mrdbourke/tensorflow-deep-learning/pull/534/hovercard" href="https://github.com/mrdbourke/tensorflow-deep-learning/pull/534">#534</a> <a data-pjax="true" title="Merge pull request #534 from sanfordmascarenhas/patch-1

fix typos" class="Link--secondary" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/d74369f7701e4c76cc9222a42b192ac43941d12c">from sanfordmascarenhas/patch-1</a></div></div></td><td><div class="react-directory-commit-age"><relative-time class="sc-bcXHqe" tense="past" datetime="2023-05-12T08:18:56.000Z" title="May 12, 2023, 1:18 AM PDT"><template shadowrootmode="open">last year</template>May 12, 2023</relative-time></div></td></tr><tr class="react-directory-row undefined" id="folder-row-9"><td class="react-directory-row-name-cell-small-screen" colspan="2"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="02_neural_network_classification_in_tensorflow.ipynb" aria-label="02_neural_network_classification_in_tensorflow.ipynb, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/02_neural_network_classification_in_tensorflow.ipynb">02_neural_network_classification_in_tensorflow.ipynb</a></div></div></div></div></td><td class="react-directory-row-name-cell-large-screen" colspan="1"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="02_neural_network_classification_in_tensorflow.ipynb" aria-label="02_neural_network_classification_in_tensorflow.ipynb, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/02_neural_network_classification_in_tensorflow.ipynb">02_neural_network_classification_in_tensorflow.ipynb</a></div></div></div></div></td><td class="react-directory-row-commit-cell"><div><div class="react-directory-commit-message"><a data-pjax="true" title="fix broken notebook formatting" class="Link--secondary" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/1f39d5dc907d2a2f32b6fbafd5de71a81c8f4a06">fix broken notebook formatting</a></div></div></td><td><div class="react-directory-commit-age"><relative-time class="sc-bcXHqe" tense="past" datetime="2023-10-12T07:13:17.000Z" title="Oct 12, 2023, 12:13 AM PDT"><template shadowrootmode="open">10 months ago</template>Oct 12, 2023</relative-time></div></td></tr><tr class="react-directory-row truncate-for-mobile" id="folder-row-10"><td class="react-directory-row-name-cell-small-screen" colspan="2"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="03_convolutional_neural_networks_in_tensorflow.ipynb" aria-label="03_convolutional_neural_networks_in_tensorflow.ipynb, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/03_convolutional_neural_networks_in_tensorflow.ipynb">03_convolutional_neural_networks_in_tensorflow.ipynb</a></div></div></div></div></td><td class="react-directory-row-name-cell-large-screen" colspan="1"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="03_convolutional_neural_networks_in_tensorflow.ipynb" aria-label="03_convolutional_neural_networks_in_tensorflow.ipynb, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/03_convolutional_neural_networks_in_tensorflow.ipynb">03_convolutional_neural_networks_in_tensorflow.ipynb</a></div></div></div></div></td><td class="react-directory-row-commit-cell"><div><div class="react-directory-commit-message"><a data-pjax="true" title="Fixing the range of randint

To prevent IndexError" class="Link--secondary" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/ac0020d989e0df1802cda9346e7721930fde36eb">Fixing the range of randint</a></div></div></td><td><div class="react-directory-commit-age"><relative-time class="sc-bcXHqe" tense="past" datetime="2023-06-14T14:34:29.000Z" title="Jun 14, 2023, 7:34 AM PDT"><template shadowrootmode="open">last year</template>Jun 14, 2023</relative-time></div></td></tr><tr class="react-directory-row truncate-for-mobile" id="folder-row-11"><td class="react-directory-row-name-cell-small-screen" colspan="2"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb" aria-label="04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb">04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb</a></div></div></div></div></td><td class="react-directory-row-name-cell-large-screen" colspan="1"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb" aria-label="04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb">04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb</a></div></div></div></div></td><td class="react-directory-row-commit-cell"><div><div class="react-directory-commit-message"><a data-pjax="true" title="update for new tensorflow version + add timestamp" class="Link--secondary" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/9ef139c60ea021c7b1ef68856c092bfb4713138f">update for new tensorflow version + add timestamp</a></div></div></td><td><div class="react-directory-commit-age"><relative-time class="sc-bcXHqe" tense="past" datetime="2023-05-11T04:43:41.000Z" title="May 10, 2023, 9:43 PM PDT"><template shadowrootmode="open">last year</template>May 10, 2023</relative-time></div></td></tr><tr class="react-directory-row truncate-for-mobile" id="folder-row-12"><td class="react-directory-row-name-cell-small-screen" colspan="2"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="05_transfer_learning_in_tensorflow_part_2_fine_tuning.ipynb" aria-label="05_transfer_learning_in_tensorflow_part_2_fine_tuning.ipynb, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/05_transfer_learning_in_tensorflow_part_2_fine_tuning.ipynb">05_transfer_learning_in_tensorflow_part_2_fine_tuning.ipynb</a></div></div></div></div></td><td class="react-directory-row-name-cell-large-screen" colspan="1"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="05_transfer_learning_in_tensorflow_part_2_fine_tuning.ipynb" aria-label="05_transfer_learning_in_tensorflow_part_2_fine_tuning.ipynb, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/05_transfer_learning_in_tensorflow_part_2_fine_tuning.ipynb">05_transfer_learning_in_tensorflow_part_2_fine_tuning.ipynb</a></div></div></div></div></td><td class="react-directory-row-commit-cell"><div><div class="react-directory-commit-message"><a data-pjax="true" title="update code to fix #553 and #544, see #575 for notes" class="Link--secondary" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/432eec208de609a969263d2f36ffccbd0ebdbd26">update code to</a> <span class="issue-keyword tooltipped tooltipped-se" aria-label="This commit closes issue #553."><a data-pjax="true" title="update code to fix #553 and #544, see #575 for notes" class="Link--secondary" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/432eec208de609a969263d2f36ffccbd0ebdbd26">fix</a></span> <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="1721260828" data-permission-text="Title is private" data-url="https://github.com/mrdbourke/tensorflow-deep-learning/issues/553" data-hovercard-type="issue" data-hovercard-url="/mrdbourke/tensorflow-deep-learning/issues/553/hovercard" href="https://github.com/mrdbourke/tensorflow-deep-learning/issues/553">#553</a> <a data-pjax="true" title="update code to fix #553 and #544, see #575 for notes" class="Link--secondary" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/432eec208de609a969263d2f36ffccbd0ebdbd26">and</a> <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="1686834553" data-permission-text="Title is private" data-url="https://github.com/mrdbourke/tensorflow-deep-learning/issues/544" data-hovercard-type="issue" data-hovercard-url="/mrdbourke/tensorflow-deep-learning/issues/544/hovercard" href="https://github.com/mrdbourke/tensorflow-deep-learning/issues/544">#544</a><a data-pjax="true" title="update code to fix #553 and #544, see #575 for notes" class="Link--secondary" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/432eec208de609a969263d2f36ffccbd0ebdbd26">, see</a> <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="5529218" data-permission-text="Title is private" data-url="https://github.com/mrdbourke/tensorflow-deep-learning/discussions/575" data-hovercard-type="discussion" data-hovercard-url="/mrdbourke/tensorflow-deep-learning/discussions/575/hovercard" href="https://github.com/mrdbourke/tensorflow-deep-learning/discussions/575">#575</a> <a data-pjax="true" title="update code to fix #553 and #544, see #575 for notes" class="Link--secondary" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/432eec208de609a969263d2f36ffccbd0ebdbd26">for notes</a></div></div></td><td><div class="react-directory-commit-age"><relative-time class="sc-bcXHqe" tense="past" datetime="2023-08-18T01:50:21.000Z" title="Aug 17, 2023, 6:50 PM PDT"><template shadowrootmode="open">last year</template>Aug 17, 2023</relative-time></div></td></tr><tr class="react-directory-row truncate-for-mobile" id="folder-row-13"><td class="react-directory-row-name-cell-small-screen" colspan="2"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="06_transfer_learning_in_tensorflow_part_3_scaling_up.ipynb" aria-label="06_transfer_learning_in_tensorflow_part_3_scaling_up.ipynb, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/06_transfer_learning_in_tensorflow_part_3_scaling_up.ipynb">06_transfer_learning_in_tensorflow_part_3_scaling_up.ipynb</a></div></div></div></div></td><td class="react-directory-row-name-cell-large-screen" colspan="1"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="06_transfer_learning_in_tensorflow_part_3_scaling_up.ipynb" aria-label="06_transfer_learning_in_tensorflow_part_3_scaling_up.ipynb, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/06_transfer_learning_in_tensorflow_part_3_scaling_up.ipynb">06_transfer_learning_in_tensorflow_part_3_scaling_up.ipynb</a></div></div></div></div></td><td class="react-directory-row-commit-cell"><div><div class="react-directory-commit-message"><a data-pjax="true" title="update tensorflow version, update to newer TensorFlow APIs" class="Link--secondary" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/fca836b9afc1f8b8ff41b7c1eab9d38664be8166">update tensorflow version, update to newer TensorFlow APIs</a></div></div></td><td><div class="react-directory-commit-age"><relative-time class="sc-bcXHqe" tense="past" datetime="2023-05-18T02:31:56.000Z" title="May 17, 2023, 7:31 PM PDT"><template shadowrootmode="open">last year</template>May 17, 2023</relative-time></div></td></tr><tr class="react-directory-row truncate-for-mobile" id="folder-row-14"><td class="react-directory-row-name-cell-small-screen" colspan="2"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="07_food_vision_milestone_project_1.ipynb" aria-label="07_food_vision_milestone_project_1.ipynb, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/07_food_vision_milestone_project_1.ipynb">07_food_vision_milestone_project_1.ipynb</a></div></div></div></div></td><td class="react-directory-row-name-cell-large-screen" colspan="1"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="07_food_vision_milestone_project_1.ipynb" aria-label="07_food_vision_milestone_project_1.ipynb, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/07_food_vision_milestone_project_1.ipynb">07_food_vision_milestone_project_1.ipynb</a></div></div></div></div></td><td class="react-directory-row-commit-cell"><div><div class="react-directory-commit-message"><a data-pjax="true" title="update to latest version of TensorFlow" class="Link--secondary" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/334cd82c694b8b327f75689898796b6297f0006c">update to latest version of TensorFlow</a></div></div></td><td><div class="react-directory-commit-age"><relative-time class="sc-bcXHqe" tense="past" datetime="2023-05-19T02:54:55.000Z" title="May 18, 2023, 7:54 PM PDT"><template shadowrootmode="open">last year</template>May 18, 2023</relative-time></div></td></tr><tr class="react-directory-row truncate-for-mobile" id="folder-row-15"><td class="react-directory-row-name-cell-small-screen" colspan="2"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="08_introduction_to_nlp_in_tensorflow.ipynb" aria-label="08_introduction_to_nlp_in_tensorflow.ipynb, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/08_introduction_to_nlp_in_tensorflow.ipynb">08_introduction_to_nlp_in_tensorflow.ipynb</a></div></div></div></div></td><td class="react-directory-row-name-cell-large-screen" colspan="1"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="08_introduction_to_nlp_in_tensorflow.ipynb" aria-label="08_introduction_to_nlp_in_tensorflow.ipynb, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/08_introduction_to_nlp_in_tensorflow.ipynb">08_introduction_to_nlp_in_tensorflow.ipynb</a></div></div></div></div></td><td class="react-directory-row-commit-cell"><div><div class="react-directory-commit-message"><a data-pjax="true" title="update to latest version of TensorFlow" class="Link--secondary" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/4a53a08632b22026008aead22a0939df09d1a592">update to latest version of TensorFlow</a></div></div></td><td><div class="react-directory-commit-age"><relative-time class="sc-bcXHqe" tense="past" datetime="2023-05-26T00:21:31.000Z" title="May 25, 2023, 5:21 PM PDT"><template shadowrootmode="open">last year</template>May 25, 2023</relative-time></div></td></tr><tr class="react-directory-row truncate-for-mobile" id="folder-row-16"><td class="react-directory-row-name-cell-small-screen" colspan="2"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="09_SkimLit_nlp_milestone_project_2.ipynb" aria-label="09_SkimLit_nlp_milestone_project_2.ipynb, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/09_SkimLit_nlp_milestone_project_2.ipynb">09_SkimLit_nlp_milestone_project_2.ipynb</a></div></div></div></div></td><td class="react-directory-row-name-cell-large-screen" colspan="1"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="09_SkimLit_nlp_milestone_project_2.ipynb" aria-label="09_SkimLit_nlp_milestone_project_2.ipynb, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/09_SkimLit_nlp_milestone_project_2.ipynb">09_SkimLit_nlp_milestone_project_2.ipynb</a></div></div></div></div></td><td class="react-directory-row-commit-cell"><div><div class="react-directory-commit-message"><a data-pjax="true" title="fix broken model download link, update to latest version of TensorFlow" class="Link--secondary" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/360e289515a4c0ae33e8f2946116d1687d7463fd">fix broken model download link, update to latest version of TensorFlow</a></div></div></td><td><div class="react-directory-commit-age"><relative-time class="sc-bcXHqe" tense="past" datetime="2023-05-26T03:56:59.000Z" title="May 25, 2023, 8:56 PM PDT"><template shadowrootmode="open">last year</template>May 25, 2023</relative-time></div></td></tr><tr class="react-directory-row truncate-for-mobile" id="folder-row-17"><td class="react-directory-row-name-cell-small-screen" colspan="2"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="10_time_series_forecasting_in_tensorflow.ipynb" aria-label="10_time_series_forecasting_in_tensorflow.ipynb, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/10_time_series_forecasting_in_tensorflow.ipynb">10_time_series_forecasting_in_tensorflow.ipynb</a></div></div></div></div></td><td class="react-directory-row-name-cell-large-screen" colspan="1"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="10_time_series_forecasting_in_tensorflow.ipynb" aria-label="10_time_series_forecasting_in_tensorflow.ipynb, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/10_time_series_forecasting_in_tensorflow.ipynb">10_time_series_forecasting_in_tensorflow.ipynb</a></div></div></div></div></td><td class="react-directory-row-commit-cell"><div><div class="react-directory-commit-message"><a data-pjax="true" title="update MASE link" class="Link--secondary" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/d0e508c1526f428a346901452187f3b67f4aaf5d">update MASE link</a></div></div></td><td><div class="react-directory-commit-age"><relative-time class="sc-bcXHqe" tense="past" datetime="2021-09-29T07:25:13.000Z" title="Sep 29, 2021, 12:25 AM PDT"><template shadowrootmode="open">3 years ago</template>Sep 29, 2021</relative-time></div></td></tr><tr class="react-directory-row truncate-for-mobile" id="folder-row-18"><td class="react-directory-row-name-cell-small-screen" colspan="2"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="11_passing_the_tensorflow_developer_certification_exam.md" aria-label="11_passing_the_tensorflow_developer_certification_exam.md, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/11_passing_the_tensorflow_developer_certification_exam.md">11_passing_the_tensorflow_developer_certification_exam.md</a></div></div></div></div></td><td class="react-directory-row-name-cell-large-screen" colspan="1"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="11_passing_the_tensorflow_developer_certification_exam.md" aria-label="11_passing_the_tensorflow_developer_certification_exam.md, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/11_passing_the_tensorflow_developer_certification_exam.md">11_passing_the_tensorflow_developer_certification_exam.md</a></div></div></div></div></td><td class="react-directory-row-commit-cell"><div><div class="react-directory-commit-message"><a data-pjax="true" title="update image link and docs title for section 11" class="Link--secondary" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/bd065b806249f7b1155e5b1fabd130c5cfc9d184">update image link and docs title for section 11</a></div></div></td><td><div class="react-directory-commit-age"><relative-time class="sc-bcXHqe" tense="past" datetime="2024-05-02T05:17:49.000Z" title="May 1, 2024, 10:17 PM PDT"><template shadowrootmode="open">4 months ago</template>May 1, 2024</relative-time></div></td></tr><tr class="react-directory-row truncate-for-mobile" id="folder-row-19"><td class="react-directory-row-name-cell-small-screen" colspan="2"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="LICENSE" aria-label="LICENSE, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/LICENSE">LICENSE</a></div></div></div></div></td><td class="react-directory-row-name-cell-large-screen" colspan="1"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="LICENSE" aria-label="LICENSE, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/LICENSE">LICENSE</a></div></div></div></div></td><td class="react-directory-row-commit-cell"><div><div class="react-directory-commit-message"><a data-pjax="true" title="Initial commit" class="Link--secondary" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/8253a62ab11243d4eaf87e83ca299d1f010168f3">Initial commit</a></div></div></td><td><div class="react-directory-commit-age"><relative-time class="sc-bcXHqe" tense="past" datetime="2020-11-23T23:11:44.000Z" title="Nov 23, 2020, 3:11 PM PST"><template shadowrootmode="open">4 years ago</template>Nov 23, 2020</relative-time></div></td></tr><tr class="react-directory-row truncate-for-mobile" id="folder-row-20"><td class="react-directory-row-name-cell-small-screen" colspan="2"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="README.md" aria-label="README.md, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/README.md">README.md</a></div></div></div></div></td><td class="react-directory-row-name-cell-large-screen" colspan="1"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="README.md" aria-label="README.md, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/README.md">README.md</a></div></div></div></div></td><td class="react-directory-row-commit-cell"><div><div class="react-directory-commit-message"><a data-pjax="true" title="update readme" class="Link--secondary" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/01fff4b482184ca3e1118a5720d0dc16ce744708">update readme</a></div></div></td><td><div class="react-directory-commit-age"><relative-time class="sc-bcXHqe" tense="past" datetime="2024-05-02T05:11:08.000Z" title="May 1, 2024, 10:11 PM PDT"><template shadowrootmode="open">4 months ago</template>May 1, 2024</relative-time></div></td></tr><tr class="react-directory-row truncate-for-mobile" id="folder-row-21"><td class="react-directory-row-name-cell-small-screen" colspan="2"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="mkdocs.yml" aria-label="mkdocs.yml, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/mkdocs.yml">mkdocs.yml</a></div></div></div></div></td><td class="react-directory-row-name-cell-large-screen" colspan="1"><div class="react-directory-filename-column"><svg aria-hidden="true" focusable="false" role="img" class="color-fg-muted" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display: inline-block; user-select: none; vertical-align: text-bottom; overflow: visible;"><path d="M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z"></path></svg><div class="overflow-hidden"><div class="react-directory-filename-cell"><div class="react-directory-truncate"><a title="mkdocs.yml" aria-label="mkdocs.yml, (File)" class="Link--primary" href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/mkdocs.yml">mkdocs.yml</a></div></div></div></div></td><td class="react-directory-row-commit-cell"><div><div class="react-directory-commit-message"><a data-pjax="true" title="update image link and docs title for section 11" class="Link--secondary" href="https://github.com/mrdbourke/tensorflow-deep-learning/commit/bd065b806249f7b1155e5b1fabd130c5cfc9d184">update image link and docs title for section 11</a></div></div></td><td><div class="react-directory-commit-age"><relative-time class="sc-bcXHqe" tense="past" datetime="2024-05-02T05:17:49.000Z" title="May 1, 2024, 10:17 PM PDT"><template shadowrootmode="open">4 months ago</template>May 1, 2024</relative-time></div></td></tr><tr class="Box-sc-g0xbh4-0 epsqEd show-for-mobile" data-testid="view-all-files-row"><td colspan="3" class="Box-sc-g0xbh4-0 ldpruc"><div><button class="Link__StyledLink-sc-14289xe-0 dheQRw">View all files</button></div></td></tr></tbody></table></div><div class="Box-sc-g0xbh4-0 ehcSsh"><div class="Box-sc-g0xbh4-0 iGmlUb"><div itemscope="" itemtype="https://schema.org/abstract" class="Box-sc-g0xbh4-0 iRQGXA"><h2 class="_VisuallyHidden__VisuallyHidden-sc-11jhm7a-0 rTZSs">Repository files navigation</h2><nav aria-label="Repository files" class="UnderlineTabbedInterface__StyledUnderlineWrapper-sc-4ilrg0-0 iRCRcS"><ul role="list" class="UnderlineTabbedInterface__StyledUnderlineItemList-sc-4ilrg0-1 cgXGvr"><li class="Box-sc-g0xbh4-0 gwuIGu"><a href="https://github.com/mrdbourke/tensorflow-deep-learning#" aria-current="page" class="UnderlineTabbedInterface__StyledUnderlineItem-sc-4ilrg0-2 cSDcQt"><span data-component="icon"><svg aria-hidden="true" focusable="false" role="img" class="octicon octicon-book" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path d="M0 1.75A.75.75 0 0 1 .75 1h4.253c1.227 0 2.317.59 3 1.501A3.743 3.743 0 0 1 11.006 1h4.245a.75.75 0 0 1 .75.75v10.5a.75.75 0 0 1-.75.75h-4.507a2.25 2.25 0 0 0-1.591.659l-.622.621a.75.75 0 0 1-1.06 0l-.622-.621A2.25 2.25 0 0 0 5.258 13H.75a.75.75 0 0 1-.75-.75Zm7.251 10.324.004-5.073-.002-2.253A2.25 2.25 0 0 0 5.003 2.5H1.5v9h3.757a3.75 3.75 0 0 1 1.994.574ZM8.755 4.75l-.004 7.322a3.752 3.752 0 0 1 1.992-.572H14.5v-9h-3.495a2.25 2.25 0 0 0-2.25 2.25Z"></path></svg></span><span data-component="text" data-content="README">README</span></a></li><li class="Box-sc-g0xbh4-0 gwuIGu"><a href="https://github.com/mrdbourke/tensorflow-deep-learning#" class="UnderlineTabbedInterface__StyledUnderlineItem-sc-4ilrg0-2 cSDcQt"><span data-component="icon"><svg aria-hidden="true" focusable="false" role="img" class="octicon octicon-law" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path d="M8.75.75V2h.985c.304 0 .603.08.867.231l1.29.736c.038.022.08.033.124.033h2.234a.75.75 0 0 1 0 1.5h-.427l2.111 4.692a.75.75 0 0 1-.154.838l-.53-.53.529.531-.001.002-.002.002-.006.006-.006.005-.01.01-.045.04c-.21.176-.441.327-.686.45C14.556 10.78 13.88 11 13 11a4.498 4.498 0 0 1-2.023-.454 3.544 3.544 0 0 1-.686-.45l-.045-.04-.016-.015-.006-.006-.004-.004v-.001a.75.75 0 0 1-.154-.838L12.178 4.5h-.162c-.305 0-.604-.079-.868-.231l-1.29-.736a.245.245 0 0 0-.124-.033H8.75V13h2.5a.75.75 0 0 1 0 1.5h-6.5a.75.75 0 0 1 0-1.5h2.5V3.5h-.984a.245.245 0 0 0-.124.033l-1.289.737c-.265.15-.564.23-.869.23h-.162l2.112 4.692a.75.75 0 0 1-.154.838l-.53-.53.529.531-.001.002-.002.002-.006.006-.016.015-.045.04c-.21.176-.441.327-.686.45C4.556 10.78 3.88 11 3 11a4.498 4.498 0 0 1-2.023-.454 3.544 3.544 0 0 1-.686-.45l-.045-.04-.016-.015-.006-.006-.004-.004v-.001a.75.75 0 0 1-.154-.838L2.178 4.5H1.75a.75.75 0 0 1 0-1.5h2.234a.249.249 0 0 0 .125-.033l1.288-.737c.265-.15.564-.23.869-.23h.984V.75a.75.75 0 0 1 1.5 0Zm2.945 8.477c.285.135.718.273 1.305.273s1.02-.138 1.305-.273L13 6.327Zm-10 0c.285.135.718.273 1.305.273s1.02-.138 1.305-.273L3 6.327Z"></path></svg></span><span data-component="text" data-content="MIT license">MIT license</span></a></li></ul></nav><button data-component="IconButton" type="button" aria-label="Edit file" title="Edit file" data-loading="false" data-no-visuals="true" data-size="small" aria-describedby=":Rj9ab:-loading-announcement" class="types__StyledButton-sc-ws60qy-0 iZuQcP" data-hotkey="e,Shift+E"><svg aria-hidden="true" focusable="false" role="img" class="octicon octicon-pencil" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path d="M11.013 1.427a1.75 1.75 0 0 1 2.474 0l1.086 1.086a1.75 1.75 0 0 1 0 2.474l-8.61 8.61c-.21.21-.47.364-.756.445l-3.251.93a.75.75 0 0 1-.927-.928l.929-3.25c.081-.286.235-.547.445-.758l8.61-8.61Zm.176 4.823L9.75 4.81l-6.286 6.287a.253.253 0 0 0-.064.108l-.558 1.953 1.953-.558a.253.253 0 0 0 .108-.064Zm1.238-3.763a.25.25 0 0 0-.354 0L10.811 3.75l1.439 1.44 1.263-1.263a.25.25 0 0 0 0-.354Z"></path></svg></button><button style="--button-color:fg.subtle" type="button" aria-label="Outline" aria-haspopup="true" aria-expanded="false" tabindex="0" data-loading="false" aria-describedby=":Rr9ab:-loading-announcement" id=":Rr9ab:" class="types__StyledButton-sc-ws60qy-0 iNcPMC"><svg aria-hidden="true" focusable="false" role="img" class="octicon octicon-list-unordered" viewBox="0 0 16 16" width="16" height="16" fill="currentColor" style="display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path d="M5.75 2.5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5Zm0 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5Zm0 5h8.5a.75.75 0 0 1 0 1.5h-8.5a.75.75 0 0 1 0-1.5ZM2 14a1 1 0 1 1 0-2 1 1 0 0 1 0 2Zm1-6a1 1 0 1 1-2 0 1 1 0 0 1 2 0ZM2 4a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg></button></div><div class="Box-sc-g0xbh4-0 bJMeLZ js-snippet-clipboard-copy-unpositioned" data-hpc="true"><article class="markdown-body entry-content container-lg" itemprop="text"><div class="markdown-heading" dir="auto"><h1 tabindex="-1" class="heading-element" dir="auto">Zero to Mastery Deep Learning with TensorFlow</h1><a id="user-content-zero-to-mastery-deep-learning-with-tensorflow" class="anchor" aria-label="Permalink: Zero to Mastery Deep Learning with TensorFlow" href="https://github.com/mrdbourke/tensorflow-deep-learning#zero-to-mastery-deep-learning-with-tensorflow"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">All of the course materials for the <a href="https://dbourke.link/ZTMTFcourse" rel="nofollow">Zero to Mastery Deep Learning with TensorFlow course</a>.</p>
<p dir="auto">This course will teach you the foundations of deep learning and how to build and train neural networks for various problem types with TensorFlow/Keras.</p>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto">Important links</h2><a id="user-content-important-links" class="anchor" aria-label="Permalink: Important links" href="https://github.com/mrdbourke/tensorflow-deep-learning#important-links"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li> Watch the <a href="https://dbourke.link/tfpart1part2" rel="nofollow">first 14-hours of the course on YouTube</a> (notebooks 00, 01, 02)</li>
<li> Read the <a href="https://dev.mrdbourke.com/tensorflow-deep-learning/" rel="nofollow">beautiful online book version of the course</a></li>
<li> <a href="https://dbourke.link/ZTMTFcourse" rel="nofollow">Sign up</a> to the full course on the Zero to Mastery Academy (videos for notebooks 03-10)</li>
<li> Got questions about the course? Check out the <a href="https://youtu.be/rqAqcFcfeK8" rel="nofollow">livestream Q&amp;A for the course launch</a></li>
<li> Get a quick overview of TensorFlow with the <a href="https://zerotomastery.io/cheatsheets/tensorflow-cheat-sheet/" rel="nofollow">TensorFlow Cheatsheet</a></li>
</ul>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto">Contents of this page</h2><a id="user-content-contents-of-this-page" class="anchor" aria-label="Permalink: Contents of this page" href="https://github.com/mrdbourke/tensorflow-deep-learning#contents-of-this-page"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li><a href="https://github.com/mrdbourke/tensorflow-deep-learning#fixes-and-updates">Fixes and updates</a></li>
<li><a href="https://github.com/mrdbourke/tensorflow-deep-learning#course-materials">Course materials</a> (everything you'll need for completing the course)</li>
<li><a href="https://github.com/mrdbourke/tensorflow-deep-learning#course-structure">Course structure</a> (how this course is taught)</li>
<li><a href="https://github.com/mrdbourke/tensorflow-deep-learning#should-you-do-this-course">Should you do this course?</a> (decide by answering a couple simple questions)</li>
<li><a href="https://github.com/mrdbourke/tensorflow-deep-learning#prerequisites">Prerequisites</a> (what skills you'll need to do this course)</li>
<li><a href="https://github.com/mrdbourke/tensorflow-deep-learning#-exercises---extra-curriculum">Exercises &amp; Extra-curriculum</a> (challenges to practice what you've learned and resources to learn more)</li>
<li><a href="https://github.com/mrdbourke/tensorflow-deep-learning#ask-questions">Ask a question</a> (like to know more? go here)</li>
<li><a href="https://github.com/mrdbourke/tensorflow-deep-learning#status">Status</a></li>
<li><a href="https://github.com/mrdbourke/tensorflow-deep-learning#log">Log</a> (updates, changes and progress)</li>
</ul>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto">Fixes and updates</h2><a id="user-content-fixes-and-updates" class="anchor" aria-label="Permalink: Fixes and updates" href="https://github.com/mrdbourke/tensorflow-deep-learning#fixes-and-updates"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>2 May 2024 - Update section 11 to reflect closing of TensorFlow Developer Certification program by Google (see <a href="https://github.com/mrdbourke/tensorflow-deep-learning/discussions/645" data-hovercard-type="discussion" data-hovercard-url="/mrdbourke/tensorflow-deep-learning/discussions/645/hovercard">#645</a> for more)</li>
<li>18 Aug 2023 - Update <a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/05_transfer_learning_in_tensorflow_part_2_fine_tuning.ipynb">Notebook 05</a> to fix <a href="https://github.com/mrdbourke/tensorflow-deep-learning/issues/544" data-hovercard-type="issue" data-hovercard-url="/mrdbourke/tensorflow-deep-learning/issues/544/hovercard">#544</a> and <a href="https://github.com/mrdbourke/tensorflow-deep-learning/issues/553" data-hovercard-type="issue" data-hovercard-url="/mrdbourke/tensorflow-deep-learning/issues/553/hovercard">#553</a>, see <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="5529218" data-permission-text="Title is private" data-url="https://github.com/mrdbourke/tensorflow-deep-learning/discussions/575" data-hovercard-type="discussion" data-hovercard-url="/mrdbourke/tensorflow-deep-learning/discussions/575/hovercard" href="https://github.com/mrdbourke/tensorflow-deep-learning/discussions/575">#575</a> for full notes
<ul dir="auto">
<li>In short, if you're using <code>tf.keras.applications.EfficientNetB0</code> and facing errors, swap to <a href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet_v2/EfficientNetV2B0" rel="nofollow"><code>tf.keras.applications.efficientnet_v2.EfficientNetV2B0</code></a></li>
</ul>
</li>
<li>26 May 2023 - Update <a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/08_introduction_to_nlp_in_tensorflow.ipynb">Notebook 08</a> for new version of TensorFlow + update <a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/09_SkimLit_nlp_milestone_project_2.ipynb">Notebook 09</a> for new version of TensorFlow &amp; spaCy, see update notes for 09: <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="5234715" data-permission-text="Title is private" data-url="https://github.com/mrdbourke/tensorflow-deep-learning/discussions/557" data-hovercard-type="discussion" data-hovercard-url="/mrdbourke/tensorflow-deep-learning/discussions/557/hovercard" href="https://github.com/mrdbourke/tensorflow-deep-learning/discussions/557">#557</a></li>
<li>19 May 2023 - Update <a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/07_food_vision_milestone_project_1.ipynb">Notebook 07</a> for new version of TensorFlow + fix model loading errors (TensorFlow 2.13+ required), see: <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="5208147" data-permission-text="Title is private" data-url="https://github.com/mrdbourke/tensorflow-deep-learning/discussions/550" data-hovercard-type="discussion" data-hovercard-url="/mrdbourke/tensorflow-deep-learning/discussions/550/hovercard" href="https://github.com/mrdbourke/tensorflow-deep-learning/discussions/550">#550</a></li>
<li>18 May 2023 - Update Notebook 06 for new TensorFlow namespaces (no major functionality change, just different imports), see: <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="5207679" data-permission-text="Title is private" data-url="https://github.com/mrdbourke/tensorflow-deep-learning/discussions/549" data-hovercard-type="discussion" data-hovercard-url="/mrdbourke/tensorflow-deep-learning/discussions/549/hovercard" href="https://github.com/mrdbourke/tensorflow-deep-learning/discussions/549">#549</a></li>
<li>12 May 2023 - Notebook 05 new namespaces added for <code>tf.keras.layers</code>, see <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="5187992" data-permission-text="Title is private" data-url="https://github.com/mrdbourke/tensorflow-deep-learning/discussions/547" data-hovercard-type="discussion" data-hovercard-url="/mrdbourke/tensorflow-deep-learning/discussions/547/hovercard" href="https://github.com/mrdbourke/tensorflow-deep-learning/discussions/547">#547</a>, also add fix for issue with <code>model.load_weights()</code> in Notebook 05, see <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="1686834553" data-permission-text="Title is private" data-url="https://github.com/mrdbourke/tensorflow-deep-learning/issues/544" data-hovercard-type="issue" data-hovercard-url="/mrdbourke/tensorflow-deep-learning/issues/544/hovercard" href="https://github.com/mrdbourke/tensorflow-deep-learning/issues/544">#544</a>, if you're having trouble saving/loading the model weights, also see <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="1721260828" data-permission-text="Title is private" data-url="https://github.com/mrdbourke/tensorflow-deep-learning/issues/553" data-hovercard-type="issue" data-hovercard-url="/mrdbourke/tensorflow-deep-learning/issues/553/hovercard" href="https://github.com/mrdbourke/tensorflow-deep-learning/issues/553">#553</a></li>
<li>12 May 2023 - Newer versions of TensorFlow (2.10+) use <code>learning_rate</code> instead of <code>lr</code> in <code>tf.keras.optimizers</code> (e.g. <code>tf.keras.optimizers.Adam(learning_rate=0.001)</code>, old <code>lr</code> still works but is deprecated</li>
<li>02 Dec 2021 - Added fix for TensorFlow 2.7.0+ for notebook 02, <a href="https://github.com/mrdbourke/tensorflow-deep-learning/discussions/278" data-hovercard-type="discussion" data-hovercard-url="/mrdbourke/tensorflow-deep-learning/discussions/278/hovercard">see discussion for more</a></li>
<li>11 Nov 2021 - Added fix for TensorFlow 2.7.0+ for notebook 01,  <a href="https://github.com/mrdbourke/tensorflow-deep-learning/discussions/256" data-hovercard-type="discussion" data-hovercard-url="/mrdbourke/tensorflow-deep-learning/discussions/256/hovercard">see discussion for more</a></li>
</ul>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto">Course materials</h2><a id="user-content-course-materials" class="anchor" aria-label="Permalink: Course materials" href="https://github.com/mrdbourke/tensorflow-deep-learning#course-materials"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">This table is the ground truth for course materials. All the links you need for everything will be here.</p>
<p dir="auto">Key:</p>
<ul dir="auto">
<li><strong>Number:</strong> The number of the target notebook (this may not match the video section of the course but it ties together all of the materials in the table)</li>
<li><strong>Notebook:</strong> The notebook for a particular module with lots of code and text annotations (notebooks from the videos are based on these)</li>
<li><strong>Data/model:</strong> Links to datasets/pre-trained models for the associated notebook</li>
<li><strong>Exercises &amp; Extra-curriculum:</strong> Each module comes with a set of exercises and extra-curriculum to help practice your skills and learn more, I suggest going through these <strong>before</strong> you move onto the next module</li>
<li><strong>Slides:</strong> Although we focus on writing TensorFlow code, we sometimes use pretty slides to describe different concepts, you'll find them here</li>
</ul>
<p dir="auto"><strong>Note:</strong> You can get all of the notebook code created during the videos in the <a href="https://github.com/mrdbourke/tensorflow-deep-learning/tree/main/video_notebooks"><code>video_notebooks</code></a> directory.</p>
<markdown-accessiblity-table data-catalyst=""><table>
<thead>
<tr>
<th>Number</th>
<th>Notebook</th>
<th>Data/Model</th>
<th>Exercises &amp; Extra-curriculum</th>
<th>Slides</th>
</tr>
</thead>
<tbody>
<tr>
<td>00</td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/00_tensorflow_fundamentals.ipynb">TensorFlow Fundamentals</a></td>
<td></td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning#-00-tensorflow-fundamentals-exercises">Go to exercises &amp; extra-curriculum</a></td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/slides/00_introduction_to_tensorflow_and_deep_learning.pdf">Go to slides</a></td>
</tr>
<tr>
<td>01</td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/01_neural_network_regression_in_tensorflow.ipynb">TensorFlow Regression</a></td>
<td></td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning#-01-neural-network-regression-with-tensorflow-exercises">Go to exercises &amp; extra-curriculum</a></td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/slides/01_neural_network_regression_with_tensorflow.pdf">Go to slides</a></td>
</tr>
<tr>
<td>02</td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/02_neural_network_classification_in_tensorflow.ipynb">TensorFlow Classification</a></td>
<td></td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning#-02-neural-network-classification-with-tensorflow-exercises">Go to exercises &amp; extra-curriculum</a></td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/slides/02_neural_network_classification_with_tensorflow.pdf">Go to slides</a></td>
</tr>
<tr>
<td>03</td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/03_convolutional_neural_networks_in_tensorflow.ipynb">TensorFlow Computer Vision</a></td>
<td><a href="https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip" rel="nofollow"><code>pizza_steak</code></a>, <a href="https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip" rel="nofollow"><code>10_food_classes_all_data</code></a></td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning#-03-computer-vision--convolutional-neural-networks-in-tensorflow-exercises">Go to exercises &amp; extra-curriculum</a></td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/slides/03_convolution_neural_networks_and_computer_vision_with_tensorflow.pdf">Go to slides</a></td>
</tr>
<tr>
<td>04</td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb">Transfer Learning Part 1: Feature extraction</a></td>
<td><a href="https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip" rel="nofollow"><code>10_food_classes_10_percent</code></a></td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning#-04-transfer-learning-in-tensorflow-part-1-feature-extraction-exercises">Go to exercises &amp; extra-curriculum</a></td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/slides/04_transfer_learning_with_tensorflow_part_1_feature_extraction.pdf">Go to slides</a></td>
</tr>
<tr>
<td>05</td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/05_transfer_learning_in_tensorflow_part_2_fine_tuning.ipynb">Transfer Learning Part 2: Fine-tuning</a></td>
<td><a href="https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip" rel="nofollow"><code>10_food_classes_10_percent</code></a>, <a href="https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_1_percent.zip" rel="nofollow"><code>10_food_classes_1_percent</code></a>, <a href="https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip" rel="nofollow"><code>10_food_classes_all_data</code></a></td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning#-05-transfer-learning-in-tensorflow-part-2-fine-tuning-exercises">Go to exercises &amp; extra-curriculum</a></td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/slides/05_transfer_learning_with_tensorflow_part_2_fine_tuning.pdf">Go to slides</a></td>
</tr>
<tr>
<td>06</td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/06_transfer_learning_in_tensorflow_part_3_scaling_up.ipynb">Transfer Learning Part 3: Scaling up</a></td>
<td><a href="https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip" rel="nofollow"><code>101_food_classes_10_percent</code></a>, <a href="https://storage.googleapis.com/ztm_tf_course/food_vision/custom_food_images.zip" rel="nofollow"><code>custom_food_images</code></a>, <a href="https://storage.googleapis.com/ztm_tf_course/food_vision/06_101_food_class_10_percent_saved_big_dog_model.zip" rel="nofollow"><code>fine_tuned_efficientnet_model</code></a></td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning#-06-transfer-learning-in-tensorflow-part-3-scaling-up-exercises">Go to exercises &amp; extra-curriculum</a></td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/slides/06_transfer_learning_with_tensorflow_part_3_scaling_up.pdf">Go to slides</a></td>
</tr>
<tr>
<td>07</td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/07_food_vision_milestone_project_1.ipynb">Milestone Project 1: Food Vision </a>, <a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/TEMPLATE_07_food_vision_milestone_project_1.ipynb">Template (your challenge)</a></td>
<td><a href="https://storage.googleapis.com/ztm_tf_course/food_vision/07_efficientnetb0_feature_extract_model_mixed_precision.zip" rel="nofollow"><code>feature_extraction_mixed_precision_efficientnet_model</code></a>, <a href="https://storage.googleapis.com/ztm_tf_course/food_vision/07_efficientnetb0_fine_tuned_101_classes_mixed_precision.zip" rel="nofollow"><code>fine_tuned_mixed_precision_efficientnet_model</code></a></td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning#-07-milestone-project-1--food-vision-big-exercises">Go to exercises &amp; extra-curriculum</a></td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/slides/07_milestone_project_1_food_vision.pdf">Go to slides</a></td>
</tr>
<tr>
<td>08</td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/08_introduction_to_nlp_in_tensorflow.ipynb">TensorFlow NLP Fundamentals</a></td>
<td><a href="https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip" rel="nofollow"><code>diaster_or_no_diaster_tweets</code></a>, <a href="https://storage.googleapis.com/ztm_tf_course/08_model_6_USE_feature_extractor.zip" rel="nofollow"><code>USE_feature_extractor_model</code></a></td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning#-08-introduction-to-nlp-natural-language-processing-in-tensorflow-exercises">Go to exercises &amp; extra-curriculum</a></td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/slides/08_natural_language_processing_in_tensorflow.pdf">Go to slides</a></td>
</tr>
<tr>
<td>09</td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/09_SkimLit_nlp_milestone_project_2.ipynb">Milestone Project 2: SkimLit </a></td>
<td><a href="https://github.com/Franck-Dernoncourt/pubmed-rct.git"><code>pubmed_RCT_200k_dataset</code></a>, <a href="https://storage.googleapis.com/ztm_tf_course/skimlit/skimlit_tribrid_model.zip" rel="nofollow"><code>skimlit_tribrid_model</code></a></td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning#-09-milestone-project-2-skimlit--exercises">Go to exercises &amp; extra-curriculum</a></td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/slides/09_milestone_project_2_skimlit.pdf">Go to slides</a></td>
</tr>
<tr>
<td>10</td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/10_time_series_forecasting_in_tensorflow.ipynb">TensorFlow Time Series Fundamentals &amp; Milestone Project 3: BitPredict </a></td>
<td><a href="https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv" rel="nofollow"><code>bitcoin_price_data_USD_2013-10-01_2021-05-18.csv</code></a></td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning#-10-time-series-fundamentals-and-milestone-project-3-bitpredict--exercises">Go to exercises &amp; extra-curriculum</a></td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/slides/10_time_series_fundamentals_and_milestone_project_3_bitpredict.pdf">Go to slides</a></td>
</tr>
<tr>
<td>11</td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/11_passing_the_tensorflow_developer_certification_exam.md">Preparing to Pass the TensorFlow Developer Certification Exam (archive)</a></td>
<td></td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning#-11-passing-the-tensorflow-developer-certification-exercises">Go to exercises &amp; extra-curriculum</a></td>
<td><a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/slides/11_passing_the_tensorflow_developer_certification_exam.pdf">Go to slides</a></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto">Course structure</h2><a id="user-content-course-structure" class="anchor" aria-label="Permalink: Course structure" href="https://github.com/mrdbourke/tensorflow-deep-learning#course-structure"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">This course is code first. The goal is to get you writing deep learning code as soon as possible.</p>
<p dir="auto">It is taught with the following mantra:</p>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto"><pre class="notranslate"><code>Code -&gt; Concept -&gt; Code -&gt; Concept -&gt; Code -&gt; Concept
</code></pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="Code -&gt; Concept -&gt; Code -&gt; Concept -&gt; Code -&gt; Concept" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<p dir="auto">This means we write code first then step through the concepts behind it.</p>
<p dir="auto">If you've got 6-months experience writing Python code and a willingness to learn (most important), you'll be able to do the course.</p>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto">Should you do this course?</h2><a id="user-content-should-you-do-this-course" class="anchor" aria-label="Permalink: Should you do this course?" href="https://github.com/mrdbourke/tensorflow-deep-learning#should-you-do-this-course"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<blockquote>
<p dir="auto">Do you have 1+ years experience with deep learning and writing TensorFlow code?</p>
</blockquote>
<p dir="auto">If yes, no you shouldn't, use your skills to build something.</p>
<p dir="auto">If no, move onto the next question.</p>
<blockquote>
<p dir="auto">Have you done at least one beginner machine learning course and would like to learn about deep learning/how to build neural networks with TensorFlow?</p>
</blockquote>
<p dir="auto">If yes, this course is for you.</p>
<p dir="auto">If no, go and do a beginner machine learning course and if you decide you want to learn TensorFlow, this page will still be here.</p>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto">Prerequisites</h2><a id="user-content-prerequisites" class="anchor" aria-label="Permalink: Prerequisites" href="https://github.com/mrdbourke/tensorflow-deep-learning#prerequisites"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<blockquote>
<p dir="auto">What do I need to know to go through this course?</p>
</blockquote>
<ul dir="auto">
<li><strong>6+ months writing Python code.</strong> Can you write a Python function which accepts and uses parameters? Thats good enough. If you dont know what that means, spend another month or two writing Python code and then come back here.</li>
<li><strong>At least one beginner machine learning course.</strong> Are you familiar with the idea of training, validation and test sets? Do you know what supervised learning is? Have you used pandas, NumPy or Matplotlib before? If no to any of these, Id going through at least one machine learning course which teaches these first and then coming back.</li>
<li><strong>Comfortable using Google Colab/Jupyter Notebooks.</strong> This course uses Google Colab throughout. If you have never used Google Colab before, it works very similar to Jupyter Notebooks with a few extra features. If youre not familiar with Google Colab notebooks, Id suggest going through the Introduction to Google Colab notebook.</li>
<li><strong>Plug:</strong> The <a href="https://dbourke.link/ZTMMLcourse" rel="nofollow">Zero to Mastery beginner-friendly machine learning course</a> (I also teach this) teaches all of the above (and this course is designed as a follow on).</li>
</ul>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto"> Exercises &amp;  Extra-curriculum</h2><a id="user-content--exercises---extra-curriculum" class="anchor" aria-label="Permalink:  Exercises &amp;  Extra-curriculum" href="https://github.com/mrdbourke/tensorflow-deep-learning#-exercises---extra-curriculum"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">To prevent the course from being 100+ hours (deep learning is a broad field), various external resources for different sections are recommended to puruse under your own discretion.</p>
<p dir="auto">You can find solutions to the exercises in <a href="https://github.com/mrdbourke/tensorflow-deep-learning/tree/main/extras/solutions"><code>extras/solutions/</code></a>, there's a notebook per set of exercises (one for 00, 01, 02... etc). Thank you to <a href="https://github.com/ashikshafi08">Ashik Shafi</a> for all of the efforts creating these.</p>
<hr>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"> 00. TensorFlow Fundamentals Exercises</h3><a id="user-content--00-tensorflow-fundamentals-exercises" class="anchor" aria-label="Permalink:  00. TensorFlow Fundamentals Exercises" href="https://github.com/mrdbourke/tensorflow-deep-learning#-00-tensorflow-fundamentals-exercises"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li>Create a vector, scalar, matrix and tensor with values of your choosing using <code>tf.constant()</code>.</li>
<li>Find the shape, rank and size of the tensors you created in 1.</li>
<li>Create two tensors containing random values between 0 and 1 with shape <code>[5, 300]</code>.</li>
<li>Multiply the two tensors you created in 3 using matrix multiplication.</li>
<li>Multiply the two tensors you created in 3 using dot product.</li>
<li>Create a tensor with random values between 0 and 1 with shape <code>[224, 224, 3]</code>.</li>
<li>Find the min and max values of the tensor you created in 6 along the first axis.</li>
<li>Created a tensor with random values of shape <code>[1, 224, 224, 3]</code> then squeeze it to change the shape to <code>[224, 224, 3]</code>.</li>
<li>Create a tensor with shape <code>[10]</code> using your own choice of values, then find the index which has the maximum value.</li>
<li>One-hot encode the tensor you created in 9.</li>
</ol>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"> 00. TensorFlow Fundamentals Extra-curriculum</h3><a id="user-content--00-tensorflow-fundamentals-extra-curriculum" class="anchor" aria-label="Permalink:  00. TensorFlow Fundamentals Extra-curriculum" href="https://github.com/mrdbourke/tensorflow-deep-learning#-00-tensorflow-fundamentals-extra-curriculum"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>Read through the <a href="https://www.tensorflow.org/api_docs/python/" rel="nofollow">list of TensorFlow Python APIs</a>, pick one we haven't gone through in this notebook, reverse engineer it (write out the documentation code for yourself) and figure out what it does.</li>
<li>Try to create a series of tensor functions to calculate your most recent grocery bill (it's okay if you don't use the names of the items, just the price in numerical form).
<ul dir="auto">
<li>How would you calculate your grocery bill for the month and for the year using tensors?</li>
</ul>
</li>
<li>Go through the <a href="https://www.tensorflow.org/tutorials/quickstart/beginner" rel="nofollow">TensorFlow 2.x quick start for beginners</a> tutorial (be sure to type out all of the code yourself, even if you don't understand it).
<ul dir="auto">
<li>Are there any functions we used in here that match what's used in there? Which are the same? Which haven't you seen before?</li>
</ul>
</li>
<li>Watch the video <a href="https://www.youtube.com/watch?v=f5liqUk0ZTw" rel="nofollow">"What's a tensor?"</a> - a great visual introduction to many of the concepts we've covered in this notebook.</li>
</ul>
<hr>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"> 01. Neural network regression with TensorFlow Exercises</h3><a id="user-content--01-neural-network-regression-with-tensorflow-exercises" class="anchor" aria-label="Permalink:  01. Neural network regression with TensorFlow Exercises" href="https://github.com/mrdbourke/tensorflow-deep-learning#-01-neural-network-regression-with-tensorflow-exercises"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li>Create your own regression dataset (or make the one we created in "Create data to view and fit" bigger) and build fit a model to it.</li>
<li>Try building a neural network with 4 Dense layers and fitting it to your own regression dataset, how does it perform?</li>
<li>Try and improve the results we got on the insurance dataset, some things you might want to try include:</li>
</ol>
<ul dir="auto">
<li>Building a larger model (how does one with 4 dense layers go?).</li>
<li>Increasing the number of units in each layer.</li>
<li>Lookup the documentation of <a href="https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam" rel="nofollow">Adam</a> and find out what the first parameter is, what happens if you increase it by 10x?</li>
<li>What happens if you train for longer (say 300 epochs instead of 200)?</li>
</ul>
<ol start="4" dir="auto">
<li>Import the <a href="https://www.tensorflow.org/api_docs/python/tf/keras/datasets/boston_housing/load_data" rel="nofollow">Boston pricing dataset</a> from TensorFlow <a href="https://www.tensorflow.org/api_docs/python/tf/keras/datasets" rel="nofollow"><code>tf.keras.datasets</code></a> and model it.</li>
</ol>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"> 01. Neural network regression with TensorFlow Extra-curriculum</h3><a id="user-content--01-neural-network-regression-with-tensorflow-extra-curriculum" class="anchor" aria-label="Permalink:  01. Neural network regression with TensorFlow Extra-curriculum" href="https://github.com/mrdbourke/tensorflow-deep-learning#-01-neural-network-regression-with-tensorflow-extra-curriculum"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li><a href="https://www.youtube.com/watch?v=7sB052Pz0sQ&amp;ab_channel=AlexanderAmini" rel="nofollow">MIT introduction deep learning lecture 1</a> - gives a great overview of what's happening behind all of the code we're running.</li>
<li>Reading: 1-hour of <a href="http://neuralnetworksanddeeplearning.com/chap1.html" rel="nofollow">Chapter 1 of Neural Networks and Deep Learning</a> by Michael Nielson - a great in-depth and hands-on example of the intuition behind neural networks.</li>
<li>To practice your regression modelling with TensorFlow, I'd also encourage you to look through <a href="https://www.kaggle.com/data" rel="nofollow">Kaggle's datasets</a>, find a regression dataset which sparks your interest and try to model.</li>
</ul>
<hr>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"> 02. Neural network classification with TensorFlow Exercises</h3><a id="user-content--02-neural-network-classification-with-tensorflow-exercises" class="anchor" aria-label="Permalink:  02. Neural network classification with TensorFlow Exercises" href="https://github.com/mrdbourke/tensorflow-deep-learning#-02-neural-network-classification-with-tensorflow-exercises"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li>Play with neural networks in the <a href="https://playground.tensorflow.org/" rel="nofollow">TensorFlow Playground</a> for 10-minutes. Especially try different values of the learning, what happens when you decrease it? What happens when you increase it?</li>
<li>Replicate the model pictured in the <a href="https://playground.tensorflow.org/#activation=relu&amp;batchSize=10&amp;dataset=circle&amp;regDataset=reg-plane&amp;learningRate=0.001&amp;regularizationRate=0&amp;noise=0&amp;networkShape=6,6,6,6,6&amp;seed=0.51287&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;regularization_hide=true&amp;discretize_hide=true&amp;regularizationRate_hide=true&amp;percTrainData_hide=true&amp;dataset_hide=true&amp;problem_hide=true&amp;noise_hide=true&amp;batchSize_hide=true" rel="nofollow">TensorFlow Playground diagram</a> below using TensorFlow code. Compile it using the Adam optimizer, binary crossentropy loss and accuracy metric. Once it's compiled check a summary of the model.
<a target="_blank" rel="noopener noreferrer nofollow" href="./github-tensorflow-deep-learning_files/02-tensorflow-playground-replication-exercise.png"><img src="./github-tensorflow-deep-learning_files/02-tensorflow-playground-replication-exercise.png" alt="tensorflow playground example neural network" style="max-width: 100%;"></a>
<em>Try this network out for yourself on the <a href="https://playground.tensorflow.org/#activation=relu&amp;batchSize=10&amp;dataset=circle&amp;regDataset=reg-plane&amp;learningRate=0.001&amp;regularizationRate=0&amp;noise=0&amp;networkShape=6,6,6,6,6&amp;seed=0.51287&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false&amp;regularization_hide=true&amp;discretize_hide=true&amp;regularizationRate_hide=true&amp;percTrainData_hide=true&amp;dataset_hide=true&amp;problem_hide=true&amp;noise_hide=true&amp;batchSize_hide=true" rel="nofollow">TensorFlow Playground website</a>. Hint: there are 5 hidden layers but the output layer isn't pictured, you'll have to decide what the output layer should be based on the input data.</em></li>
<li>Create a classification dataset using Scikit-Learn's <a href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html" rel="nofollow"><code>make_moons()</code></a> function, visualize it and then build a model to fit it at over 85% accuracy.</li>
<li>Train a model to get 88%+ accuracy on the fashion MNIST test set. Plot a confusion matrix to see the results after.</li>
<li>Recreate <a href="https://www.tensorflow.org/api_docs/python/tf/keras/activations/softmax" rel="nofollow">TensorFlow's</a> <a href="https://en.wikipedia.org/wiki/Softmax_function" rel="nofollow">softmax activation function</a> in your own code. Make sure it can accept a tensor and return that tensor after having the softmax function applied to it.</li>
<li>Create a function (or write code) to visualize multiple image predictions for the fashion MNIST at the same time. Plot at least three different images and their prediction labels at the same time. Hint: see the <a href="https://www.tensorflow.org/tutorials/keras/classification" rel="nofollow">classification tutorial in the TensorFlow documentation</a> for ideas.</li>
<li>Make a function to show an image of a certain class of the fashion MNIST dataset and make a prediction on it. For example, plot 3 images of the <code>T-shirt</code> class with their predictions.</li>
</ol>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"> 02. Neural network classification with TensorFlow Extra-curriculum</h3><a id="user-content--02-neural-network-classification-with-tensorflow-extra-curriculum" class="anchor" aria-label="Permalink:  02. Neural network classification with TensorFlow Extra-curriculum" href="https://github.com/mrdbourke/tensorflow-deep-learning#-02-neural-network-classification-with-tensorflow-extra-curriculum"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>Watch 3Blue1Brown's neural networks video 2: <a href="https://www.youtube.com/watch?v=IHZwWFHWa-w" rel="nofollow"><em>Gradient descent, how neural networks learn</em></a>. After you're done, write 100 words about what you've learned.
<ul dir="auto">
<li>If you haven't already, watch video 1: <a href="https://www.youtube.com/watch?v=aircAruvnKk" rel="nofollow"><em>But what is a Neural Network?</em></a>. Note the activation function they talk about at the end.</li>
</ul>
</li>
<li>Watch <a href="https://youtu.be/njKP3FqW3Sk" rel="nofollow">MIT's introduction to deep learning lecture 1</a> (if you haven't already) to get an idea of the concepts behind using linear and non-linear functions.</li>
<li>Spend 1-hour reading <a href="http://neuralnetworksanddeeplearning.com/index.html" rel="nofollow">Michael Nielsen's Neural Networks and Deep Learning book</a>.</li>
<li>Read the <a href="https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html" rel="nofollow">ML-Glossary documentation on activation functions</a>. Which one is your favourite?
<ul dir="auto">
<li>After you've read the ML-Glossary, see which activation functions are available in TensorFlow by searching "tensorflow activation functions".</li>
</ul>
</li>
</ul>
<hr>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"> 03. Computer vision &amp; convolutional neural networks in TensorFlow Exercises</h3><a id="user-content--03-computer-vision--convolutional-neural-networks-in-tensorflow-exercises" class="anchor" aria-label="Permalink:  03. Computer vision &amp; convolutional neural networks in TensorFlow Exercises" href="https://github.com/mrdbourke/tensorflow-deep-learning#-03-computer-vision--convolutional-neural-networks-in-tensorflow-exercises"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li>Spend 20-minutes reading and interacting with the <a href="https://poloclub.github.io/cnn-explainer/" rel="nofollow">CNN explainer website</a>.</li>
</ol>
<ul dir="auto">
<li>What are the key terms? e.g. explain convolution in your own words, pooling in your own words</li>
</ul>
<ol start="2" dir="auto">
<li>Play around with the "understanding hyperparameters" section in the <a href="https://poloclub.github.io/cnn-explainer/" rel="nofollow">CNN explainer</a> website for 10-minutes.</li>
</ol>
<ul dir="auto">
<li>What is the kernel size?</li>
<li>What is the stride?</li>
<li>How could you adjust each of these in TensorFlow code?</li>
</ul>
<ol start="3" dir="auto">
<li>Take 10 photos of two different things and build your own CNN image classifier using the techniques we've built here.</li>
<li>Find an ideal learning rate for a simple convolutional neural network model on your the 10 class dataset.</li>
</ol>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"> 03. Computer vision &amp; convolutional neural networks in TensorFlow Extra-curriculum</h3><a id="user-content--03-computer-vision--convolutional-neural-networks-in-tensorflow-extra-curriculum" class="anchor" aria-label="Permalink:  03. Computer vision &amp; convolutional neural networks in TensorFlow Extra-curriculum" href="https://github.com/mrdbourke/tensorflow-deep-learning#-03-computer-vision--convolutional-neural-networks-in-tensorflow-extra-curriculum"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li><strong>Watch:</strong> <a href="https://www.youtube.com/watch?v=uapdILWYTzE&amp;list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&amp;index=3&amp;ab_channel=AlexanderAmini" rel="nofollow">MIT's Introduction to Deep Computer Vision</a> lecture. This will give you a great intuition behind convolutional neural networks.</li>
<li><strong>Watch:</strong> Deep dive on <a href="https://youtu.be/-_4Zi8fCZO4" rel="nofollow">mini-batch gradient descent</a> by deeplearning.ai. If you're still curious about why we use <strong>batches</strong> to train models, this technical overview covers many of the reasons why.</li>
<li><strong>Read:</strong> <a href="https://cs231n.github.io/convolutional-networks/" rel="nofollow">CS231n Convolutional Neural Networks for Visual Recognition</a> class notes. This will give a very deep understanding of what's going on behind the scenes of the convolutional neural network architectures we're writing.</li>
<li><strong>Read:</strong> <a href="https://arxiv.org/pdf/1603.07285.pdf" rel="nofollow">"A guide to convolution arithmetic for deep learning"</a>. This paper goes through all of the mathematics running behind the scenes of our convolutional layers.</li>
<li><strong>Code practice:</strong> <a href="https://www.tensorflow.org/tutorials/images/data_augmentation" rel="nofollow">TensorFlow Data Augmentation Tutorial</a>. For a more in-depth introduction on data augmentation with TensorFlow, spend an hour or two reading through this tutorial.</li>
</ul>
<hr>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"> 04. Transfer Learning in TensorFlow Part 1: Feature Extraction Exercises</h3><a id="user-content--04-transfer-learning-in-tensorflow-part-1-feature-extraction-exercises" class="anchor" aria-label="Permalink:  04. Transfer Learning in TensorFlow Part 1: Feature Extraction Exercises" href="https://github.com/mrdbourke/tensorflow-deep-learning#-04-transfer-learning-in-tensorflow-part-1-feature-extraction-exercises"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li>Build and fit a model using the same data we have here but with the MobileNetV2 architecture feature extraction (<a href="https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4" rel="nofollow"><code>mobilenet_v2_100_224/feature_vector</code></a>) from TensorFlow Hub, how does it perform compared to our other models?</li>
<li>Name 3 different image classification models on TensorFlow Hub that we haven't used.</li>
<li>Build a model to classify images of two different things you've taken photos of.</li>
</ol>
<ul dir="auto">
<li>You can use any feature extraction layer from TensorFlow Hub you like for this.</li>
<li>You should aim to have at least 10 images of each class, for example to build a fridge versus oven classifier, you'll want 10 images of fridges and 10 images of ovens.</li>
</ul>
<ol start="4" dir="auto">
<li>What is the current best performing model on ImageNet?</li>
</ol>
<ul dir="auto">
<li>Hint: you might want to check <a href="https://www.sotabench.com/" rel="nofollow">sotabench.com</a> for this.</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"> 04. Transfer Learning in TensorFlow Part 1: Feature Extraction Extra-curriculum</h3><a id="user-content--04-transfer-learning-in-tensorflow-part-1-feature-extraction-extra-curriculum" class="anchor" aria-label="Permalink:  04. Transfer Learning in TensorFlow Part 1: Feature Extraction Extra-curriculum" href="https://github.com/mrdbourke/tensorflow-deep-learning#-04-transfer-learning-in-tensorflow-part-1-feature-extraction-extra-curriculum"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>Read through the <a href="https://www.tensorflow.org/tutorials/images/transfer_learning" rel="nofollow">TensorFlow Transfer Learning Guide</a> and define the main two types of transfer learning in your own words.</li>
<li>Go through the <a href="https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub" rel="nofollow">Transfer Learning with TensorFlow Hub tutorial</a> on the TensorFlow website and rewrite all of the code yourself into a new Google Colab notebook making comments about what each step does along the way.</li>
<li>We haven't covered fine-tuning with TensorFlow Hub in this notebook, but if you'd like to know more, go through the <a href="https://www.tensorflow.org/hub/tf2_saved_model#fine-tuning" rel="nofollow">fine-tuning a TensorFlow Hub model tutorial</a> on the TensorFlow homepage.How to fine-tune a tensorflow hub model:</li>
<li>Look into <a href="https://www.wandb.com/experiment-tracking" rel="nofollow">experiment tracking with Weights &amp; Biases</a>, how could you integrate it with our existing TensorBoard logs?</li>
</ul>
<hr>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"> 05. Transfer Learning in TensorFlow Part 2: Fine-tuning Exercises</h3><a id="user-content--05-transfer-learning-in-tensorflow-part-2-fine-tuning-exercises" class="anchor" aria-label="Permalink:  05. Transfer Learning in TensorFlow Part 2: Fine-tuning Exercises" href="https://github.com/mrdbourke/tensorflow-deep-learning#-05-transfer-learning-in-tensorflow-part-2-fine-tuning-exercises"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li>Use feature-extraction to train a transfer learning model on 10% of the Food Vision data for 10 epochs using <a href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB0" rel="nofollow"><code>tf.keras.applications.EfficientNetB0</code></a> as the base model. Use the <a href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint" rel="nofollow"><code>ModelCheckpoint</code></a> callback to save the weights to file.</li>
<li>Fine-tune the last 20 layers of the base model you trained in 2 for another 10 epochs. How did it go?</li>
<li>Fine-tune the last 30 layers of the base model you trained in 2 for another 10 epochs. How did it go?</li>
<li>Write a function to visualize an image from any dataset (train or test file) and any class (e.g. "steak", "pizza"... etc), visualize it and make a prediction on it using a trained model.</li>
</ol>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"> 05. Transfer Learning in TensorFlow Part 2: Fine-tuning Extra-curriculum</h3><a id="user-content--05-transfer-learning-in-tensorflow-part-2-fine-tuning-extra-curriculum" class="anchor" aria-label="Permalink:  05. Transfer Learning in TensorFlow Part 2: Fine-tuning Extra-curriculum" href="https://github.com/mrdbourke/tensorflow-deep-learning#-05-transfer-learning-in-tensorflow-part-2-fine-tuning-extra-curriculum"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>Read the <a href="https://www.tensorflow.org/tutorials/images/data_augmentation" rel="nofollow">documentation on data augmentation</a> in TensorFlow.</li>
<li>Read the <a href="https://arxiv.org/abs/1801.06146" rel="nofollow">ULMFit paper</a> (technical) for an introduction to the concept of freezing and unfreezing different layers.</li>
<li>Read up on learning rate scheduling (there's a <a href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LearningRateScheduler" rel="nofollow">TensorFlow callback</a> for this), how could this influence our model training?
<ul dir="auto">
<li>If you're training for longer, you probably want to reduce the learning rate as you go... the closer you get to the bottom of the hill, the smaller steps you want to take. Imagine it like finding a coin at the bottom of your couch. In the beginning your arm movements are going to be large and the closer you get, the smaller your movements become.</li>
</ul>
</li>
</ul>
<hr>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"> 06. Transfer Learning in TensorFlow Part 3: Scaling-up Exercises</h3><a id="user-content--06-transfer-learning-in-tensorflow-part-3-scaling-up-exercises" class="anchor" aria-label="Permalink:  06. Transfer Learning in TensorFlow Part 3: Scaling-up Exercises" href="https://github.com/mrdbourke/tensorflow-deep-learning#-06-transfer-learning-in-tensorflow-part-3-scaling-up-exercises"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li>Take 3 of your own photos of food and use the trained model to make predictions on them, share your predictions with the other students in Discord and show off your Food Vision model .</li>
<li>Train a feature-extraction transfer learning model for 10 epochs on the same data and compare its performance versus a model which used feature extraction for 5 epochs and fine-tuning for 5 epochs (like we've used in this notebook). Which method is better?</li>
<li>Recreate the first model (the feature extraction model) with <a href="https://www.tensorflow.org/guide/mixed_precision" rel="nofollow"><code>mixed_precision</code></a> turned on.</li>
</ol>
<ul dir="auto">
<li>Does it make the model train faster?</li>
<li>Does it effect the accuracy or performance of our model?</li>
<li>What's the advantages of using <code>mixed_precision</code> training?</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"> 06. Transfer Learning in TensorFlow Part 3: Scaling-up Extra-curriculum</h3><a id="user-content--06-transfer-learning-in-tensorflow-part-3-scaling-up-extra-curriculum" class="anchor" aria-label="Permalink:  06. Transfer Learning in TensorFlow Part 3: Scaling-up Extra-curriculum" href="https://github.com/mrdbourke/tensorflow-deep-learning#-06-transfer-learning-in-tensorflow-part-3-scaling-up-extra-curriculum"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>Spend 15-minutes reading up on the <a href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping" rel="nofollow">EarlyStopping callback</a>. What does it do? How could we use it in our model training?</li>
<li>Spend an hour reading about <a href="https://www.streamlit.io/" rel="nofollow">Streamlit</a>. What does it do? How might you integrate some of the things we've done in this notebook in a Streamlit app?</li>
</ul>
<hr>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"> 07. Milestone Project 1:  Food Vision Big Exercises</h3><a id="user-content--07-milestone-project-1--food-vision-big-exercises" class="anchor" aria-label="Permalink:  07. Milestone Project 1:  Food Vision Big Exercises" href="https://github.com/mrdbourke/tensorflow-deep-learning#-07-milestone-project-1--food-vision-big-exercises"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><strong>Note:</strong> The chief exercise for Milestone Project 1 is to finish the "TODO" sections in the <a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/TEMPLATE_07_food_vision_milestone_project_1.ipynb">Milestone Project 1 Template notebook</a>. After doing so, move onto the following.</p>
<ol dir="auto">
<li>Use the same evaluation techniques on the large-scale Food Vision model as you did in the previous notebook (<a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/06_transfer_learning_in_tensorflow_part_3_scaling_up.ipynb">Transfer Learning Part 3: Scaling up</a>). More specifically, it would be good to see:</li>
</ol>
<ul dir="auto">
<li>A confusion matrix between all of the model's predictions and true labels.</li>
<li>A graph showing the f1-scores of each class.</li>
<li>A visualization of the model making predictions on various images and comparing the predictions to the ground truth.
<ul dir="auto">
<li>For example, plot a sample image from the test dataset and have the title of the plot show the prediction, the prediction probability and the ground truth label.</li>
</ul>
</li>
<li><strong>Note:</strong> To compare predicted labels to test labels, it might be a good idea when loading the test data to set <code>shuffle=False</code> (so the ordering of test data is preserved alongside the order of predicted labels).</li>
</ul>
<ol start="2" dir="auto">
<li>Take 3 of your own photos of food and use the Food Vision model to make predictions on them. How does it go? Share your images/predictions with the other students.</li>
<li>Retrain the model (feature extraction and fine-tuning) we trained in this notebook, except this time use <a href="https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetB4" rel="nofollow"><code>EfficientNetB4</code></a> as the base model instead of <code>EfficientNetB0</code>. Do you notice an improvement in performance? Does it take longer to train? Are there any tradeoffs to consider?</li>
<li>Name one important benefit of mixed precision training, how does this benefit take place?</li>
</ol>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"> 07. Milestone Project 1:  Food Vision Big Extra-curriculum</h3><a id="user-content--07-milestone-project-1--food-vision-big-extra-curriculum" class="anchor" aria-label="Permalink:  07. Milestone Project 1:  Food Vision Big Extra-curriculum" href="https://github.com/mrdbourke/tensorflow-deep-learning#-07-milestone-project-1--food-vision-big-extra-curriculum"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>Read up on learning rate scheduling and the <a href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/LearningRateScheduler" rel="nofollow">learning rate scheduler callback</a>. What is it? And how might it be helpful to this project?</li>
<li>Read up on TensorFlow data loaders (<a href="https://www.tensorflow.org/guide/data_performance" rel="nofollow">improving TensorFlow data loading performance</a>). Is there anything we've missed? What methods you keep in mind whenever loading data in TensorFlow? Hint: check the summary at the bottom of the page for a great round up of ideas.</li>
<li>Read up on the documentation for <a href="https://www.tensorflow.org/guide/mixed_precision" rel="nofollow">TensorFlow mixed precision training</a>. What are the important things to keep in mind when using mixed precision training?</li>
</ul>
<hr>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"> 08. Introduction to NLP (Natural Language Processing) in TensorFlow Exercises</h3><a id="user-content--08-introduction-to-nlp-natural-language-processing-in-tensorflow-exercises" class="anchor" aria-label="Permalink:  08. Introduction to NLP (Natural Language Processing) in TensorFlow Exercises" href="https://github.com/mrdbourke/tensorflow-deep-learning#-08-introduction-to-nlp-natural-language-processing-in-tensorflow-exercises"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li>Rebuild, compile and train <code>model_1</code>, <code>model_2</code> and <code>model_5</code> using the <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Sequential" rel="nofollow">Keras Sequential API</a> instead of the Functional API.</li>
<li>Retrain the baseline model with 10% of the training data. How does perform compared to the Universal Sentence Encoder model with 10% of the training data?</li>
<li>Try fine-tuning the TF Hub Universal Sentence Encoder model by setting <code>training=True</code> when instantiating it as a Keras layer.</li>
</ol>
<div class="snippet-clipboard-content notranslate position-relative overflow-auto"><pre class="notranslate"><code># We can use this encoding layer in place of our text_vectorizer and embedding layer
sentence_encoder_layer = hub.KerasLayer("https://tfhub.dev/google/universal-sentence-encoder/4",
                                        input_shape=[],
                                        dtype=tf.string,
                                        trainable=True) # turn training on to fine-tune the TensorFlow Hub model
</code></pre><div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w" value="# We can use this encoding layer in place of our text_vectorizer and embedding layer
sentence_encoder_layer = hub.KerasLayer(&quot;https://tfhub.dev/google/universal-sentence-encoder/4&quot;,
                                        input_shape=[],
                                        dtype=tf.string,
                                        trainable=True) # turn training on to fine-tune the TensorFlow Hub model" tabindex="0" role="button">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div></div>
<ol start="4" dir="auto">
<li>Retrain the best model you've got so far on the whole training set (no validation split). Then use this trained model to make predictions on the test dataset and format the predictions into the same format as the <code>sample_submission.csv</code> file from Kaggle (see the Files tab in Colab for what the <code>sample_submission.csv</code> file looks like). Once you've done this, <a href="https://www.kaggle.com/c/nlp-getting-started/data" rel="nofollow">make a submission to the Kaggle competition</a>, how did your model perform?</li>
<li>Combine the ensemble predictions using the majority vote (mode), how does this perform compare to averaging the prediction probabilities of each model?</li>
<li>Make a confusion matrix with the best performing model's predictions on the validation set and the validation ground truth labels.</li>
</ol>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"> 08. Introduction to NLP (Natural Language Processing) in TensorFlow Extra-curriculum</h3><a id="user-content--08-introduction-to-nlp-natural-language-processing-in-tensorflow-extra-curriculum" class="anchor" aria-label="Permalink:  08. Introduction to NLP (Natural Language Processing) in TensorFlow Extra-curriculum" href="https://github.com/mrdbourke/tensorflow-deep-learning#-08-introduction-to-nlp-natural-language-processing-in-tensorflow-extra-curriculum"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">To practice what you've learned, a good idea would be to spend an hour on 3 of the following (3-hours total, you could through them all if you want) and then write a blog post about what you've learned.</p>
<ul dir="auto">
<li>For an overview of the different problems within NLP and how to solve them read through:
<ul dir="auto">
<li><a href="https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32" rel="nofollow">A Simple Introduction to Natural Language Processing</a></li>
<li><a href="https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e" rel="nofollow">How to solve 90% of NLP problems: a step-by-step guide</a></li>
</ul>
</li>
<li>Go through <a href="https://youtu.be/SEnXr6v2ifU" rel="nofollow">MIT's Recurrent Neural Networks lecture</a>. This will be one of the greatest additions to what's happening behind the RNN model's you've been building.</li>
<li>Read through the <a href="https://www.tensorflow.org/tutorials/text/word_embeddings" rel="nofollow">word embeddings page on the TensorFlow website</a>. Embeddings are such a large part of NLP. We've covered them throughout this notebook but extra practice would be well worth it. A good exercise would be to write out all the code in the guide in a new notebook.</li>
<li>For more on RNN's in TensorFlow, read and reproduce <a href="https://www.tensorflow.org/guide/keras/rnn" rel="nofollow">the TensorFlow RNN guide</a>. We've covered many of the concepts in this guide, but it's worth writing the code again for yourself.</li>
<li>Text data doesn't always come in a nice package like the data we've downloaded. So if you're after more on preparing different text sources for being with your TensorFlow deep learning models, it's worth checking out the following:
<ul dir="auto">
<li><a href="https://www.tensorflow.org/tutorials/load_data/text" rel="nofollow">TensorFlow text loading tutorial</a>.</li>
<li><a href="https://realpython.com/read-write-files-python/" rel="nofollow">Reading text files with Python</a> by Real Python.</li>
</ul>
</li>
<li>This notebook has focused on writing NLP code. For a mathematically rich overview of how NLP with Deep Learning happens, read <a href="https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes01-wordvecs1.pdf" rel="nofollow">Stanford's Natural Language Processing with Deep Learning lecture notes Part 1</a>.
<ul dir="auto">
<li>For an even deeper dive, you could even do the whole <a href="http://web.stanford.edu/class/cs224n/" rel="nofollow">CS224n</a> (Natural Language Processing with Deep Learning) course.</li>
</ul>
</li>
<li>Great blog posts to read:
<ul dir="auto">
<li>Andrei Karpathy's <a href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/" rel="nofollow">The Unreasonable Effectiveness of RNNs</a> dives into generating Shakespeare text with RNNs.</li>
<li><a href="https://towardsdatascience.com/text-classification-with-nlp-tf-idf-vs-word2vec-vs-bert-41ff868d1794" rel="nofollow">Text Classification with NLP: Tf-Idf vs Word2Vec vs BERT</a> by Mauro Di Pietro. An overview of different techniques for turning text into numbers and then classifying it.</li>
<li><a href="https://machinelearningmastery.com/what-are-word-embeddings/" rel="nofollow">What are word embeddings?</a> by Machine Learning Mastery.</li>
</ul>
</li>
<li>Other topics worth looking into:
<ul dir="auto">
<li><a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" rel="nofollow">Attention mechanisms</a>. These are a foundational component of the transformer architecture and also often add improvements to deep NLP models.</li>
<li><a href="http://jalammar.github.io/illustrated-transformer/" rel="nofollow">Transformer architectures</a>. This model architecture has recently taken the NLP world by storm, achieving state of the art on many benchmarks. However, it does take a little more processing to get off the ground, the <a href="https://huggingface.co/models/" rel="nofollow">HuggingFace Models (formerly HuggingFace Transformers) library</a> is probably your best quick start.</li>
</ul>
</li>
</ul>
<hr>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"> 09. Milestone Project 2: SkimLit  Exercises</h3><a id="user-content--09-milestone-project-2-skimlit--exercises" class="anchor" aria-label="Permalink:  09. Milestone Project 2: SkimLit  Exercises" href="https://github.com/mrdbourke/tensorflow-deep-learning#-09-milestone-project-2-skimlit--exercises"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li>Train <code>model_5</code> on all of the data in the training dataset for as many epochs until it stops improving. Since this might take a while, you might want to use:</li>
</ol>
<ul dir="auto">
<li><a href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint" rel="nofollow"><code>tf.keras.callbacks.ModelCheckpoint</code></a> to save the model's best weights only.</li>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping" rel="nofollow"><code>tf.keras.callbacks.EarlyStopping</code></a> to stop the model from training once the validation loss has stopped improving for ~3 epochs.</li>
</ul>
<ol start="2" dir="auto">
<li>Checkout the <a href="https://keras.io/examples/nlp/pretrained_word_embeddings/" rel="nofollow">Keras guide on using pretrained GloVe embeddings</a>. Can you get this working with one of our models?</li>
</ol>
<ul dir="auto">
<li>Hint: You'll want to incorporate it with a custom token <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding" rel="nofollow">Embedding</a> layer.</li>
<li>It's up to you whether or not you fine-tune the GloVe embeddings or leave them frozen.</li>
</ul>
<ol start="3" dir="auto">
<li>Try replacing the TensorFlow Hub Universal Sentence Encoder pretrained  embedding for the <a href="https://tfhub.dev/google/experts/bert/pubmed/2" rel="nofollow">TensorFlow Hub BERT PubMed expert</a> (a language model pretrained on PubMed texts) pretrained embedding. Does this effect results?</li>
</ol>
<ul dir="auto">
<li>Note: Using the BERT PubMed expert pretrained embedding requires an extra preprocessing step for sequences (as detailed in the <a href="https://tfhub.dev/google/experts/bert/pubmed/2" rel="nofollow">TensorFlow Hub guide</a>).</li>
<li>Does the BERT model beat the results mentioned in this paper? <a href="https://arxiv.org/pdf/1710.06071.pdf" rel="nofollow">https://arxiv.org/pdf/1710.06071.pdf</a></li>
</ul>
<ol start="4" dir="auto">
<li>What happens if you were to merge our <code>line_number</code> and <code>total_lines</code> features for each sequence? For example, created a <code>X_of_Y</code> feature instead? Does this effect model performance?</li>
</ol>
<ul dir="auto">
<li>Another example: <code>line_number=1</code> and <code>total_lines=11</code> turns into <code>line_of_X=1_of_11</code>.</li>
</ul>
<ol start="5" dir="auto">
<li>Write a function (or series of functions) to take a sample abstract string, preprocess it (in the same way our model has been trained), make a prediction on each sequence in the abstract and return the abstract in the format:</li>
</ol>
<ul dir="auto">
<li><code>PREDICTED_LABEL</code>: <code>SEQUENCE</code></li>
<li><code>PREDICTED_LABEL</code>: <code>SEQUENCE</code></li>
<li><code>PREDICTED_LABEL</code>: <code>SEQUENCE</code></li>
<li><code>PREDICTED_LABEL</code>: <code>SEQUENCE</code></li>
<li>...
<ul dir="auto">
<li>You can find your own unstructured RCT abstract from PubMed or try this one from: <a href="https://pubmed.ncbi.nlm.nih.gov/22244707/" rel="nofollow"><em>Baclofen promotes alcohol abstinence in alcohol dependent cirrhotic patients with hepatitis C virus (HCV) infection</em></a>.</li>
</ul>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"> 09. Milestone Project 2: SkimLit  Extra-curriculum</h3><a id="user-content--09-milestone-project-2-skimlit--extra-curriculum" class="anchor" aria-label="Permalink:  09. Milestone Project 2: SkimLit  Extra-curriculum" href="https://github.com/mrdbourke/tensorflow-deep-learning#-09-milestone-project-2-skimlit--extra-curriculum"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>For more on working with text/spaCy, see <a href="https://course.spacy.io/en/" rel="nofollow">spaCy's advanced NLP course</a>. If you're going to be working on production-level NLP problems, you'll probably end up using spaCy.</li>
<li>For another look at how to approach a text classification problem like the one we've just gone through, I'd suggest going through <a href="https://developers.google.com/machine-learning/guides/text-classification" rel="nofollow">Google's Machine Learning Course for text classification</a>.</li>
<li>Since our dataset has imbalanced classes (as with many real-world datasets), so it might be worth looking into the <a href="https://www.tensorflow.org/tutorials/structured_data/imbalanced_data" rel="nofollow">TensorFlow guide for different methods to training a model with imbalanced classes</a>.</li>
</ul>
<hr>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"> 10. Time series fundamentals and Milestone Project 3: BitPredict  Exercises</h3><a id="user-content--10-time-series-fundamentals-and-milestone-project-3-bitpredict--exercises" class="anchor" aria-label="Permalink:  10. Time series fundamentals and Milestone Project 3: BitPredict  Exercises" href="https://github.com/mrdbourke/tensorflow-deep-learning#-10-time-series-fundamentals-and-milestone-project-3-bitpredict--exercises"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li>Does scaling the data help for univariate/multivariate data? (e.g. getting all of the values between 0 &amp; 1)</li>
</ol>
<ul dir="auto">
<li>Try doing this for a univariate model (e.g. <code>model_1</code>) and a multivariate model (e.g. <code>model_6</code>) and see if it effects model training or evaluation results.</li>
</ul>
<ol start="2" dir="auto">
<li>Get the most up to date data on Bitcoin, train a model &amp; see how it goes (our data goes up to May 18 2021).</li>
</ol>
<ul dir="auto">
<li>You can download the Bitcoin historical data for free from <a href="https://www.coindesk.com/price/bitcoin" rel="nofollow">coindesk.com/price/bitcoin</a> and clicking "Export Data" -&gt; "CSV".</li>
</ul>
<ol start="3" dir="auto">
<li>For most of our models we used <code>WINDOW_SIZE=7</code>, but is there a better window size?</li>
</ol>
<ul dir="auto">
<li>Setup a series of experiments to find whether or not there's a better window size.</li>
<li>For example, you might train 10 different models with <code>HORIZON=1</code> but with window sizes ranging from 2-12.</li>
</ul>
<ol start="4" dir="auto">
<li>Create a windowed dataset just like the ones we used for <code>model_1</code> using <a href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/timeseries_dataset_from_array" rel="nofollow"><code>tf.keras.preprocessing.timeseries_dataset_from_array()</code></a> and retrain <code>model_1</code> using the recreated dataset.</li>
<li>For our multivariate modelling experiment, we added the Bitcoin block reward size as an extra feature to make our time series multivariate.</li>
</ol>
<ul dir="auto">
<li>Are there any other features you think you could add?</li>
<li>If so, try it out, how do these affect the model?</li>
</ul>
<ol start="6" dir="auto">
<li>Make prediction intervals for future forecasts. To do so, one way would be to train an ensemble model on all of the data, make future forecasts with it and calculate the prediction intervals of the ensemble just like we did for <code>model_8</code>.</li>
<li>For future predictions, try to make a prediction, retrain a model on the predictions, make a prediction, retrain a model, make a prediction, retrain a model, make a prediction (retrain a model each time a new prediction is made). Plot the results, how do they look compared to the future predictions where a model wasn't retrained for every forecast (<code>model_9</code>)?</li>
<li>Throughout this notebook, we've only tried algorithms we've handcrafted ourselves. But it's worth seeing how a purpose built forecasting algorithm goes.</li>
</ol>
<ul dir="auto">
<li>Try out one of the extra algorithms listed in the modelling experiments part such as:
<ul dir="auto">
<li><a href="https://github.com/facebookresearch/Kats">Facebook's Kats library</a> - there are many models in here, remember the machine learning practioner's motto: experiment, experiment, experiment.</li>
<li><a href="https://github.com/linkedin/greykite">LinkedIn's Greykite library</a></li>
</ul>
</li>
</ul>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"> 10. Time series fundamentals and Milestone Project 3: BitPredict  Extra-curriculum</h3><a id="user-content--10-time-series-fundamentals-and-milestone-project-3-bitpredict--extra-curriculum" class="anchor" aria-label="Permalink:  10. Time series fundamentals and Milestone Project 3: BitPredict  Extra-curriculum" href="https://github.com/mrdbourke/tensorflow-deep-learning#-10-time-series-fundamentals-and-milestone-project-3-bitpredict--extra-curriculum"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">We've only really scratched the surface with time series forecasting and time series modelling in general. But the good news is, you've got plenty of hands-on coding experience with it already.</p>
<p dir="auto">If you'd like to dig deeper in to the world of time series, I'd recommend the following:</p>
<ul dir="auto">
<li><a href="https://otexts.com/fpp3/" rel="nofollow">Forecasting: Principles and Practice</a> is an outstanding online textbook which discusses at length many of the most important concepts in time series forecasting. I'd especially recommend reading at least Chapter 1 in full.
<ul dir="auto">
<li>I'd definitely recommend at least checking out chapter 1 as well as the chapter on forecasting accuracy measures.</li>
</ul>
</li>
<li> <a href="https://youtu.be/wqQKFu41FIw" rel="nofollow">Introduction to machine learning and time series</a> by Markus Loning goes through different time series problems and how to approach them. It focuses on using the <code>sktime</code> library (Scikit-Learn for time series), though the principles are applicable elsewhere.</li>
<li><a href="https://towardsdatascience.com/why-you-should-care-about-the-nate-silver-vs-nassim-taleb-twitter-war-a581dce1f5fc" rel="nofollow"><em>Why you should care about the Nate Silver vs. Nassim Taleb Twitter war</em></a> by Isaac Faber is an outstanding discussion insight into the role of uncertainty in the example of election prediction.</li>
<li><a href="https://www.tensorflow.org/tutorials/structured_data/time_series" rel="nofollow">TensorFlow time series tutorial</a> - A tutorial on using TensorFlow to forecast weather time series data with TensorFlow.</li>
<li> <a href="https://en.wikipedia.org/wiki/The_Black_Swan:_The_Impact_of_the_Highly_Improbable" rel="nofollow"><em>The Black Swan</em></a> by Nassim Nicholas Taleb - Nassim Taleb was a pit trader (a trader who trades on their own behalf) for 25 years, this book compiles many of the lessons he learned from first-hand experience. It changed my whole perspective on our ability to predict.</li>
<li><a href="https://towardsdatascience.com/3-facts-about-time-series-forecasting-that-surprise-experienced-machine-learning-practitioners-69c18ee89387" rel="nofollow"><em>3 facts about time series forecasting that surprise experienced machine learning practitioners</em></a> by Skander Hannachi, Ph.D - time series data is different to other kinds of data, if you've worked on other kinds of machine learning problems before, getting into time series might require some adjustments, Hannachi outlines 3 of the most common.</li>
<li> World-class lectures by
Jordan Kern, watching these will take you from 0 to 1 with time series problems:
<ul dir="auto">
<li><a href="https://youtu.be/Prpu_U5tKkE" rel="nofollow">Time Series Analysis</a> - how to analyse time series data.</li>
<li><a href="https://www.youtube.com/watch?v=s3XH7fTHMb4" rel="nofollow">Time Series Modelling</a> - different techniques for modelling time series data (many of which aren't deep learning).</li>
</ul>
</li>
</ul>
<hr>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto">TensorFlow Developer Certificate (archive)</h2><a id="user-content-tensorflow-developer-certificate-archive" class="anchor" aria-label="Permalink: TensorFlow Developer Certificate (archive)" href="https://github.com/mrdbourke/tensorflow-deep-learning#tensorflow-developer-certificate-archive"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<blockquote>
<p dir="auto"><strong>Note:</strong> As of 1 May 2024, the TensorFlow Developer Certification is no longer available for purchase. After being in contact with the TensorFlow Certification team, they stated they were closing the program with no official next steps (see <a href="https://github.com/mrdbourke/tensorflow-deep-learning/discussions/645" data-hovercard-type="discussion" data-hovercard-url="/mrdbourke/tensorflow-deep-learning/discussions/645/hovercard">#645</a> for more).</p>
<p dir="auto">With this in mind, the exercises/extra-curriculum below are for archive purposes only. The rest of the course materials are still valid.</p>
</blockquote>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"> 11. Passing the TensorFlow Developer Certification Exercises (archive)</h3><a id="user-content--11-passing-the-tensorflow-developer-certification-exercises-archive" class="anchor" aria-label="Permalink:  11. Passing the TensorFlow Developer Certification Exercises (archive)" href="https://github.com/mrdbourke/tensorflow-deep-learning#-11-passing-the-tensorflow-developer-certification-exercises-archive"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><strong>Preparing your brain</strong></p>
<ol dir="auto">
<li>Read through the <a href="https://www.tensorflow.org/extras/cert/TF_Certificate_Candidate_Handbook.pdf" rel="nofollow">TensorFlow Developer Certificate Candidate Handbook</a>.</li>
<li>Go through the Skills checklist section of the TensorFlow Developer Certification Candidate Handbook and create a notebook which covers all of the skills required, write code for each of these (this notebook can be used as a point of reference during the exam).</li>
</ol>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="./github-tensorflow-deep-learning_files/11-map-the-skills-checklist-to-a-notebook.png"><img src="./github-tensorflow-deep-learning_files/11-map-the-skills-checklist-to-a-notebook.png" alt="mapping the TensorFlow Developer handbook to code in a notebook" style="max-width: 100%;"></a>
<em>Example of mapping the Skills checklist section of the TensorFlow Developer Certification Candidate handbook to a notebook.</em></p>
<p dir="auto"><strong>Prearing your computer</strong></p>
<ol dir="auto">
<li>Go through the <a href="https://www.jetbrains.com/pycharm/learning-center/" rel="nofollow">PyCharm quick start</a> tutorials to make sure you're familiar with PyCharm (the exam uses PyCharm, you can download the free version).</li>
<li>Read through and follow the suggested steps in the <a href="https://www.tensorflow.org/extras/cert/Setting_Up_TF_Developer_Certificate_Exam.pdf" rel="nofollow">setting up for the TensorFlow Developer Certificate Exam guide</a>.</li>
<li>After going through (2), go into PyCharm and make sure you can train a model in TensorFlow. The model and dataset in the example <code>image_classification_test.py</code> <a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/image_classification_test.py">script on GitHub</a> should be enough. If you can train and save the model in under 5-10 minutes, your computer will be powerful enough to train the models in the exam.
<ul dir="auto">
<li>Make sure you've got experience running models locally in PyCharm before taking the exam. Google Colab (what we used through the course) is a little different to PyCharm.</li>
</ul>
</li>
</ol>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="./github-tensorflow-deep-learning_files/11-getting-example-script-to-run-in-pycharm.png"><img src="./github-tensorflow-deep-learning_files/11-getting-example-script-to-run-in-pycharm.png" alt="before taking the TensorFlow Developer certification exam, make sure you can run TensorFlow code in PyCharm on your local machine" style="max-width: 100%;"></a>
<em>Before taking the exam make sure you can run TensorFlow code on your local machine in PyCharm. If the <a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/image_classification_test.py">example <code>image_class_test.py</code> script</a> can run completely in under 5-10 minutes on your local machine, your local machine can handle the exam (if not, you can use Google Colab to train, save and download models to submit for the exam).</em></p>
<div class="markdown-heading" dir="auto"><h3 tabindex="-1" class="heading-element" dir="auto"> 11. Passing the TensorFlow Developer Certification Extra-curriculum (archive)</h3><a id="user-content--11-passing-the-tensorflow-developer-certification-extra-curriculum-archive" class="anchor" aria-label="Permalink:  11. Passing the TensorFlow Developer Certification Extra-curriculum (archive)" href="https://github.com/mrdbourke/tensorflow-deep-learning#-11-passing-the-tensorflow-developer-certification-extra-curriculum-archive"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">If you'd like some extra materials to go through to further your skills with TensorFlow and deep learning in general or to prepare more for the exam, I'd highly recommend the following:</p>
<ul dir="auto">
<li> <strong>Read:</strong> <a href="https://www.mrdbourke.com/how-i-got-tensorflow-developer-certified/" rel="nofollow">How I got TensorFlow Developer Certified (and how you can too)</a></li>
<li> <strong>Watch:</strong> <a href="https://youtu.be/ya5NwvKafDk" rel="nofollow">How I passed the TensorFlow Developer Certification exam (and how you can too)</a></li>
<li>Go through the <a href="https://dbourke.link/tfinpractice" rel="nofollow">TensorFlow in Practice Specialization on Coursera</a></li>
<li>Read through the second half of <a href="https://amzn.to/3aYexF2" rel="nofollow">Hands-On Machine Learning with Scikit-Learn, Keras &amp; TensorFlow 2nd Edition</a></li>
</ul>
<hr>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto">What this course is missing</h2><a id="user-content-what-this-course-is-missing" class="anchor" aria-label="Permalink: What this course is missing" href="https://github.com/mrdbourke/tensorflow-deep-learning#what-this-course-is-missing"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Deep learning is a broad topic. So this course doesn't cover it all.</p>
<p dir="auto">Here are some of the main topics you might want to look into next:</p>
<ul dir="auto">
<li>Transformers (the neural network architecture taking the NLP world by storm)</li>
<li>Multi-modal models (models which use more than one data source such as text &amp; images)</li>
<li>Reinforcement learning</li>
<li>Unsupervised learning</li>
</ul>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto">Extensions (possible places to go after the course)</h2><a id="user-content-extensions-possible-places-to-go-after-the-course" class="anchor" aria-label="Permalink: Extensions (possible places to go after the course)" href="https://github.com/mrdbourke/tensorflow-deep-learning#extensions-possible-places-to-go-after-the-course"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li><a href="http://neuralnetworksanddeeplearning.com/" rel="nofollow">Neural Networks and Deep Learning Book</a> by Michael Nielsen - If the Zero to Mastery TensorFlow for Deep Learning course is top down, this book is bottom up. A fantastic resource to sandwich your knowledge.</li>
<li><a href="https://www.deeplearning.ai/" rel="nofollow">Deeplearning.AI specializations</a> - The ZTM TensorFLow course focuses on code-first, the deeplearning.ai specializations will teach you what's going on behind the code.</li>
<li><a href="https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/" rel="nofollow">Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow Book</a> (especially the 2nd half) - Many of the materials in this course were inspired by and guided by the pages of this beautiful text book.</li>
<li><a href="https://fullstackdeeplearning.com/" rel="nofollow">Full Stack Deep Learning</a> - Learn how to turn your models into machine learning-powered applications.</li>
<li><a href="https://madewithml.com/#mlops" rel="nofollow">Made with ML MLOps materials</a> - Similar to Full Stack Deep Learning but comprised into many small lessons around all the pieces of the puzzle (data collection, labelling, deployment and more) required to build a full-stack machine learning-powered application.</li>
<li><a href="https://www.fast.ai/" rel="nofollow">fast.ai Curriculum</a> - One of the best (and free) AI/deep learning courses online. Enough said.</li>
<li><a href="https://www.mrdbourke.com/how-can-a-beginner-data-scientist-like-me-gain-experience/" rel="nofollow">"How does a beginner data scientist like me gain experience?"</a> by Daniel Bourke - Read this on how to get experience for a job after studying online/at unveristy (start the job before you have it).</li>
</ul>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto">Ask questions</h2><a id="user-content-ask-questions" class="anchor" aria-label="Permalink: Ask questions" href="https://github.com/mrdbourke/tensorflow-deep-learning#ask-questions"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Contact <a href="mailto:daniel@mrdbourke.com">Daniel Bourke</a> or <a href="https://github.com/mrdbourke/tensorflow-deep-learning/discussions">add a discussion</a> (preferred).</p>
<div class="markdown-heading" dir="auto"><h2 tabindex="-1" class="heading-element" dir="auto">Log</h2><a id="user-content-log" class="anchor" aria-label="Permalink: Log" href="https://github.com/mrdbourke/tensorflow-deep-learning#log"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>2 May 2024 - update materials to reflect closing of TensorFlow Developer Certification exam by Google (see <a href="https://github.com/mrdbourke/tensorflow-deep-learning/discussions/645" data-hovercard-type="discussion" data-hovercard-url="/mrdbourke/tensorflow-deep-learning/discussions/645/hovercard">#645</a> for more)</li>
<li>12 May 2023 - update several course notebooks for latest version of TensorFlow, several API updates for Notebook 05 here: <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="5187992" data-permission-text="Title is private" data-url="https://github.com/mrdbourke/tensorflow-deep-learning/discussions/547" data-hovercard-type="discussion" data-hovercard-url="/mrdbourke/tensorflow-deep-learning/discussions/547/hovercard" href="https://github.com/mrdbourke/tensorflow-deep-learning/discussions/547">#547</a></li>
<li>02 Dec 2021 - add fix for TensorFlow 2.7 to notebook 02</li>
<li>11 Nov 2021 - add fix for TensorFlow 2.7 to notebook 01</li>
<li>14 Aug 2021 - added a discussion with TensorFlow 2.6 updates and EfficientNetV2 notes: <a class="issue-link js-issue-link" data-error-text="Failed to load title" data-id="3520570" data-permission-text="Title is private" data-url="https://github.com/mrdbourke/tensorflow-deep-learning/discussions/166" data-hovercard-type="discussion" data-hovercard-url="/mrdbourke/tensorflow-deep-learning/discussions/166/hovercard" href="https://github.com/mrdbourke/tensorflow-deep-learning/discussions/166">#166</a></li>
<li>16 Jul 2021 - added 35 videos to ZTM Academy + Udemy versions of the course for time series and how to pass TensorFlow Developer Certification</li>
<li>10 Jul 2021 - added 29 edited time series videos to ZTM Academy + Udemy versions of the course, more to come soon</li>
<li>07 Jul 2021 - recorded 5 videos for passing TensorFlow Developer Certification exam section - ALL VIDEOS FOR COURSE DONE!!! time to edit/upload! </li>
<li>06 Jul 2021 - (archived) added guide to TensorFlow Certification Exam: <a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/11_passing_the_tensorflow_developer_certification_exam.md">https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/11_passing_the_tensorflow_developer_certification_exam.md</a> - going to record videos for it tomorrow</li>
<li>05 Jul 2021 - making materials for TF certification exam (what/why/how)</li>
<li>02 Jul 2021 - FINISHED RECORDING VIDEOS FOR TIME SERIES SECTION!!!!! time to upload</li>
<li>30 Jun 2021 - recorded 12 videos for time series section, total heading past 60 (the biggest section yet), nearly done!!!</li>
<li>29 Jun 2021 - recorded 10 videos for time series section, total heading towards 60</li>
<li>28 Jun 2021 - recorded 10 videos for time series section, the line below says 40 videos total, actually more like 50</li>
<li>26 Jun 2021 - recorded 4 videos for time series section, looks like it'll be about 40 videos total</li>
<li>25 Jun 2021 - recorded 8 videos for time series section + fixed a bunch of typos in time series notebook</li>
<li>24 Jun 2021 - recorded 14 videos for time series section, more to come tomorrow</li>
<li>23 Jun 2021 - finished adding images to time series notebook, now to start video recording</li>
<li>22 Jun 2021 - added a bunch of images to the time series notebook/started making slides</li>
<li>21 Jun 2021 - code for time series notebook is done, now creating slides/images to prepare for recording</li>
<li>19 Jun 2021 - turned curriculum into an online book, you can read it here: <a href="https://dev.mrdbourke.com/tensorflow-deep-learning/" rel="nofollow">https://dev.mrdbourke.com/tensorflow-deep-learning/</a></li>
<li>18 Jun 2021 - add exercises/extra-curriculum/outline to time series notebook</li>
<li>17 Jun 2021 - add annotations for turkey problem and model comparison in time series notebook, next is outline/images</li>
<li>16 Jun 2021 - add annotations for uncertainty and future predictions in time series notebook, next is turkey problem</li>
<li>14 Jun 2021 - add annotations for ensembling, begin on prediction intervals</li>
<li>10 Jun 2021 - finished annotations for N-BEATS algorithm, now onto ensembling/prediction intervals</li>
<li>9 Jun 2021 - add annotations for N-BEATS algorithm implementation for time series notebook</li>
<li>8 Jun 2021 - add annotations to time series notebook, all will be finished by end of week (failed)</li>
<li>4 Jun 2021 - more annotation updates to time series notebook, brick by brick!</li>
<li>3 Jun 2021 - added a bunch of annotations/explanations to time series notebook, momentum building, plenty more to come!</li>
<li>2 Jun 2021 - started adding annotations explaining the code + resources to learn more, will continue for next few days</li>
<li>1 Jun 2021 - added turkey problem to time series notebook, cleaned up a bunch of code, draft code is ready, now to write annotations/explanations</li>
<li>28 May 2021 - added future forecasts, added ensemble model, added prediction intervals to time series notebook</li>
<li>25 May 2021 - added multivariate time series to time series notebook, fix LSTM model, next we add TensorFlow windowing/experimenting with window sizes</li>
<li>24 May 2021 - fixed broken preprocessing function in time series notebook, LSTM model is broken, more material to come</li>
<li>20 May 2021 - more time series material creation</li>
<li>19 May 2021 - more time series material creation, streaming much of it live on Twitch - <a href="https://twitch.tv/mrdbourke" rel="nofollow">https://twitch.tv/mrdbourke</a></li>
<li>18 May 2021 - added time series forecasting notebook outline (<a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/10_time_series_forecasting_in_tensorflow.ipynb">notebook 10</a>), going to really start ramping up the materials here</li>
<li>12 May 2021 - all videos for 09 have now been released on Udemy &amp; ZTM!!! enjoy build SkimLit </li>
<li>11 May 2021 - 40+ section 08 &amp; 09 videos released on Udemy &amp; ZTM!!!</li>
<li>10 May 2021 - time series materials research + preparation</li>
<li>08 May 2021 - time series materials research + preparation</li>
<li>05 May 2021 - ~20+ videos edited for 08, ~10+ videos edited for 09, time series materials in 1st draft mode</li>
<li>04 May 2021 - fixed the remaining videos for 08 (audio missing), now onto making time series materials!</li>
<li>03 May 2021 - rerecorded 10 videos for 08 fixing the sound isse, these are going straight to editing and should be uploaded by end of week</li>
<li>02 May 2021 - found an issue with videos 09-20 of section 08 (no audio), going to rerecord them</li>
<li>29 Apr 2021 -  launched on Udemy!!! </li>
<li>22 Apr 2021 - finished recording videos for 09! added slides and video notebook 09</li>
<li>21 Apr 2021 - recorded 14 videos for 09! biggggg day of recording! getting closer to finishing 09</li>
<li>20 Apr 2021 - recorded 10 videos for 09</li>
<li>19 Apr 2021 - recorded 9 videos for 09</li>
<li>16 Apr 2021 - slides done for 09, ready to start recording!</li>
<li>15 Apr 2021 - added slides, extra-curriculum, exercises and video notebook for 08, started making slides for 09, will finish tomorrow</li>
<li>14 Apr 2021 - recorded 12 videos for notebook 08, finished the section! time to make slides for 09 and get into it</li>
<li>10 Apr 2021 - recorded 4 videos for notebook 08</li>
<li>9 Apr 2021 - recorded 6 videos for notebook 08</li>
<li>8 Apr 2021 - recorded 10 videos for notebook 08! more coming tomorrow! home stretch baby!!!</li>
<li>7 Apr 2021 - added a whole bunch of images to notebook 08, getting ready for recording tomorrow!</li>
<li>1 Apr 2021 - added <a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/09_SkimLit_nlp_milestone_project_2.ipynb">notebook 09: SkimLit</a>, almost finished, a little cleaning and we'll be ready for slide making!</li>
<li>31 Mar 2021 - added notebook 08, going to finish tomorrow, then onto 09!</li>
<li>24 Mar 2021 - Recorded 8 videos for 07, finished! onto materials (slides/notebooks) for 08, 09</li>
<li>23 Mar 2021 - Recorded 6 videos for 07 (finally), going to finish tomorrow</li>
<li>22 Mar 2021 - Polished notebook 07 ready for recording, made slides for 07, added template for 07 (for a student to go through and practice), ready to record!</li>
<li>17 Mar 2021 - 99% finished notebook 07, added links to first 14 hours of the course on YouTube (<a href="https://youtu.be/tpCFfeUEGs8" rel="nofollow">10 hours in part 1</a>, <a href="https://youtu.be/ZUKz4125WNI" rel="nofollow">4 hours in part 2</a>)</li>
<li>11 Mar 2021 - added even more text annotations to notebook 07, finishing tomorrow, then slides</li>
<li>10 Mar 2021 - Typed a whole bunch of explanations into notebook 07, continuing tomorrow</li>
<li>09 Mar 2021 - fixed plenty of code in notebook 07, should run end to end very cleanly (though loading times are still a thing)</li>
<li>05 Mar 2021 - added draft notebook 07 (heaps of data loading and model training improvements in this one!), gonna fix up over next few days</li>
<li>01 Mar 2021 - Added slides for 06 (<a href="https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/slides/06_transfer_learning_with_tensorflow_part_3_scaling_up.pdf">see them here</a>)</li>
<li>26 Feb 2021 -  LAUNCHED!!!!! also finished recording videos for 06, onto 07, 08, 09 for next release</li>
<li>24 Feb 2021 - recorded 9 videos for section 06, launch inbound!!!</li>
<li>23 Feb 2021 - rearranged GitHub in preparation for launch </li>
<li>18 Feb 2021 - recorded 8 videos for 05 and... it's done! onto polishing the GitHub</li>
<li>17 Feb 2021 - recorded 10 videos for 05! going to finish tomorrow </li>
<li>16 Feb 2021 - polished slides for 05 and started recording videos, got 7 videos done for 05</li>
<li>15 Feb 2021 - finished videos for 04, now preparing to record for 05!</li>
<li>12 Feb 2021 - recored 7 videos for section 04... wanted 10 but we'll take 7 ( this seems to have happened before)</li>
<li>11 Feb 2021 - NO PROGRESS - gave a Machine Learning deployment tutorial for <a href="https://stanford-cs329s.github.io/syllabus.html" rel="nofollow">Stanford's CS329s</a> (using the model code from this course!!!) - <a href="https://github.com/mrdbourke/cs329s-ml-deployment-tutorial">see the full tutorial materials</a></li>
<li>08 Feb 2021 - recorded 10 videos for section 03... and section 03 is done!  onto section 04</li>
<li>30 Jan 2021 - 07 Feb 2021: NO PROGRESS (working on a ML deployment lecture for <a href="https://stanford-cs329s.github.io/syllabus.html" rel="nofollow">Stanford's CS329s</a>... more on this later)</li>
<li>29 Jan 2021 - recorded 9 videos for section 03... closer to 10 than yesterday but still not there</li>
<li>28 Jan 2021 - recorded 7 videos for section 03... wanted 10 but we'll take 7</li>
<li>27 Jan 2021 - recorded 10 videos for section 03</li>
<li>26 Jan 2021 - polished GitHub README (what you're looking at) with a <a href="https://github.com/mrdbourke/tensorflow-deep-learning#course-materials">nice table</a></li>
<li>23 Jan 2021 - finished slides of 06</li>
<li>22 Jan 2021 - finished review of notebook 06 &amp; started slides of 06</li>
<li>21 Jan 2021 - finished slides for 05 &amp; started review of 06</li>
<li>20 Jan 2021 - finished notebook 05 &amp; 95% slides for 05</li>
<li>19 Jan 2021 - found a storage idea for data during course (use Google Storage in same region as Colab Notebooks, cheapest/fastest)</li>
<li>18 Jan 2021 - reviewed notebook 05 &amp; slides for 05</li>
<li>17 Jan 2021 - finished notebook 04 &amp; slides for 04</li>
<li>16 Jan 2021 - review notebook 04 &amp; made slides for transfer learning</li>
<li>13 Jan 2021 - review notebook 03 again &amp; finished slides for 03, BIGGGGG updates to the README, notebook 03 99% done, just need to figure out optimum way to transfer data (e.g. when a student downloads it, where's best to store it in the meantime? Dropbox? S3? <del>GS</del> (too expensive)</li>
<li>11 Jan 2021 - reviewed notebook 03, 95% ready for recording, onto slides for 03</li>
<li>9 Jan 2021 - I'm back baby! Finished all videos for 02, now onto slides/materials for 03, 04, 05 (then I'll get back in the lab)</li>
<li>19 Dec 2020 - ON HOLD (family holiday until Jan 02 2021)</li>
<li>18 Dec 2020 - recorded 75% of videos for 02</li>
<li>17 Dec 2020 - recorded 50% of videos for 02</li>
<li>16 Dec 2020 - recorded 100% of videos for 01</li>
<li>15 Dec 2020 - recorded 90% of videos for 01</li>
<li>09 Dec 2020 - finished recording videos for 00</li>
<li>08 Dec 2020 - recorded 90% of videos for 00</li>
<li>05 Dec 2020 - trialled recording studio for ~6 videos with notebook 00 material</li>
<li>04 Dec 2020 - setup <a href="https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/misc-studio-setup.jpeg" rel="nofollow">recording studio in closet</a></li>
<li>03 Dec 2020 - finished notebook 02, finished slides for 02, time to setup recording studio</li>
<li>02 Dec 2020 - notebook 02 95% done, slides for 02 90% done</li>
<li>01 Dec 2020 - added notebook 02 (90% polished), start preparing slides for 02</li>
<li>27 Nov 2020 - polished notebook 01, made slides for notebook 01</li>
<li>26 Nov 2020 - polished notebook 00, made slides for notebook 00</li>
</ul>
</article></div></div></div></div></div> <!-- --> <!-- --> <script type="application/json" id="__PRIMER_DATA_:R0:__">{"resolvedServerColorMode":"day"}</script></div>
</react-partial>

      <input type="hidden" value="Lp7_kUxFt5csWbblEiyOpfeXEmxs4trbnviHuSJW-iBc2JaDPxGXyywxMXDlE-XHYW9tv_9xNrzkA9C98oB5bw" data-csrf="true" id="react-codespace-csrf">
</div>
  <div data-view-component="true" class="Layout-sidebar">      

      <div class="BorderGrid about-margin" data-pjax="">
        <div class="BorderGrid-row">
          <div class="BorderGrid-cell">
            <div class="hide-sm hide-md">
  <h2 class="mb-3 h4">About</h2>

      <p class="f4 my-3">
        All course materials for the Zero to Mastery Deep Learning with TensorFlow course.
      </p>
      <div class="my-3 d-flex flex-items-center">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-link flex-shrink-0 mr-2">
    <path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path>
</svg>
        <span class="flex-auto min-width-0 css-truncate css-truncate-target width-fit">
          <a title="https://dbourke.link/ZTMTFcourse" role="link" target="_blank" rel="noopener noreferrer nofollow" class="text-bold" href="https://dbourke.link/ZTMTFcourse">dbourke.link/ZTMTFcourse</a>
        </span>
      </div>

    <h3 class="sr-only">Topics</h3>
    <div class="my-3">
        <div class="f6">
      <a data-ga-click="Topic, repository page" data-octo-click="topic_click" data-octo-dimensions="topic:deep-neural-networks" href="https://github.com/topics/deep-neural-networks" title="Topic: deep-neural-networks" data-view-component="true" class="topic-tag topic-tag-link">
  deep-neural-networks
</a>
      <a data-ga-click="Topic, repository page" data-octo-click="topic_click" data-octo-dimensions="topic:deep-learning" href="https://github.com/topics/deep-learning" title="Topic: deep-learning" data-view-component="true" class="topic-tag topic-tag-link">
  deep-learning
</a>
      <a data-ga-click="Topic, repository page" data-octo-click="topic_click" data-octo-dimensions="topic:curriculum" href="https://github.com/topics/curriculum" title="Topic: curriculum" data-view-component="true" class="topic-tag topic-tag-link">
  curriculum
</a>
      <a data-ga-click="Topic, repository page" data-octo-click="topic_click" data-octo-dimensions="topic:tensorflow" href="https://github.com/topics/tensorflow" title="Topic: tensorflow" data-view-component="true" class="topic-tag topic-tag-link">
  tensorflow
</a>
      <a data-ga-click="Topic, repository page" data-octo-click="topic_click" data-octo-dimensions="topic:tensorflow-tutorials" href="https://github.com/topics/tensorflow-tutorials" title="Topic: tensorflow-tutorials" data-view-component="true" class="topic-tag topic-tag-link">
  tensorflow-tutorials
</a>
      <a data-ga-click="Topic, repository page" data-octo-click="topic_click" data-octo-dimensions="topic:tensorflow-course" href="https://github.com/topics/tensorflow-course" title="Topic: tensorflow-course" data-view-component="true" class="topic-tag topic-tag-link">
  tensorflow-course
</a>
      <a data-ga-click="Topic, repository page" data-octo-click="topic_click" data-octo-dimensions="topic:tensorflow2" href="https://github.com/topics/tensorflow2" title="Topic: tensorflow2" data-view-component="true" class="topic-tag topic-tag-link">
  tensorflow2
</a>
  </div>

    </div>

    <h3 class="sr-only">Resources</h3>
    <div class="mt-2">
      <a class="Link--muted" data-analytics-event="{&quot;category&quot;:&quot;Repository Overview&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;location:sidebar;file:readme&quot;}" href="https://github.com/mrdbourke/tensorflow-deep-learning#readme-ov-file">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-book mr-2">
    <path d="M0 1.75A.75.75 0 0 1 .75 1h4.253c1.227 0 2.317.59 3 1.501A3.743 3.743 0 0 1 11.006 1h4.245a.75.75 0 0 1 .75.75v10.5a.75.75 0 0 1-.75.75h-4.507a2.25 2.25 0 0 0-1.591.659l-.622.621a.75.75 0 0 1-1.06 0l-.622-.621A2.25 2.25 0 0 0 5.258 13H.75a.75.75 0 0 1-.75-.75Zm7.251 10.324.004-5.073-.002-2.253A2.25 2.25 0 0 0 5.003 2.5H1.5v9h3.757a3.75 3.75 0 0 1 1.994.574ZM8.755 4.75l-.004 7.322a3.752 3.752 0 0 1 1.992-.572H14.5v-9h-3.495a2.25 2.25 0 0 0-2.25 2.25Z"></path>
</svg>
        Readme
</a>    </div>

  
    <h3 class="sr-only">License</h3>
  <div class="mt-2">
    <a href="https://github.com/mrdbourke/tensorflow-deep-learning#MIT-1-ov-file" class="Link--muted" data-analytics-event="{&quot;category&quot;:&quot;Repository Overview&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;location:sidebar;file:license&quot;}">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-law mr-2">
    <path d="M8.75.75V2h.985c.304 0 .603.08.867.231l1.29.736c.038.022.08.033.124.033h2.234a.75.75 0 0 1 0 1.5h-.427l2.111 4.692a.75.75 0 0 1-.154.838l-.53-.53.529.531-.001.002-.002.002-.006.006-.006.005-.01.01-.045.04c-.21.176-.441.327-.686.45C14.556 10.78 13.88 11 13 11a4.498 4.498 0 0 1-2.023-.454 3.544 3.544 0 0 1-.686-.45l-.045-.04-.016-.015-.006-.006-.004-.004v-.001a.75.75 0 0 1-.154-.838L12.178 4.5h-.162c-.305 0-.604-.079-.868-.231l-1.29-.736a.245.245 0 0 0-.124-.033H8.75V13h2.5a.75.75 0 0 1 0 1.5h-6.5a.75.75 0 0 1 0-1.5h2.5V3.5h-.984a.245.245 0 0 0-.124.033l-1.289.737c-.265.15-.564.23-.869.23h-.162l2.112 4.692a.75.75 0 0 1-.154.838l-.53-.53.529.531-.001.002-.002.002-.006.006-.016.015-.045.04c-.21.176-.441.327-.686.45C4.556 10.78 3.88 11 3 11a4.498 4.498 0 0 1-2.023-.454 3.544 3.544 0 0 1-.686-.45l-.045-.04-.016-.015-.006-.006-.004-.004v-.001a.75.75 0 0 1-.154-.838L2.178 4.5H1.75a.75.75 0 0 1 0-1.5h2.234a.249.249 0 0 0 .125-.033l1.288-.737c.265-.15.564-.23.869-.23h.984V.75a.75.75 0 0 1 1.5 0Zm2.945 8.477c.285.135.718.273 1.305.273s1.02-.138 1.305-.273L13 6.327Zm-10 0c.285.135.718.273 1.305.273s1.02-.138 1.305-.273L3 6.327Z"></path>
</svg>
     MIT license
    </a>
  </div>




  <include-fragment src="/mrdbourke/tensorflow-deep-learning/hovercards/citation/sidebar_partial?tree_name=main" class="is-error"><template shadowrootmode="open"><style>:host {display: block;}</style><slot></slot></template>
  </include-fragment>

  <div class="mt-2">
    <a href="https://github.com/mrdbourke/tensorflow-deep-learning/activity" data-view-component="true" class="Link Link--muted">
      <svg text="gray" aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-pulse mr-2">
    <path d="M6 2c.306 0 .582.187.696.471L10 10.731l1.304-3.26A.751.751 0 0 1 12 7h3.25a.75.75 0 0 1 0 1.5h-2.742l-1.812 4.528a.751.751 0 0 1-1.392 0L6 4.77 4.696 8.03A.75.75 0 0 1 4 8.5H.75a.75.75 0 0 1 0-1.5h2.742l1.812-4.529A.751.751 0 0 1 6 2Z"></path>
</svg>
      <span class="color-fg-muted">Activity</span>
</a>  </div>


  <h3 class="sr-only">Stars</h3>
  <div class="mt-2">
    <a href="https://github.com/mrdbourke/tensorflow-deep-learning/stargazers" data-view-component="true" class="Link Link--muted">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-star mr-2">
    <path d="M8 .25a.75.75 0 0 1 .673.418l1.882 3.815 4.21.612a.75.75 0 0 1 .416 1.279l-3.046 2.97.719 4.192a.751.751 0 0 1-1.088.791L8 12.347l-3.766 1.98a.75.75 0 0 1-1.088-.79l.72-4.194L.818 6.374a.75.75 0 0 1 .416-1.28l4.21-.611L7.327.668A.75.75 0 0 1 8 .25Zm0 2.445L6.615 5.5a.75.75 0 0 1-.564.41l-3.097.45 2.24 2.184a.75.75 0 0 1 .216.664l-.528 3.084 2.769-1.456a.75.75 0 0 1 .698 0l2.77 1.456-.53-3.084a.75.75 0 0 1 .216-.664l2.24-2.183-3.096-.45a.75.75 0 0 1-.564-.41L8 2.694Z"></path>
</svg>
      <strong>5.1k</strong>
      stars
</a>  </div>

  <h3 class="sr-only">Watchers</h3>
  <div class="mt-2">
    <a href="https://github.com/mrdbourke/tensorflow-deep-learning/watchers" data-view-component="true" class="Link Link--muted">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-eye mr-2">
    <path d="M8 2c1.981 0 3.671.992 4.933 2.078 1.27 1.091 2.187 2.345 2.637 3.023a1.62 1.62 0 0 1 0 1.798c-.45.678-1.367 1.932-2.637 3.023C11.67 13.008 9.981 14 8 14c-1.981 0-3.671-.992-4.933-2.078C1.797 10.83.88 9.576.43 8.898a1.62 1.62 0 0 1 0-1.798c.45-.677 1.367-1.931 2.637-3.022C4.33 2.992 6.019 2 8 2ZM1.679 7.932a.12.12 0 0 0 0 .136c.411.622 1.241 1.75 2.366 2.717C5.176 11.758 6.527 12.5 8 12.5c1.473 0 2.825-.742 3.955-1.715 1.124-.967 1.954-2.096 2.366-2.717a.12.12 0 0 0 0-.136c-.412-.621-1.242-1.75-2.366-2.717C10.824 4.242 9.473 3.5 8 3.5c-1.473 0-2.825.742-3.955 1.715-1.124.967-1.954 2.096-2.366 2.717ZM8 10a2 2 0 1 1-.001-3.999A2 2 0 0 1 8 10Z"></path>
</svg>
      <strong>158</strong>
      watching
</a>  </div>

  <h3 class="sr-only">Forks</h3>
  <div class="mt-2">
    <a href="https://github.com/mrdbourke/tensorflow-deep-learning/forks" data-view-component="true" class="Link Link--muted">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-repo-forked mr-2">
    <path d="M5 5.372v.878c0 .414.336.75.75.75h4.5a.75.75 0 0 0 .75-.75v-.878a2.25 2.25 0 1 1 1.5 0v.878a2.25 2.25 0 0 1-2.25 2.25h-1.5v2.128a2.251 2.251 0 1 1-1.5 0V8.5h-1.5A2.25 2.25 0 0 1 3.5 6.25v-.878a2.25 2.25 0 1 1 1.5 0ZM5 3.25a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Zm6.75.75a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Zm-3 8.75a.75.75 0 1 0-1.5 0 .75.75 0 0 0 1.5 0Z"></path>
</svg>
      <strong>2.5k</strong>
      forks
</a>  </div>

    <div class="mt-2">
      <a class="Link--muted" href="https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fmrdbourke%2Ftensorflow-deep-learning&amp;report=mrdbourke+%28user%29">
          Report repository
</a>    </div>
</div>

          </div>
        </div>

        
        
        
        
            <div class="BorderGrid-row" hidden="">
              <div class="BorderGrid-cell">
                <include-fragment src="/mrdbourke/tensorflow-deep-learning/used_by_list" accept="text/fragment+html" class="is-error"><template shadowrootmode="open"><style>:host {display: block;}</style><slot></slot></template>
</include-fragment>
              </div>
            </div>

        
            <div class="BorderGrid-row">
              <div class="BorderGrid-cell">
                <h2 class="h4 mb-3">
  <a href="https://github.com/mrdbourke/tensorflow-deep-learning/graphs/contributors" data-view-component="true" class="Link--primary no-underline Link d-flex flex-items-center">
    Contributors
      <span title="25" data-view-component="true" class="Counter ml-1">25</span>
</a></h2>


    
  <ul class="list-style-none d-flex flex-wrap mb-n2">
    <li class="mb-2 mr-2">
      <a href="https://github.com/mrdbourke" class="" data-hovercard-type="user" data-hovercard-url="/users/mrdbourke/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self">
        <img src="./github-tensorflow-deep-learning_files/16750345(2)" alt="@mrdbourke" size="32" height="32" width="32" data-view-component="true" class="avatar circle">
      </a>
    </li>
    <li class="mb-2 mr-2">
      <a href="https://github.com/ashikshafi08" class="" data-hovercard-type="user" data-hovercard-url="/users/ashikshafi08/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self">
        <img src="./github-tensorflow-deep-learning_files/45290954" alt="@ashikshafi08" size="32" height="32" width="32" data-view-component="true" class="avatar circle">
      </a>
    </li>
    <li class="mb-2 mr-2">
      <a href="https://github.com/sanfordmascarenhas" class="" data-hovercard-type="user" data-hovercard-url="/users/sanfordmascarenhas/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self">
        <img src="./github-tensorflow-deep-learning_files/25857590" alt="@sanfordmascarenhas" size="32" height="32" width="32" data-view-component="true" class="avatar circle">
      </a>
    </li>
    <li class="mb-2 mr-2">
      <a href="https://github.com/elvanselvano" class="" data-hovercard-type="user" data-hovercard-url="/users/elvanselvano/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self">
        <img src="./github-tensorflow-deep-learning_files/49674061" alt="@elvanselvano" size="32" height="32" width="32" data-view-component="true" class="avatar circle">
      </a>
    </li>
    <li class="mb-2 mr-2">
      <a href="https://github.com/undisputedcoder" class="" data-hovercard-type="user" data-hovercard-url="/users/undisputedcoder/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self">
        <img src="./github-tensorflow-deep-learning_files/52372624" alt="@undisputedcoder" size="32" height="32" width="32" data-view-component="true" class="avatar circle">
      </a>
    </li>
    <li class="mb-2 mr-2">
      <a href="https://github.com/Hrushi11" class="" data-hovercard-type="user" data-hovercard-url="/users/Hrushi11/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self">
        <img src="./github-tensorflow-deep-learning_files/73577192" alt="@Hrushi11" size="32" height="32" width="32" data-view-component="true" class="avatar circle">
      </a>
    </li>
    <li class="mb-2 mr-2">
      <a href="https://github.com/0xKoios" class="" data-hovercard-type="user" data-hovercard-url="/users/0xKoios/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self">
        <img src="./github-tensorflow-deep-learning_files/53548542" alt="@0xKoios" size="32" height="32" width="32" data-view-component="true" class="avatar circle">
      </a>
    </li>
    <li class="mb-2 mr-2">
      <a href="https://github.com/MahmoudHassan" class="" data-hovercard-type="user" data-hovercard-url="/users/MahmoudHassan/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self">
        <img src="./github-tensorflow-deep-learning_files/5719215" alt="@MahmoudHassan" size="32" height="32" width="32" data-view-component="true" class="avatar circle">
      </a>
    </li>
    <li class="mb-2 mr-2">
      <a href="https://github.com/Aadesh-Magare" class="" data-hovercard-type="user" data-hovercard-url="/users/Aadesh-Magare/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self">
        <img src="./github-tensorflow-deep-learning_files/6009151" alt="@Aadesh-Magare" size="32" height="32" width="32" data-view-component="true" class="avatar circle">
      </a>
    </li>
    <li class="mb-2 mr-2">
      <a href="https://github.com/VedantMadane" class="" data-hovercard-type="user" data-hovercard-url="/users/VedantMadane/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self">
        <img src="./github-tensorflow-deep-learning_files/6527493" alt="@VedantMadane" size="32" height="32" width="32" data-view-component="true" class="avatar circle">
      </a>
    </li>
    <li class="mb-2 mr-2">
      <a href="https://github.com/ramitsurana" class="" data-hovercard-type="user" data-hovercard-url="/users/ramitsurana/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self">
        <img src="./github-tensorflow-deep-learning_files/8342133" alt="@ramitsurana" size="32" height="32" width="32" data-view-component="true" class="avatar circle">
      </a>
    </li>
    <li class="mb-2 mr-2">
      <a href="https://github.com/spekulatius" class="" data-hovercard-type="user" data-hovercard-url="/users/spekulatius/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self">
        <img src="./github-tensorflow-deep-learning_files/8433587" alt="@spekulatius" size="32" height="32" width="32" data-view-component="true" class="avatar circle">
      </a>
    </li>
    <li class="mb-2 mr-2">
      <a href="https://github.com/Ming-Jia" class="" data-hovercard-type="user" data-hovercard-url="/users/Ming-Jia/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self">
        <img src="./github-tensorflow-deep-learning_files/44937005" alt="@Ming-Jia" size="32" height="32" width="32" data-view-component="true" class="avatar circle">
      </a>
    </li>
    <li class="mb-2 mr-2">
      <a href="https://github.com/acromondx" class="" data-hovercard-type="user" data-hovercard-url="/users/acromondx/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self">
        <img src="./github-tensorflow-deep-learning_files/50566307" alt="@acromondx" size="32" height="32" width="32" data-view-component="true" class="avatar circle">
      </a>
    </li>
</ul>




  <div data-view-component="true" class="mt-3">
    <a text="small" href="https://github.com/mrdbourke/tensorflow-deep-learning/graphs/contributors" data-view-component="true" class="Link--inTextBlock Link">
      + 11 contributors
</a></div>
              </div>
            </div>

        
        
            <div class="BorderGrid-row">
              <div class="BorderGrid-cell">
                <h2 class="h4 mb-3">Languages</h2>
<div class="mb-2">
  <span data-view-component="true" class="Progress">
    <span style="background-color:#DA5B0B !important;;width: 100.0%;" itemprop="keywords" aria-label="Jupyter Notebook 100.0" data-view-component="true" class="Progress-item color-bg-success-emphasis"></span>
</span></div>
<ul class="list-style-none">
    <li class="d-inline">
        <a class="d-inline-flex flex-items-center flex-nowrap Link--secondary no-underline text-small mr-3" href="https://github.com/mrdbourke/tensorflow-deep-learning/search?l=jupyter-notebook" data-ga-click="Repository, language stats search click, location:repo overview">
          <svg style="color:#DA5B0B;" aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-dot-fill mr-2">
    <path d="M8 4a4 4 0 1 1 0 8 4 4 0 0 1 0-8Z"></path>
</svg>
          <span class="color-fg-default text-bold mr-1">Jupyter Notebook</span>
          <span>100.0%</span>
        </a>
    </li>
</ul>

              </div>
            </div>

              </div>
</div>
  
</div></div>

  </div>


  </div>

</turbo-frame>


    </main>
  </div>

  </div>

          <footer class="footer pt-8 pb-6 f6 color-fg-muted p-responsive" role="contentinfo">
  <h2 class="sr-only">Footer</h2>

  


  <div class="d-flex flex-justify-center flex-items-center flex-column-reverse flex-lg-row flex-wrap flex-lg-nowrap">
    <div class="d-flex flex-items-center flex-shrink-0 mx-2">
      <a aria-label="Homepage" title="GitHub" class="footer-octicon mr-2" href="https://github.com/">
        <svg aria-hidden="true" height="24" viewBox="0 0 24 24" version="1.1" width="24" data-view-component="true" class="octicon octicon-mark-github">
    <path d="M12.5.75C6.146.75 1 5.896 1 12.25c0 5.089 3.292 9.387 7.863 10.91.575.101.79-.244.79-.546 0-.273-.014-1.178-.014-2.142-2.889.532-3.636-.704-3.866-1.35-.13-.331-.69-1.352-1.18-1.625-.402-.216-.977-.748-.014-.762.906-.014 1.553.834 1.769 1.179 1.035 1.74 2.688 1.25 3.349.948.1-.747.402-1.25.733-1.538-2.559-.287-5.232-1.279-5.232-5.678 0-1.25.445-2.285 1.178-3.09-.115-.288-.517-1.467.115-3.048 0 0 .963-.302 3.163 1.179.92-.259 1.897-.388 2.875-.388.977 0 1.955.13 2.875.388 2.2-1.495 3.162-1.179 3.162-1.179.633 1.581.23 2.76.115 3.048.733.805 1.179 1.825 1.179 3.09 0 4.413-2.688 5.39-5.247 5.678.417.36.776 1.05.776 2.128 0 1.538-.014 2.774-.014 3.162 0 .302.216.662.79.547C20.709 21.637 24 17.324 24 12.25 24 5.896 18.854.75 12.5.75Z"></path>
</svg>
</a>
      <span>
         2024 GitHub,&nbsp;Inc.
      </span>
    </div>

    <nav aria-label="Footer">
      <h3 class="sr-only" id="sr-footer-heading">Footer navigation</h3>

      <ul class="list-style-none d-flex flex-justify-center flex-wrap mb-2 mb-lg-0" aria-labelledby="sr-footer-heading">

          <li class="mx-2">
            <a data-analytics-event="{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to Terms&quot;,&quot;label&quot;:&quot;text:terms&quot;}" href="https://docs.github.com/site-policy/github-terms/github-terms-of-service" data-view-component="true" class="Link--secondary Link">Terms</a>
          </li>

          <li class="mx-2">
            <a data-analytics-event="{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to privacy&quot;,&quot;label&quot;:&quot;text:privacy&quot;}" href="https://docs.github.com/site-policy/privacy-policies/github-privacy-statement" data-view-component="true" class="Link--secondary Link">Privacy</a>
          </li>

          <li class="mx-2">
            <a data-analytics-event="{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to security&quot;,&quot;label&quot;:&quot;text:security&quot;}" href="https://github.com/security" data-view-component="true" class="Link--secondary Link">Security</a>
          </li>

          <li class="mx-2">
            <a data-analytics-event="{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to status&quot;,&quot;label&quot;:&quot;text:status&quot;}" href="https://www.githubstatus.com/" data-view-component="true" class="Link--secondary Link">Status</a>
          </li>

          <li class="mx-2">
            <a data-analytics-event="{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to docs&quot;,&quot;label&quot;:&quot;text:docs&quot;}" href="https://docs.github.com/" data-view-component="true" class="Link--secondary Link">Docs</a>
          </li>

          <li class="mx-2">
            <a data-analytics-event="{&quot;category&quot;:&quot;Footer&quot;,&quot;action&quot;:&quot;go to contact&quot;,&quot;label&quot;:&quot;text:contact&quot;}" href="https://support.github.com/?tags=dotcom-footer" data-view-component="true" class="Link--secondary Link">Contact</a>
          </li>

          <li class="mr-3">
  <cookie-consent-link data-catalyst="">
    <button type="button" class="Link--secondary underline-on-hover border-0 p-0 color-bg-transparent" data-action="click:cookie-consent-link#showConsentManagement" data-analytics-event="{&quot;location&quot;:&quot;footer&quot;,&quot;action&quot;:&quot;cookies&quot;,&quot;context&quot;:&quot;subfooter&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;cookies_link_subfooter_footer&quot;}">
      Manage cookies
    </button>
  </cookie-consent-link>
</li>

<li class="mr-3">
  <cookie-consent-link data-catalyst="">
    <button type="button" class="Link--secondary underline-on-hover border-0 p-0 color-bg-transparent" data-action="click:cookie-consent-link#showConsentManagement" data-analytics-event="{&quot;location&quot;:&quot;footer&quot;,&quot;action&quot;:&quot;dont_share_info&quot;,&quot;context&quot;:&quot;subfooter&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;dont_share_info_link_subfooter_footer&quot;}">
      Do not share my personal information
    </button>
  </cookie-consent-link>
</li>

      </ul>
    </nav>
  </div>
</footer>




    <ghcc-consent id="ghcc" class="position-fixed bottom-0 left-0" style="z-index: 999999" data-initial-cookie-consent-allowed="" data-cookie-consent-required="false" data-catalyst=""></ghcc-consent>


  <div id="ajax-error-message" class="ajax-error-message flash flash-error" hidden="">
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-alert">
    <path d="M6.457 1.047c.659-1.234 2.427-1.234 3.086 0l6.082 11.378A1.75 1.75 0 0 1 14.082 15H1.918a1.75 1.75 0 0 1-1.543-2.575Zm1.763.707a.25.25 0 0 0-.44 0L1.698 13.132a.25.25 0 0 0 .22.368h12.164a.25.25 0 0 0 .22-.368Zm.53 3.996v2.5a.75.75 0 0 1-1.5 0v-2.5a.75.75 0 0 1 1.5 0ZM9 11a1 1 0 1 1-2 0 1 1 0 0 1 2 0Z"></path>
</svg>
    <button type="button" class="flash-close js-ajax-error-dismiss" aria-label="Dismiss error">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
    </button>
    You cant perform that action at this time.
  </div>

    <template id="site-details-dialog"></template>

    <div class="Popover js-hovercard-content position-absolute" style="display: none; outline: none;">
  <div class="Popover-message Popover-message--bottom-left Popover-message--large Box color-shadow-large" style="width:360px;"></div>
</div>

    <template id="snippet-clipboard-copy-button"></template>
<template id="snippet-clipboard-copy-button-unpositioned"></template>


    <style>
      .user-mention[href$="/xroadtraveler"] {
        color: var(--color-user-mention-fg);
        background-color: var(--bgColor-attention-muted, var(--color-attention-subtle));
        border-radius: 2px;
        margin-left: -2px;
        margin-right: -2px;
        padding: 0 2px;
      }
    </style>


    </div>

    <div id="js-global-screen-reader-notice" class="sr-only mt-n1" aria-live="polite" aria-atomic="true"></div>
    <div id="js-global-screen-reader-notice-assertive" class="sr-only mt-n1" aria-live="assertive" aria-atomic="true"></div>
  


<div id="torrent-scanner-popup" style="display: none;"><template shadowrootmode="open"><link rel="stylesheet" href="chrome-extension://aegnopegbbhjeeiganiajffnalhlkkjb/css/custom.css"><div id="yf-bt-wrapper" class="free"><div class="header"><img class="sts-logo" src="chrome-extension://aegnopegbbhjeeiganiajffnalhlkkjb/img/assets/ts-free-logo.png"><div class="search-content"><input id="search-input" class="search-input" type="search" placeholder="Start your search here..."><span id="search-btn" class="search-btn"></span></div></div><div class="container"><div class="main-container"><div id="torrent-data" class="torrent-content"><div class="t-table"><div class="t-header"><div class="t-name">Torrent search results</div></div><div id="checked-sites" class="checked-sites-section"><div class="left">Checked Sites</div><div class="right"><span id="sites-count" class="sites-count">0</span></div></div><div id="table-body" class="t-body"><div id="loading" class="spinner"><div class="bounce1"></div><div class="bounce2"></div><div class="bounce3"></div></div><div class="table-message-container" id="table-message"><p>No items to list <br> Use the search bar above for instant results</p></div></div></div></div><div class="tooltip"><p class="tooltip-text">To see search results, type here and hit `Enter`</p></div><div class="footer"><span><span id="numberScanned" class="numberScanned">No results</span></span></div><div class="upgradeProPanel"><div class="upgradeProPanelTitle">Try our Torrent Scanner Plus to unlock:</div><div class="upgradeProPanelList"><div><p>Faster Results</p></div><div><p>Unlimited Search Results with detailed torrent info</p></div><div><p>Secure Torrenting</p></div></div><a class="upgrade-to-pro-button-2" id="buy-pro" href="https://shop.lavasoft.com/clickgate/join.aspx?ref=shop.lavasoft.com&amp;ujid=W9yhyAwEW5Q%3D" target="_blank">Get Torrent Scanner +</a></div></div><div class="sync-container nav-se-container"><div class="nav-se-content"><img class="sync-icon nav-se-icon" src="chrome-extension://aegnopegbbhjeeiganiajffnalhlkkjb/img/assets/icon-sync.svg"><div class="nav-se-title">One more step to go before you start torrenting!</div><p class="nav-se-text">This extension can sync results with BitTorrent and/or uTorrent for instant downloading.</p><p class="nav-se-text">To activate this feature, please click on the button below, and then on the Chrome message to activate the 'Messaging Permission'.</p><button class="sync-permission-btn nav-se-btn">Activate Messaging Permission</button></div><div class="nav-se-content display-none"><img class="sync-icon nav-se-icon" src="chrome-extension://aegnopegbbhjeeiganiajffnalhlkkjb/img/assets/icon-sync.svg"><div class="nav-se-title">Syncing...</div><p class="nav-se-text">Please allow Messaging Permissions in the proceeding Chrome message.</p></div><div class="nav-se-content display-none"><img class="sync-icon nav-se-icon" src="chrome-extension://aegnopegbbhjeeiganiajffnalhlkkjb/img/assets/icon-success.svg"><div class="nav-se-title">Sync Complete</div><p class="nav-se-text">You have successfully activated the Messaging Permission feature. All your search results will sync with BitTorrent and/or uTorrent.</p></div></div><div class="license-container nav-se-container"><div class="nav-se-content"><img class="nav-se-icon" src="chrome-extension://aegnopegbbhjeeiganiajffnalhlkkjb/img/assets/icon-key2.svg"><div class="nav-se-title">Enter License Key</div><p class="nav-se-text">Enter your license key and click on the activate button to start using <span>Torrent Scanner Plus.</span></p><input type="text" id="license-input-key" class="license-input-key" placeholder="Enter Key"><div class="license-spinner"><div class="bounce1"></div><div class="bounce2"></div><div class="bounce3"></div></div><button id="license-activate-button" class="license-activate-button nav-se-btn">Activate</button><p>Don't have a license key? <a class="license-buy-link" target="_blank">Click here</a></p></div><div class="nav-se-content display-none"><img class="nav-se-icon" src="chrome-extension://aegnopegbbhjeeiganiajffnalhlkkjb/img/assets/icon-success.svg"><div class="nav-se-title">Happy Torrenting!</div><p class="nav-se-text">You are now an active PRO user</p><p class="nav-se-text">Your key is valid until <span class="expiry-date"></span></p></div><div class="nav-se-content display-none"><img class="nav-se-icon" src="chrome-extension://aegnopegbbhjeeiganiajffnalhlkkjb/img/assets/icon-alert.svg"><div class="nav-se-title">Your license key has expired</div><p class="nav-se-text">Looks like your license key has expired, to renew your PRO license key, please select a license type:</p><a class="upgrade-to-pro-button-2 buy-license-expiry-button" href="https://shop.lavasoft.com/clickgate/join.aspx?ref=shop.lavasoft.com&amp;ujid=W9yhyAwEW5Q%3D" target="_blank">Buy Torrent Scanner +</a><p class="nav-se-text">Already have a license key? <a class="link" id="show-license-panel">Click here</a></p></div><div class="nav-se-content display-none"><img class="nav-se-icon" src="chrome-extension://aegnopegbbhjeeiganiajffnalhlkkjb/img/assets/icon-success.svg"><p class="nav-se-text">Your key is valid until <span class="expiry-date"></span></p><p class="nav-se-text">Your License Key:</p><p class="nav-se-text"></p><p class="nav-se-text margin-top-50">Switch back to Torrent Scanner Free?</p><button class="activate-free-btn nav-se-btn">Revert to Free Version</button></div></div><div class="feedback-container nav-se-container"><div class="nav-se-content"><img class="nav-se-icon" src="chrome-extension://aegnopegbbhjeeiganiajffnalhlkkjb/img/assets/icon-feedback.svg"><div class="nav-se-title">Feedback</div><p class="nav-se-text">Help us improve Torrent Scanner, send us comments, bugs, feedback, and suggestions.</p><button id="feedback-button" class="feedback-button nav-se-btn">Send Feedback</button></div></div><div class="settings-container nav-se-container"><div class="nav-se-content"><div class="settings-title">Settings</div></div><div class="s-table"><div class="s-row"><div class="s-title">FAQ<div class="s-arrow"><span class="arrow-down"></span></div></div><div class="s-content faq-content"><p class="faq-text">FAQ: <a href="chrome-extension://aegnopegbbhjeeiganiajffnalhlkkjb/faq.html" target="_blank">Click here</a></p></div></div><div class="s-row"><div class="s-title">Rate the extension<div class="s-arrow"><span class="arrow-down"></span></div></div><div class="s-content"><p class="rate-text">How did you like the extension experience?</p><div class="rating"><span class="rating-star"></span><span class="rating-star"></span><span class="rating-star"></span><span class="rating-star"></span><span class="rating-star"></span></div><button class="rating-btn nav-se-btn" disabled="">Submit</button></div></div><div class="s-row"><div class="s-title">About<div class="s-arrow"><span class="arrow-down"></span></div></div><div class="s-content about-content"><div class="about-version">Version 1.4.0 <br><br> What's New</div><div class="about-new"><p></p><ul><li>Experience a complete new User Interface of the extension. It is enhanced and user friendly now.</li><li>Squashed some bugs.</li></ul><p></p></div></div></div><div class="s-row"><div class="s-title">Privacy Policy<div class="s-arrow"><span class="arrow-down"></span></div></div><div class="s-content"><div class="policy-text">Adaware Software (7270356 Canada Inc.) is the operator of the Adaware products suites and related services (the <b>Company</b>, <b>we</b> or <b>us</b>). We respect your privacy rights and we are committed to protecting them. This privacy policy (<b>Privacy Policy</b> or simply <b>policy</b>) governs our products, services and websites that link to this Privacy Policy, and describes our practices of processing data from you. By <b>you</b>, we refer to either or all of the following: (i) visitors to our websites that links to this Privacy Policy (<b>Visitor</b> and <b>Website</b>, respectively); (ii) our customers using our software products and Services (<b>User</b>); and (c) a business customer, a business partner that has a contractual relationship with us or a prospective customer that is yet to be engaged in a contract with us (Business Customer). Unless explicitly mentioned otherwise, the information in this Privacy Policy refers to any and all data subject types (you or your). <br><br> For the purpose of this policy, the <b>Service(s)</b> shall include any software licensed by the Company, including features offered by or within the installed software or additional software scripts available therein (either downloaded from one of our websites, pre-installed on your device, downloaded through a third party website, obtained on a physical medium, or otherwise), or services provided through and/or on top such software, services offered on our websites, communication forums, support services, account operation, updates, enhancements, new features, premium support, extended guarantees, online version and free versions of a software or additional services or features as we ay make available from time to time. <br><br> If you are a California resident, please also see our <a href="https://www.adaware.com/CCPA/" target="_blank">CCPA Notice</a>. <br><br> <a href="https://www.adaware.com/privacy-policy/" target="_blank">Read more</a></div></div></div><div class="s-row" style="display: none;"><div class="s-title">Contact Us<div class="s-arrow"><span class="arrow-down"></span></div></div><div class="s-content"><div class="contact-text">For any payment and order-related support, please contact us at Email: <a href="mailto:support@torrentscanner.zendesk.com">support@torrentscanner.zendesk.com</a> or <a href="mailto:pcsoftwareinfo.com">pcsoftwareinfo.com</a><br><br>Phone: <a href="https://pcsoftwareinfo.com/contact.aspx" target="_blank">Click here</a></div></div></div></div></div></div><div class="nav"><button id="btnSync" class="nav-btn">Sync</button><button id="btnLicense" class="nav-btn">License</button><button id="btnHome" class="nav-btn">Home</button><button id="btnFeedback" class="nav-btn">Feedback</button><button id="btnSettings" class="nav-btn">Settings</button></div></div></template></div></body><div id="lolli-overlay-8zZlpZDppdg5s4kBy4DaBWGZos8tOwWg" style="all:initial" ng-version="14.2.5"><template shadowrootmode="open"><!----><!----><!----><!----></template></div></html>